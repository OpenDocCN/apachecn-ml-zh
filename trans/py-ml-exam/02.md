# Two

# 用朴素贝叶斯构建电影推荐引擎

正如承诺的那样，在本章中，我们将从机器学习分类，特别是二进制分类开始我们的监督学习之旅。本章的目标是建立一个电影推荐系统。从现实生活中的例子中学习分类是一个很好的起点——电影流媒体服务提供商已经在这样做了，我们也可以这样做。您将学习分类的基本概念，包括它的功能及其各种类型和应用，重点是使用简单但强大的算法朴素贝叶斯解决二元分类问题。最后，本章将演示如何微调模型，这是每个数据科学或机器学习从业者都应该学习的重要技能。

我们将详细讨论以下主题:

*   什么是机器学习分类？
*   分类类型
*   文本分类的应用
*   朴素贝叶斯分类器
*   朴素贝叶斯的力学
*   朴素的贝叶斯实现
*   用朴素贝叶斯构建电影推荐系统
*   分类绩效评估
*   交叉验证
*   调整分类模型

# 分类入门

电影推荐可以框架为机器学习分类问题。例如，如果有人预测你喜欢一部电影，那么它就会出现在你的推荐名单上，否则就不会。让我们从学习机器学习分类的重要概念开始。

**分类**是监督学习的主要实例之一。给定包含观察值及其相关分类输出的训练数据集，分类的目标是学习一个通用规则，该规则将**观察值**(也称为**特征**或**预测变量**)正确映射到目标**类别**(也称为**标签**或**类**)。换一种说法模型学习训练样本的特征和目标后会生成一个训练好的分类模型，如图*前半部分图 2.1* 。当新的或者看不见的数据进来时，训练好的模型将能够确定它们想要的类成员。使用训练好的分类模型，基于已知的输入特征来预测类别信息，如*图 2.1* 后半部分所示:

<figure class="mediaobject">![](../Images/B16326_02_01-new.png)</figure>

图 2.1:分类中的训练和预测阶段

一般来说，基于类输出可能性的分类有三种——**二进制**、**多类**、**多标签分类**。我们将在下一节逐一介绍它们。

## 二元分类

这将观测值分为两种可能的类别之一。我们每天遇到的垃圾邮件过滤的例子就是二进制分类的典型用例，它将电子邮件消息(输入观察)识别为垃圾邮件还是非垃圾邮件(输出类)。客户流失预测是另一个经常提到的例子，其中预测系统从客户关系管理系统中获取客户细分数据和活动数据，并识别哪些客户可能流失。

营销和广告行业的另一个应用是在线广告的点进预测——也就是说，根据用户的 cookie 信息和浏览历史，广告是否会被点击。最后但并非最不重要的一点是，二元分类也已被用于生物医学科学，例如，在早期癌症诊断中，根据磁共振图像将患者分为高风险组或低风险组。

如*图 2.2* 所示，二进制分类试图找到一种方法将数据从两个类中分离出来(用点和叉表示):

<figure class="mediaobject">![](../Images/B16326_02_02.png)</figure>

图 2.2:二进制分类示例

别忘了预测一个人是否喜欢一部电影也是一个二元分类问题。

## 多类分类

这种分类也被称为**多项式分类**。它允许两个以上可能的类，而在二进制情况下只有两个。手写数字识别是分类的一个常见实例，自 20 世纪初以来已有很长的研究和发展历史。例如，一个分类系统可以学习阅读和理解手写的邮政编码(在大多数国家是从 0 到 9 的数字)，信封可以通过它自动分类。

手写数字识别变成了*“你好，世界！”*在学习机器学习的旅途中，由国家标准与技术研究院构建的扫描文档数据集，名为 **MNIST** ( **修改后的国家标准与技术研究院**)是一个经常用于测试和评估多类分类模型的基准数据集。*图 2.3* 显示了取自 MNIST 数据集的四个样本:

<figure class="mediaobject">![](../Images/B16326_02_03.png)</figure>

图 2.3:来自 MNIST 数据集的样本

在*图 2.4* 中，多类分类模型试图找到分离边界，将数据从以下三个不同的类中分离出来(用点、十字和三角形表示):

<figure class="mediaobject">![](../Images/B16326_02_04.png)</figure>

图 2.4:多类分类示例

## 多标签分类

在前两种类型的分类中，目标类是互斥的，一个样本被分配*一个，只有一个*标签。多标签分类则相反。由于现代应用中类别无处不在的性质，越来越多的研究注意力被吸引到多标签分类上。例如，捕捉大海和日落的图片可以同时属于两个概念场景，而在二元情况下，它只能是猫或狗的图像，或者在多类情况下，它只能是橙子、苹果和香蕉中的一种水果的图像。同样，冒险电影也经常与其他类型相结合，如奇幻、科幻、恐怖和戏剧。

另一个典型的应用是蛋白质功能分类，因为蛋白质可能有不止一个功能——储存、抗体、支持、运输等等。

解决 *n* 标签分类问题的典型方法是将其转换为一组 *n* 二进制分类问题，其中每个二进制分类问题由单独的二进制分类器处理。

参考*图 2.5* 看到一个多标签分类问题重组为多个二元分类问题:

<figure class="mediaobject">![](../Images/B16326_02_05.png)</figure>

图 2.5:将三标签分类转换为三个独立的二进制分类

为了解决这些问题，研究人员开发了许多强大的分类算法，其中经常使用朴素贝叶斯、**支持向量机** ( **SVM** )、决策树和逻辑回归。在接下来的小节中，我们将介绍朴素贝叶斯的机制及其深入实现，以及其他重要概念，包括分类器调优和分类性能评估。请继续关注接下来的章节，这些章节涵盖了其他分类算法。

# 探索朴素的贝叶斯

**朴素贝叶斯**分类器属于概率分类器家族。它计算属于每个类别的数据的每个预测**特征**(也称为**属性**或**信号**)的概率，以便对所有类别的概率分布进行预测。当然，从得到的概率分布，我们可以得出数据样本最有可能关联的类。正如其名称所示，朴素贝叶斯具体做了如下工作:

*   **贝叶斯**:如中所示，它基于贝叶斯定理，将给定可能类别的观察输入特征的概率映射到给定观察证据的类别概率。
*   **天真**:和中一样通过假设预测特征是相互独立的，简化了概率计算。

我将在下一节用例子解释贝叶斯定理。

## 通过例子学习贝叶斯定理

在深入分类器之前，理解贝叶斯定理很重要。让 *A* 和 *B* 表示两个事件。事件可能是*明天会下雨*；*一副牌抽两个王*，或者*一个人得了癌症*。在贝叶斯定理中， *P(A |B)* 是假设 *B* 为真时 *A* 出现的概率。它可以计算如下:

<figure class="mediaobject">![](../Images/B16326_02_001.png)</figure>

这里 *P(B |A)* 是给定 *A* 出现的情况下观察 *B* 的概率，而 *P(A)* 和 *P(B)* 分别是 *A* 和 *B* 出现的概率。是不是太抽象了？让我们考虑以下具体示例:

*   例 1:给两个硬币，一个不公平，90%的空翻得到一个头，10%得到一个尾，另一个公平。随机挑选一枚硬币并掷下。如果我们得到一个人头，这枚硬币不公平的概率是多少？

我们可以这样解决，先表示 *U* 为摘不公平币事件， *F* 为公平币事件， *H* 为领人头事件。所以，当我们得到一个人头 *P(U |H)* 时，不公平硬币被挑中的概率，可以用以下公式计算:

<figure class="mediaobject">![](../Images/B16326_02_002.png)</figure>

我们知道， *P(H |U)* 为 90%。 *P(U)* 是 0.5，因为我们从两个硬币中随机挑一个。然而，推导出获得人头的概率 *P(H)* 并没有那么简单，因为两个事件可以导致以下情况，其中 *U* 是不公平硬币被摘下的时候， *F* 是公平硬币被摘下的时候:

<figure class="mediaobject">![](../Images/B16326_02_003.png)</figure>

现在， *P(U | H)* 变成如下:

<figure class="mediaobject">![](../Images/B16326_02_004.png)</figure>

*   例 2:假设医生在 10000 人中报告了以下癌症筛查测试场景:

<colgroup><col> <col> <col> <col></colgroup> 
|  | 巨蟹星座 | 没有癌症 | 总数 |
| 测试阳性 | Eighty | Nine hundred | Nine hundred and eighty |
| 测试阴性 | Twenty | Nine thousand | Nine thousand and twenty |
| 总数 | One hundred | Nine thousand nine hundred | ten thousand |

表 2.1:癌症筛查结果示例

这表明 100 名癌症患者中有 80 名被正确诊断，而另外 20 名没有被正确诊断；在 9900 名健康人中，有 900 人被错误地检测出癌症。

如果对一个人的筛查结果是阳性，他们实际上患癌症的概率是多少？让我们将癌症事件和阳性检测结果分别指定为 *C* 和 *Pos* 。所以我们有 *P(Pos |C)* = 80/100 = 0.8， *P(C)* = 100/1000 = 0.1， *P(Pos)* = 980/1000 = 0.98。

我们可以应用贝叶斯定理来计算 *P(C |Pos)* :

<figure class="mediaobject">![](../Images/B16326_02_005.png)</figure>

给定阳性筛查结果，受试者患癌症的几率为 8.16%，这明显高于一般假设(100/10000=1%)下未接受筛查的受试者。

*   例 3:一个工厂的三台机器*A**B**C*分别占灯泡产量的 35%、20%和 45%。每台机器生产的缺陷灯泡比例分别为 1.5%、1%和 2%。该厂生产的灯泡被鉴定为有缺陷，被标记为事件 *D* 。这个灯泡分别由机器 *A* 、 *B* 、 *C* 制造的概率有多大？

同样，我们可以简单地遵循贝叶斯定理:

<figure class="mediaobject">![](../Images/B16326_02_07.png)</figure>

另外，无论哪种方式，我们甚至不需要计算 *P(D)* ，因为我们知道以下情况:

<figure class="mediaobject">![](../Images/B16326_02_006.png)</figure>

我们还知道以下概念:

<figure class="mediaobject">![](../Images/B16326_02_007.png)</figure>

因此，我们有以下公式:

<figure class="mediaobject">![](../Images/B16326_02_008.png)</figure>

<figure class="mediaobject">![](../Images/B16326_02_009.png)</figure>

现在，您已经理解了贝叶斯定理是朴素贝叶斯的支柱，我们可以很容易地推进分类器本身。

## 朴素贝叶斯的力学

让我们从讨论算法背后的魔力开始——朴素贝叶斯是如何工作的。给定一个数据样本， *x* ，带有 *n* 特征，*x*T7】1， *x* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">2</sub> ，...，*x*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">n</sub>(*x*代表特征向量，*x*=(*x*T23】1，*x*T27】2，...， *x* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">n</sub> ))，朴素贝叶斯的目标是确定这个样本属于每一个 *K* 可能类*y*T37】1，*y*T41】2，...，*y*T45】K，即*P(y*T49】KT51】| x)或*P*(*x*T57】1，*x*T61】2，...， *x* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">n</sub> )，其中 *k* = 1，2，…， *K* 。

这看起来和我们刚才处理的没什么区别: *x* 或*x*T4】1、*x*T8】2，...， *x* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">n</sub> 。这是一个联合事件，观察到特征值的样本 *x* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">1</sub> ， *x* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">2</sub> ，...， *x* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">n</sub> 。 *y* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">K</sub> 是样品属于类 *k* 的事件。我们可以马上应用贝叶斯定理:

<figure class="mediaobject">![](../Images/B16326_02_010.png)</figure>

让我们详细看看每个组件:

*   *P(y* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">K</sub> *)* 描绘的是类是如何分布的，对观察特征没有进一步的了解。因此，它在贝叶斯概率术语中也被称为优先于。先验可以是预先确定的(通常以统一的方式，其中每个类都有相等的出现机会)，也可以从一组训练样本中学习。
*   *P(y* <sub class="" style="font-style: italic;">K</sub> *|x)* ，在对比之前的 *P(y* <sub class="" style="font-style: italic;">K</sub> *)* ，是**的后路**，拥有额外的观察知识。
*   *P(x |y* <sub class="" style="font-style: italic;">K</sub> *)* ，或 *P(x* <sub class="" style="font-style: italic;">1</sub> *，x* <sub class="" style="font-style: italic;">2</sub> *，...，x*<sub class="" style="font-style: italic;">n</sub>*| y*<sub class="" style="font-style: italic;">K</sub>*)*是 *n* 特征的联合分布，假设样品属于类 *y* <sub class="" style="font-style: italic;">K</sub> 。这就是具有这些值的特征共存的可能性。这在贝叶斯术语中被称为**可能性**。显然，随着特征数量的增加，可能性将很难计算。在朴素贝叶斯中，由于特征独立性假设，这个问题得以解决。 *n* 特征的联合条件分布可以表示为单个特征条件分布的联合乘积:

<figure class="mediaobject">![](../Images/B16326_02_011.png)</figure>

可以从一组训练样本中有效地学习每个条件分布。

*   *P(x)* ，也称为**证据**，仅仅依赖于特征的整体分布，其并不特定于某些类，因此是一个归一化常数。因此，后验与先验和可能性成正比:

<figure class="mediaobject">![](../Images/B16326_02_012.png)</figure>

*图 2.6* 总结了朴素贝叶斯分类模型是如何训练并应用于新数据的:

<figure class="mediaobject">![](../Images/B16326_02_08-new.png)</figure>

图 2.6:朴素贝叶斯分类中的训练和预测阶段

在我们跳到朴素贝叶斯的实现之前，让我们通过一个电影推荐的简化例子来看看朴素贝叶斯分类器的作用。给定四个(伪)用户，他们是否喜欢三部电影中的每一部， *m* <sub class="" style="font-style: italic;">1</sub> *、m* <sub class="" style="font-style: italic;">2</sub> *、m* <sub class="" style="font-style: italic;">3</sub> (表示为 1 或 0)，以及他们是否喜欢目标电影(表示为事件 *Y* )(表示为事件 *N* )，如下表所示，要求我们预测另一个用户喜欢该电影的可能性有多大

<colgroup><col> <col> <col> <col> <col> <col></colgroup> 
|  | 身份证明 | 货币供应量 | 货币供应量之二 | m3 | 用户是否喜欢目标电影 |
| 培训用数据 | one | Zero | one | one | Y |
| Two | Zero | Zero | one | 普通 |
| three | Zero | Zero | Zero | Y |
| four | one | one | Zero | Y |
| 测试案例 | five | one | one | Zero | ？ |

表 2.2:电影推荐的玩具数据示例

用户是否喜欢三部电影， *m* <sub class="" style="font-style: italic;">1</sub> *，m* <sub class="" style="font-style: italic;">2</sub> *，m* <sub class="" style="font-style: italic;">3</sub> ，都是我们可以用来预测目标类的特征(信号)。我们掌握的训练数据是四个样本，既有评分也有目标信息。

现在，让我们首先计算先验， *P(Y)* 和 *P(N)* 。从训练集中，我们可以很容易地得到以下内容:

<figure class="mediaobject">![](../Images/B16326_02_013.png)</figure>

<figure class="mediaobject">![](../Images/B16326_02_014.png)</figure>

或者，我们也可以假设 *P(Y)* = 50%，例如。

为简单起见，我们将表示用户是否喜欢三部电影的事件分别为*f*T3】1T5】fT7】2T9】fT11】3。要计算后验*P(Y | x)*其中 *x* = (1，1，0)，第一步是计算可能性，*P(f*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">1</sub>*= 1 | Y)*，*P(f*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">2</sub>*= 1Y)*，以及 *P(f* <sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">3 *P(f*T43】2</sub>*= 1 | N)*，以及*P(f*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">3</sub>*= 0 | N)*基于训练集。 但是，你可能会注意到，由于*f*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">1</sub>*= 1*在 *N* 类中没有出现，我们将得到*P(f*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="" style="font-style: italic;">1</sub>*= 1 | N)= 0*。因此，我们会有![](../Images/B16326_02_015.png)，这意味着我们会不顾一切地预测 class = *Y* 。

为了消除零乘法因子，即未知的可能性，我们通常给每个特征分配一个初始值 1，也就是说，我们从 1 开始计算一个特征的每个可能值。这种技术也被称为拉普拉斯平滑 T2。有了这项修正案，我们现在有了以下内容:

<figure class="mediaobject">![](../Images/B16326_02_016.png)</figure>

<figure class="mediaobject">![](../Images/B16326_02_017.png)</figure>

这里，给定类 *N* ，0 + 1 表示有零个喜欢的 *m* <sub class="" style="font-style: italic;">1</sub> 加+ 1 平滑；1 + 2 表示有一个数据点(ID = 2)加上两个(两个可能的值)+ 1 个平滑。给定类 *Y* ，1 + 1 表示有一个类 *m* <sub class="" style="font-style: italic;">1</sub> (ID = 4)加+ 1 平滑；3 + 2 意味着有三个数据点(ID = 1，3，4)加上两个(两个可能的值)+ 1 平滑。

同样，我们可以计算如下:

<figure class="mediaobject">![](../Images/B16326_02_018.png)</figure>

<figure class="mediaobject">![](../Images/B16326_02_019.png)</figure>

<figure class="mediaobject">![](../Images/B16326_02_020.png)</figure>

<figure class="mediaobject">![](../Images/B16326_02_021.png)</figure>

现在，我们可以计算两个后验概率的比值，如下所示:

<figure class="mediaobject">![](../Images/B16326_02_022.png)</figure>

另外，请记住:

<figure class="mediaobject">![](../Images/B16326_02_023.png)</figure>

最后，我们有以下内容:

<figure class="mediaobject">![](../Images/B16326_02_024.png)</figure>

新用户喜欢目标电影的几率为 92.1%。

希望你现在在看完理论和一个玩具例子后，对朴素贝叶斯有一个扎实的理解。让我们在下一节为它的实现做好准备。

# 实现朴素贝叶斯

手算电影偏好预测示例后，如承诺的，我们要从头开始编写朴素贝叶斯。之后，我们将使用`scikit-learn`包来实现它。

## 从头开始实现朴素贝叶斯

在开发模型之前，让我们定义一下刚刚处理过的玩具数据集:

```py
>>> import numpy as np
>>> X_train = np.array([
...     [0, 1, 1],
...     [0, 0, 1],
...     [0, 0, 0],
...     [1, 1, 0]])
>>> Y_train = ['Y', 'N', 'Y', 'Y']
>>> X_test = np.array([[1, 1, 0]]) 
```

对于模型，从前面开始，我们首先按标签对数据进行分组，并按类记录它们的索引:

```py
>>> def get_label_indices(labels):
...     """
...     Group samples based on their labels and return indices
...     @param labels: list of labels
...     @return: dict, {class1: [indices], class2: [indices]}
...     """
...     from collections import defaultdict
...     label_indices = defaultdict(list)
...     for index, label in enumerate(labels):
...         label_indices[label].append(index)
...     return label_indices 
```

看看我们得到了什么:

```py
>>> label_indices = get_label_indices(Y_train)
>>> print('label_indices:\n', label_indices)
label_indices
 defaultdict(<class 'list'>, {'Y': [0, 2, 3], 'N': [1]}) 
```

有了`label_indices`，我们计算先验:

```py
>>> def get_prior(label_indices):
...     """
...     Compute prior based on training samples
...     @param label_indices: grouped sample indices by class
...     @return: dictionary, with class label as key, corresponding 
...              prior as the value
...     """
...     prior = {label: len(indices) for label, indices in
...                                      label_indices.items()}
...     total_count = sum(prior.values())
...     for label in prior:
...         prior[label] /= total_count
...     return prior 
```

看看计算的先验:

```py
>>> prior = get_prior(label_indices)
>>> print('Prior:', prior)
 Prior: {'Y': 0.75, 'N': 0.25} 
```

计算`prior`后，我们继续`likelihood`，这是条件概率 P(特征|类):

```py
>>> def get_likelihood(features, label_indices, smoothing=0):
...     """
...     Compute likelihood based on training samples
...     @param features: matrix of features
...     @param label_indices: grouped sample indices by class
...     @param smoothing: integer, additive smoothing parameter
...     @return: dictionary, with class as key, corresponding 
...              conditional probability P(feature|class) vector   
...              as value
...     """
...     likelihood = {}
...     for label, indices in label_indices.items():
...         likelihood[label] = features[indices, :].sum(axis=0) 
...                                + smoothing
...         total_count = len(indices)
...         likelihood[label] = likelihood[label] / 
...                                 (total_count + 2 * smoothing)
...     return likelihood 
```

我们在这里将`smoothing`值设置为 1，也可以是 0 表示不平滑，或者任何其他正值，只要达到更高的分类性能即可:

```py
>>> smoothing = 1
>>> likelihood = get_likelihood(X_train, label_indices, smoothing)
>>> print('Likelihood:\n', likelihood)
Likelihood:
 {'Y': array([0.4, 0.6, 0.4]), 'N': array([0.33333333, 0.33333333, 0.66666667])} 
```

如果你发现这些令人困惑，请随意查看*图 2.7* 来刷新你的记忆:

<figure class="mediaobject">![](../Images/B16326_02_10.png)</figure>

图 2.7:计算先验和可能性的简单例子

准备好先验和可能性后，我们现在可以计算测试/新样本的后验概率:

```py
>>> def get_posterior(X, prior, likelihood):
...     """
...     Compute posterior of testing samples, based on prior and 
...     likelihood
...     @param X: testing samples
...     @param prior: dictionary, with class label as key, 
...                   corresponding prior as the value
...     @param likelihood: dictionary, with class label as key, 
...                        corresponding conditional probability
...                            vector as value
...     @return: dictionary, with class label as key, corresponding 
...              posterior as value
...     """
...     posteriors = []
...     for x in X:
...         # posterior is proportional to prior * likelihood
...         posterior = prior.copy()
...         for label, likelihood_label in likelihood.items():
...             for index, bool_value in enumerate(x):
...                 posterior[label] *= likelihood_label[index] if 
...                   bool_value else (1 - likelihood_label[index])
...         # normalize so that all sums up to 1
...         sum_posterior = sum(posterior.values())
...         for label in posterior:
...             if posterior[label] == float('inf'):
...                 posterior[label] = 1.0
...             else:
...                 posterior[label] /= sum_posterior
...         posteriors.append(posterior.copy())
...     return posteriors 
```

现在，让我们使用这个预测函数来预测我们的一个样本测试集的类别:

```py
>>> posterior = get_posterior(X_test, prior, likelihood)
>>> print('Posterior:\n', posterior)
Posterior:
 [{'Y': 0.9210360075805433, 'N': 0.07896399241945673}] 
```

这正是我们以前得到的。我们已经从零开始成功开发了朴素贝叶斯，现在我们可以使用`scikit-learn`继续实现。

## 用 scikit-learn 实现朴素贝叶斯

从头开始编码并实现自己的解决方案是学习机器学习模型的最佳方式。当然可以直接使用`BernoulliNB`模块([https://sci kit-learn . org/stable/modules/generated/sklearn . naive _ Bayes)走捷径。BernoulliNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html))来自 scikit-learn API:

```py
>>> from sklearn.naive_bayes import BernoulliNB 
```

让我们用`1.0`的平滑因子(在`scikit-learn`中指定为`alpha`)和从训练集(在`scikit-learn`中指定为`fit_prior=True`中学习的`prior`初始化一个模型:

```py
>>> clf = BernoulliNB(alpha=1.0, fit_prior=True) 
```

为了用`fit`方法训练朴素贝叶斯分类器，我们使用下面一行代码:

```py
>>> clf.fit(X_train, Y_train) 
```

为了使用`predict_proba`方法获得预测概率结果，我们使用以下代码行:

```py
>>> pred_prob = clf.predict_proba(X_test)
>>> print('[scikit-learn] Predicted probabilities:\n', pred_prob)
[scikit-learn] Predicted probabilities:
 [[0.07896399 0.92103601]] 
```

最后，我们通过`predict`方法直接获取预测类(0.5 为默认阈值，如果类`Y`的预测概率大于 0.5，则分配类`Y`；否则，使用`N`):

```py
>>> pred = clf.predict(X_test)
>>> print('[scikit-learn] Prediction:', pred)
[scikit-learn] Prediction: ['Y'] 
```

使用 scikit-learn 的预测结果与我们使用自己的解决方案得到的结果一致。既然我们已经实现了从头开始和使用`scikit-learn`的算法，为什么不用它来解决电影推荐问题呢？

# 用朴素贝叶斯构建电影推荐系统

在玩具示例之后，现在是时候使用真实数据集构建电影推荐器(或者更具体地说，电影偏好分类器)了。我们在此使用电影分级数据集([https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/))。电影分级数据是由 GroupLens 研究小组从 MovieLens 网站([http://movielens.org](http://movielens.org))收集的。

为了演示的目的，我们将以 ml-latest-small(从以下链接下载:[http://files . group lens . org/datasets/movielens/ml-latest-small . zip](http://files.grouplens.org/datasets/movielens/ml-latest-small.zip )of ml-latest-small . zip(大小:1 MB))为例。它有大约 10 万个评级，从 1 到 5 不等，由 6040 名用户对 3706 部电影给出(最近一次更新是 2018 年 9 月)。

解压`ml-1m.zip`文件，会看到以下四个文件:

*   `movies.dat`:包含电影 ID::Title::流派格式的电影信息。
*   `ratings.dat`:包含 UserID::MovieID::Rating::Timestamp 格式的用户电影分级。在本章中，我们将只使用该文件中的数据。
*   `users.dat`:包含用户标识::性别::年龄::职业::邮政编码格式的用户信息。
*   `README`

让我们尝试根据用户对其他电影的评分来确定用户是否喜欢某部电影(同样，评分从 1 到 5)。

首先，我们导入所有必要的模块和变量:

```py
>>> import numpy as np
>>> from collections import defaultdict
>>> data_path = 'ml-1m/ratings.dat'
>>> n_users = 6040
>>> n_movies = 3706 
```

然后，我们开发以下函数来从`ratings.dat`加载评级数据:

```py
>>> def load_rating_data(data_path, n_users, n_movies):
...     """
...     Load rating data from file and also return the number of 
...         ratings for each movie and movie_id index mapping
...     @param data_path: path of the rating data file
...     @param n_users: number of users
...     @param n_movies: number of movies that have ratings
...     @return: rating data in the numpy array of [user, movie]; 
...              movie_n_rating, {movie_id: number of ratings};
...              movie_id_mapping, {movie_id: column index in 
...                 rating data}
...     """
...     data = np.zeros([n_users, n_movies], dtype=np.float32)
...     movie_id_mapping = {}
...     movie_n_rating = defaultdict(int)
...     with open(data_path, 'r') as file:
...         for line in file.readlines()[1:]:
...             user_id, movie_id, rating, _ = line.split("::")
...             user_id = int(user_id) - 1
...             if movie_id not in movie_id_mapping:
...                 movie_id_mapping[movie_id] = 
...                              len(movie_id_mapping)
...             rating = int(rating)
...             data[user_id, movie_id_mapping[movie_id]] = rating
...             if rating > 0:
...                 movie_n_rating[movie_id] += 1
...     return data, movie_n_rating, movie_id_mapping 
```

然后我们使用这个函数加载数据:

```py
>>> data, movie_n_rating, movie_id_mapping = 
...     load_rating_data(data_path, n_users, n_movies) 
```

总是建议分析数据分布。我们执行以下操作:

```py
>>> def display_distribution(data):
...     values, counts = np.unique(data, return_counts=True)
...     for value, count in zip(values, counts):
...         print(f'Number of rating {int(value)}: {count}')
>>> display_distribution(data)
Number of rating 0: 21384032
Number of rating 1: 56174
Number of rating 2: 107557
Number of rating 3: 261197
Number of rating 4: 348971
Number of rating 5: 226309 
```

如你所见，大多数收视率是未知的；对于已知的评级，35%的评级为 4，其次是 26%的评级为 3，23%的评级为 5，然后分别是 11%和 6%的评级为 2 和 1。

由于大多数收视率未知，我们将收视率最高的电影作为目标电影:

```py
>>> movie_id_most, n_rating_most = sorted(movie_n_rating.items(),
...     key=lambda d: d[1], reverse=True)[0]
>>> print(f'Movie ID {movie_id_most} has {n_rating_most} ratings.')
Movie ID 2858 has 3428 ratings. 
```

ID 2858 的电影是目标电影，其余电影的收视率都是信号。我们据此构建数据集:

```py
>>> X_raw = np.delete(data, movie_id_mapping[movie_id_most], 
...                   axis=1)
>>> Y_raw = data[:, movie_id_mapping[movie_id_most]] 
```

我们丢弃电影 ID 2858 中没有评级的样本:

```py
>>> X = X_raw[Y_raw > 0]
>>> Y = Y_raw[Y_raw > 0]
>>> print('Shape of X:', X.shape)
Shape of X: (3428, 3705)
>>> print('Shape of Y:', Y.shape)
Shape of Y: (3428,) 
```

我们再来看看目标电影收视率的分布情况:

```py
>>> display_distribution(Y)
Number of rating 1: 83
Number of rating 2: 134
Number of rating 3: 358
Number of rating 4: 890
Number of rating 5: 1963 
```

我们可以将评分大于 3 的电影视为受欢迎(被推荐):

```py
>>> recommend = 3
>>> Y[Y <= recommend] = 0
>>> Y[Y > recommend] = 1
>>> n_pos = (Y == 1).sum()
>>> n_neg = (Y == 0).sum()
>>> print(f'{n_pos} positive samples and {n_neg} negative 
...       samples.')
2853 positive samples and 575 negative samples. 
```

作为解决分类问题的经验法则，我们需要时刻分析标签分布，看数据集有多平衡(或不平衡)。

接下来，为了综合评估我们的分类器的性能，我们可以将数据集随机分成两组，分别模拟学习数据和预测数据的训练集和测试集。通常，原始数据集包含在测试分割中的比例可以是 20%、25%、33.3%或 40%。我们使用`scikit-learn`中的`train_test_split`函数进行随机分割，并保留每个类别的样本百分比:

```py
>>> from sklearn.model_selection import train_test_split
>>> X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
...     test_size=0.2, random_state=42) 
```

在实验和探索过程中分配一个固定的`random_state`(例如`42`)是一个很好的做法，以保证每次程序运行时生成相同的训练和测试集。这使我们能够确保分类器在固定的数据集上运行良好，然后我们再引入随机性并进一步处理。

我们检查培训和测试规模如下:

```py
>>> print(len(Y_train), len(Y_test))
2742 686 
```

`train_test_split`函数的另一个好处是，生成的训练集和测试集将具有相同的类比率。

接下来，我们在训练集上训练一个朴素贝叶斯模型。您可能会注意到输入特征的值是从 0 到 5，而不是我们的玩具示例中的 0 或 1。因此，我们使用`MultinomialNB`模块([https://sci kit-learn . org/stable/modules/generated/sklearn . naive _ Bayes。MultinomialNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html))而不是`BernoulliNB`模块，因为`MultinomialNB`可以使用整数功能。我们导入模块，用平滑因子`1.0`和从训练集中学习的`prior`初始化模型，并根据训练集训练该模型，如下所示:

```py
>>> from sklearn.naive_bayes import MultinomialNB
>>> clf = MultinomialNB(alpha=1.0, fit_prior=True)
>>> clf.fit(X_train, Y_train) 
```

然后，我们使用训练好的模型对测试集进行预测。我们得到如下预测概率:

```py
>>> prediction_prob = clf.predict_proba(X_test)
>>> print(prediction_prob[0:10])
[[7.50487439e-23 1.00000000e+00]
 [1.01806208e-01 8.98193792e-01]
 [3.57740570e-10 1.00000000e+00]
 [1.00000000e+00 2.94095407e-16]
 [1.00000000e+00 2.49760836e-25]
 [7.62630220e-01 2.37369780e-01]
 [3.47479627e-05 9.99965252e-01]
 [2.66075292e-11 1.00000000e+00]
 [5.88493563e-10 9.99999999e-01]
 [9.71326867e-09 9.99999990e-01]] 
```

我们得到预测的类如下:

```py
>>> prediction = clf.predict(X_test)
>>> print(prediction[:10])
[1\. 1\. 1\. 0\. 0\. 0\. 1\. 1\. 1\. 1.] 
```

最后，我们用分类精度来评估模型的性能，分类精度是正确预测的比例:

```py
>>> accuracy = clf.score(X_test, Y_test)
>>> print(f'The accuracy is: {accuracy*100:.1f}%')
The accuracy is: 71.6% 
```

分类的准确率在 72%左右，也就是说我们刚刚开发的朴素贝叶斯分类器能够正确的向 72%左右的用户推荐电影。这还不错，因为我们只从电影分级数据中提取了用户-电影关系，而大多数分级都是未知的。理想情况下，我们还可以利用文件`movies.dat`中的电影类型信息，以及文件`users.dat`中的用户人口统计(性别、年龄、职业和邮政编码)信息。显然，相似类型的电影往往会吸引相似的用户，相似人口统计的用户很可能有相似的电影偏好。

到目前为止，我们已经深入研究了第一个机器学习分类器，并通过预测精度评估了它的性能。还有其他分类指标吗？让我们在下一节看到。

# 评估分类性能

除了准确性之外，还有几个我们可以用来获得更多洞察力和避免阶级不平衡影响的指标。这些措施如下:

*   混淆矩阵
*   精确
*   回忆
*   F1 分数
*   曲线下面积

一个**混淆矩阵**通过预测值和真实值总结测试实例，呈现为一个列联表:

<figure class="mediaobject">![](../Images/B16326_02_11.png)</figure>

表 2.3:混淆矩阵的列联表

为了说明这一点，我们可以计算朴素贝叶斯分类器的混淆矩阵。我们使用来自`scikit-learn`的`confusion_matrix`函数来计算它，但是我们自己编码它非常容易:

```py
>>> from sklearn.metrics import confusion_matrix
>>> print(confusion_matrix(Y_test, prediction, labels=[0, 1]))
[[ 60  47]
 [148 431]] 
```

从产生的混淆矩阵中可以看出，有 47 个假阳性案例(模型将不喜欢误解为喜欢电影)，148 个假阴性案例(未能检测到喜欢电影)。因此，分类精度只是所有真实案例的比例:

<figure class="mediaobject">![](../Images/B16326_02_025.png)</figure>

**Precision** 测量正确的正向呼叫的分数，在我们的例子中是![](../Images/B16326_02_026.png)和![](../Images/B16326_02_027.png)。

**回忆**，另一方面测量正确识别的真阳性的比例，在我们的例子中是![](../Images/B16326_02_028.png)和![](../Images/B16326_02_029.png)。召回也称为**真阳性率**。

**f1 得分**综合了的精度和召回率，并将等同于它们的**调和平均值** : ![](../Images/B16326_02_030.png)。我们倾向于将 f1 的分数看得比精确或回忆更重要。

让我们使用从`scikit-learn`开始的相应函数来计算这三个测量值，如下所示:

```py
>>> from sklearn.metrics import precision_score, recall_score, f1_score
>>> precision_score(Y_test, prediction, pos_label=1) 
0.9016736401673641 
>>> recall_score(Y_test, prediction, pos_label=1) 
0.7443868739205527 
>>> f1_score(Y_test, prediction, pos_label=1) 
0.815515610217597 
```

另一方面，消极(不喜欢)类也可以被视为积极的，这取决于上下文。例如，将`0`类指定为`pos_label`，我们有以下内容:

```py
>>> f1_score(Y_test, prediction, pos_label=0) 
0.38095238095238093 
```

要获得每个类的精度、召回率和 f1 分数，一个更快的方法是调用`classification_report`函数，而不是像前面所示的那样用尽三个函数调用中的所有类标签:

```py
>>> from sklearn.metrics import classification_report
>>> report = classification_report(Y_test, prediction)
>>> print(report)
              precision    recall  f1-score   support
         0.0       0.29      0.56      0.38       107
         1.0       0.90      0.74      0.82       579
   micro avg       0.72      0.72      0.72       686
   macro avg       0.60      0.65      0.60       686
weighted avg       0.81      0.72      0.75       686 
```

这里，`weighted avg`是按类的比例加权平均。

分类报告提供了分类器如何在每个类上执行的全面视图。因此，它在不平衡分类中是有用的，在不平衡分类中，我们可以通过简单地将每个样本分类为优势类来轻松获得高精度，而少数类的精度、召回率和 f1 分数测量值将显著较低。

精度、召回率和 f1 分数也适用于**多类**分类，我们可以简单地将我们感兴趣的类视为正例，将任何其他类视为负例。

在调整二进制分类器的过程中(即，尝试不同的超参数组合，例如，我们的朴素贝叶斯分类器中的平滑因子)，如果有一组参数可以同时获得最高的平均和类个体 f1 分数，那将是完美的。然而，通常情况并非如此。有时，一个模型的平均 f1 分数比另一个模型高，但特定类别的 f1 分数明显较低；有时，两种车型的平均 f1 成绩相同，但一种车型的 f1 成绩在一个级别上较高，而在另一个级别上较低。在这样的情况下，如何判断哪个模型效果更好？**接收机工作特性** ( **ROC** )的曲线 ( **AUC** )下的**区域是在二进制分类中经常使用的合并测量。**

ROC 曲线是真实阳性率与假阳性率在各种概率阈值(范围从 0 到 1)下的曲线图。对于测试样本，如果正类的概率大于阈值，则分配正类；否则，我们使用负类。概括地说，真阳性率相当于回忆，假阳性率是被错误识别为阳性的阴性的比例。让我们编码并展示我们模型的 ROC 曲线(在 0.0、0.1、0.2、…、1.0 的阈值下):

```py
>>> pos_prob = prediction_prob[:, 1]
>>> thresholds = np.arange(0.0, 1.1, 0.05)
>>> true_pos, false_pos = [0]*len(thresholds), [0]*len(thresholds)
>>> for pred, y in zip(pos_prob, Y_test):
...     for i, threshold in enumerate(thresholds):
...         if pred >= threshold:
...            # if truth and prediction are both 1
...             if y == 1:
...                 true_pos[i] += 1
...            # if truth is 0 while prediction is 1
...             else:
...                 false_pos[i] += 1
...         else:
...             break 
```

然后，让我们计算所有阈值设置的真阳性和假阳性率(记住，有`516.0`阳性检测样本和`1191`阴性样本):

```py
>>> n_pos_test = (Y_test == 1).sum()
>>> n_neg_test = (Y_test == 0).sum()
>>> true_pos_rate = [tp / n_pos_test for tp in true_pos]
>>> false_pos_rate = [fp / n_neg_test for fp in false_pos] 
```

现在，我们可以用`Matplotlib`绘制 ROC 曲线:

```py
>>> import matplotlib.pyplot as plt
>>> plt.figure()
>>> lw = 2
>>> plt.plot(false_pos_rate, true_pos_rate, 
...          color='darkorange', lw=lw)
>>> plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
>>> plt.xlim([0.0, 1.0])
>>> plt.ylim([0.0, 1.05])
>>> plt.xlabel('False Positive Rate')
>>> plt.ylabel('True Positive Rate')
>>> plt.title('Receiver Operating Characteristic')
>>> plt.legend(loc="lower right")
>>> plt.show() 
```

生成的 ROC 曲线见*图 2.8* :

<figure class="mediaobject">![](../Images/B16326_02_12.png)</figure>

图 2.8: ROC 曲线

在图中，虚线是表示随机猜测的基线，其中真阳性率随着假阳性率线性增加；其 AUC 为 0.5。实线是我们模型的 ROC 图，其 AUC 略小于 1。在完美的情况下，真阳性样本的概率为 1，因此 ROC 从 100%真阳性和 0%假阳性的点开始。这样完美曲线的 AUC 是 1。为了计算我们模型的精确 AUC，我们可以借助`scikit-learn`的`roc_auc_score`功能:

```py
>>> from sklearn.metrics import roc_auc_score
>>> roc_auc_score(Y_test, pos_prob)
0.6857375752586637 
```

什么样的 AUC 值可以得出分类器好的结论？可惜，没有这样的“神奇”数字。我们使用以下经验法则作为一般指南:AUC 达到 0.7 到 0.8 的分类模型被认为是可接受的，0.8 到 0.9 是很好的，任何高于 0.9 的都是极好的。同样，在我们的例子中，我们只使用非常稀疏的电影分级数据。因此，0.69 的 AUC 实际上是可以接受的。

您已经学习了几个分类指标，我们将在下一节中探讨如何正确测量它们以及如何微调我们的模型。

# 使用交叉验证调整模型

我们可以简单地避免采用来自一个固定测试集的分类结果，这是我们之前在实验中做过的。相反，我们通常应用 **k 倍交叉验证**技术来评估模型在实践中的表现。

在 k 重交叉验证设置中，首先将原始数据随机分成 *k* 个大小相等的子集，其中类比例往往被保留。这些 *k* 子集中的每一个随后被连续保留作为用于评估模型的测试集。在每次试验中，其余的 *k* -1 子集(不包括单重保持)形成用于驾驶模型的训练集。最后，计算所有 *k* 试验的平均性能，以生成总体结果:

<figure class="mediaobject">![](../Images/B16326_02_13.png)</figure>

图 2.9:三重交叉验证图

统计上，k 倍交叉验证的平均性能是对模型总体表现的更好估计。给定与机器学习模型和/或数据预处理算法相关的不同参数集，或者甚至两个或更多不同的模型，模型调整和/或模型选择的目标是选择分类器的一组参数，从而实现最佳平均性能。考虑到这些概念，我们现在可以开始调整我们的朴素贝叶斯分类器，结合交叉验证和 ROC 测量的 AUC。

在 k 倍交叉验证中，k 通常设置为 3、5 或 10。如果训练规模较小，建议使用较大的 *k* (5 或 10)，以确保每个折叠中有足够的训练样本。如果训练规模较大，较小的值(如 3 或 4)也可以，因为较高的 *k* 将导致在大数据集上训练的计算成本更高。

我们将使用来自`scikit-learn`的`StratifiedKFold`类的`split()`方法将数据划分为保留类分布的块:

```py
>>> from sklearn.model_selection import StratifiedKFold
>>> k = 5
>>> k_fold = StratifiedKFold(n_splits=k, random_state=42) 
```

初始化 5 倍发生器后，我们选择探索以下参数的以下值:

*   `alpha`:表示平滑因子，即每个特征的初始值。
*   `fit_prior`:表示是否使用事先定制好的训练数据。

我们从以下选项开始:

```py
>>> smoothing_factor_option = [1, 2, 3, 4, 5, 6]
>>> fit_prior_option = [True, False]
>>> auc_record = {} 
```

然后，对于由`k_fold`对象的`split()`方法生成的每个折叠，我们用上述参数组合之一重复分类器初始化、训练和预测的过程，并记录结果的 AUC:

```py
>>> for train_indices, test_indices in k_fold.split(X, Y):
...     X_train, X_test = X[train_indices], X[test_indices]
...     Y_train, Y_test = Y[train_indices], Y[test_indices]
...     for alpha in smoothing_factor_option:
...         if alpha not in auc_record:
...             auc_record[alpha] = {}
...         for fit_prior in fit_prior_option:
...             clf = MultinomialNB(alpha=alpha, 
...                                 fit_prior=fit_prior)
...             clf.fit(X_train, Y_train)
...             prediction_prob = clf.predict_proba(X_test)
...             pos_prob = prediction_prob[:, 1]
...             auc = roc_auc_score(Y_test, pos_prob)
...             auc_record[alpha][fit_prior] = auc + 
...                        auc_record[alpha].get(fit_prior, 0.0) 
```

最后，我们给出如下结果:

```py
>>> for smoothing, smoothing_record in auc_record.items():
...     for fit_prior, auc in smoothing_record.items():
...         print(f'    {smoothing}        {fit_prior}    
...               {auc/k:.5f}')
smoothing  fit prior  auc
    1        True    0.65647
    1        False    0.65708
    2        True    0.65795
    2        False    0.65823
    3        True    0.65740
    3        False    0.65801
    4        True    0.65808
    4        False    0.65795
    5        True    0.65814
    5        False    0.65694
    6        True    0.65663
    6        False    0.65719 
```

(`2`、`False`)设置在`0.65823`启用最佳平均 AUC。

最后，我们用最佳的一组超参数(`2`、`False`)重新训练模型，并计算 AUC:

```py
>>> clf = MultinomialNB(alpha=2.0, fit_prior=False)
>>> clf.fit(X_train, Y_train)
>>> pos_prob = clf.predict_proba(X_test)[:, 1]
>>> print('AUC with the best model:', roc_auc_score(Y_test,
...       pos_prob))
AUC with the best model:  0.6862056720417091 
```

通过微调模型获得了`0.686`的 AUC。一般来说，使用交叉验证调整模型超参数是提高学习性能和减少过度拟合的最有效方法之一。

# 摘要

在本章中，您学习了机器学习分类的基本和重要概念，包括分类类型、分类性能评估、交叉验证和模型调优。您还了解了简单而强大的分类器朴素贝叶斯。我们用几个例子深入探讨了朴素贝叶斯的机制和实现，其中最重要的是电影推荐项目。

二元分类是本章的主要话题，多类分类将是下一章的主题。具体来说，我们将讨论用于图像分类的支持向量机。

# 锻炼

1.  如前所述，我们仅从大多数评分未知的电影评分数据中提取用户-电影关系。你还能利用文件`movies.dat`和`users.dat`中的数据吗？
2.  熟能生巧——加深理解的另一个伟大项目可能是心脏病分类。数据集可以在[https://www.kaggle.com/ronitf/heart-disease-uci](https://www.kaggle.com/ronitf/heart-disease-uci)直接下载，也可以在[https://archive.ics.uci.edu/ml/datasets/Heart+Disease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)从原页面下载。
3.  不要忘记使用本章中学习的技巧来微调从练习 2 中获得的模型。它达到的最佳 AUC 是多少？

# 参考

为了认可本章中对 MovieLens 数据集的使用，我想引用以下论文:

F.麦克斯韦·哈珀和约瑟夫·康斯坦。2015.电影数据集:*历史和背景*。ACM **互动智能系统交易** ( **TiiS** ) 5、4、第 19 条(2015 年 12 月)，19 页。DOI =[http://dx.doi.org/10.1145/2827872](http://dx.doi.org/10.1145/2827872)
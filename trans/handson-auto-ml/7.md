# 深入学习

**人工智能** ( **AI** )的下一步更多的是自动化。在这本书里，我们已经介绍了**自动机器学习** ( **AutoML** )的一些基础知识。还有一个人工智能领域刚刚开始出现在多个用例中，并且需要极其自动化地应用。人工智能领域的这一领域被称为**深度学习** ( **DL** )。DL 正处于机器能做什么的临界点。它可以比**机器学习** ( **ML** )做得更多，更轻松，精度更好。DL 算法可以自己学习数据集的关键特征，可以调整权重以创建更好的模型，等等。下行链路网络的应用非常广泛。

随着深度学习的出现，图像、语音和视频识别领域的研究人员和实践者正在看到一些可操作的结果。它帮助人工智能接近了成为机器人大脑的最初目标。它还可以在不断增长的**物联网** ( **物联网**)领域发挥作用。对于企业来说，DL 已经在简化客户服务和协助许多人力密集型任务的自动化方面发挥了重要作用。到目前为止，你可能已经遇到了由 DL 驱动的机器人试图回答你的产品查询或帮助你预订你最喜欢的比萨饼订单。

DL 也在医药和医疗保健领域释放发展。如果机器开始通过阅读 x 光和核磁共振扫描来诊断你的疾病，不要感到惊讶。预计 DL 将解决人类拥有的许多谜团，并自动化以前不可能完成的大量手动任务。很有趣，不是吗？让我们揭开 DL 的一些深层秘密。

在本章中，我们将了解:

*   前馈神经网络
*   自动编码器
*   深度卷积网络

在这一章中，我们将尝试举例说明 DL 的一些基本概念。我们这里的重点不是阻止你用方程、数学公式和导数来描述。虽然它们是基本概念，但它们可能是压倒性的。相反，我们将以说明性的方式向您介绍这些概念，并帮助您编写第一个 DL 代码。

神经网络是 DL 网络的前身，它们构成了 DL 框架的构件。神经网络背后的基本思想是创建一个模拟我们生物大脑工作的计算系统。

# 技术要求

所有代码示例都可以在 GitHub 的`Chapter 07`文件夹中找到。

# 神经网络综述

神经网络的最佳定义是由第一批神经计算机科学家之一的发明家罗伯特·赫克特-尼尔森博士在 1989 年 2 月人工智能专家莫林·考迪尔的《神经网络入门:第一部分》中提供的:

...a computing system made up of a number of simple, highly interconnected processing elements, which process information by their dynamic state response to external inputs.

神经网络的基本构件是神经元，它们被组织在不同的层中。分层架构将每一层的神经元连接到下一层的神经元。神经网络至少有三层。输入层连接到一个或多个隐藏层，其中通过**加权**链接系统建立连接。最后一个隐藏层连接到产生任务结果的输出层。

下图说明了一个三层神经网络:

![](Images/8667f4c1-7d6a-4397-a91e-e022fbc767c3.png)

这个网络也被称为全连接人工神经网络或**前馈神经网络** ( **FNN** )。还有一种神经网络架构，将结果传播回去学习和调整权重，称为**前馈神经网络**，反向传播，如下图所示:

![](Images/934bc4ce-746b-4ec4-b411-3e9918ffc951.png)

让我们以综合的方式检查神经网络的每个单元。

# 神经元

神经元是神经网络的基本单位。每个神经元都有多个输入、一个处理器和一个输出。神经元的处理是从累加所有输入开始的，根据激活函数，它会发出一个信号，传播给其他神经元或作为输出信号。这有助于神经元学习。神经元最基本的形式被称为**感知器**。感知器的二进制输出为 0 或 1。

典型的神经元如下所示:

![](Images/5214a738-00ed-4207-8e58-64fd8c89fa5a.png)

我们可以看到，神经元有几个输入。对于每个输入连接，都有一个与特定连接相关联的权重。当神经元被激活时，状态是通过将输入与相应连接的权重相乘来计算的。数学上，它可以用下面的函数来表示:

![](Images/5829c6c1-8a70-4533-9caa-ad660e04b089.png)

其中 *x <sub class="calibre54">i</sub>* 为包含偏差的输入值。

偏差是一个额外的输入，一个神经元。偏差有自己的连接权重，偏差的值总是 1。这是为了确保即使没有输入，即输入值为 0，神经元也会激活。

一旦计算出状态，该值就通过一个激活函数来规范化结果。

# 激活功能

激活函数用于使用加权输入的先验线性组合产生非线性决策。我们将讨论主要用于 DL 应用程序的四种不同类型的激活函数:

*   步骤
*   乙状结肠的
*   ReLU
*   双曲正切

# 阶跃函数

在阶跃函数中，如果输入加权和的值大于某个阈值，则神经元被激活。两个选项如下:

![](Images/7dc5f438-9c3b-4ad0-b2fc-434dfdb13585.png)

如果 *x* ，即输入值的加权和大于或等于 0，则激活 1，否则激活 0。下图说明了阶跃函数:

![](Images/76351d74-8466-4095-81ae-3436e3e69999.png)

下一个广泛使用的激活函数是 **sigmoid** 函数。

# sigmoid 函数

sigmoid 函数定义为:

![](Images/1e81ffa6-1c5a-4d48-b88e-d01d4047f2ef.png)

这里， *x* 是输入值的加权和的值。我们已经在逻辑回归中看到了这个函数。当 *x* 低于零度时，它下降，高于零度时，它接近于 1。与阶跃函数不同，它是一个非线性激活函数。它主要用于神经网络的输出层，当我们在分类任务中试图预测概率时。下图说明了 sigmoid 函数:

![](Images/420ad101-164d-47b0-9970-640614291886.png)

我们讨论的下一个激活函数是 **ReLU** ，它广泛用于神经网络的隐藏层。

# ReLU 函数

研究人员发现，使用**整流线性单元** ( **ReLU** )函数的神经网络比其他非线性函数(如 sigmoid 和 tanh)训练得更快，并且精度没有显著下降。所以， **ReLU 功能**是最重要的激活功能之一。如果 *x* 为正，则给出 *x* 的输出，否则为 0。

其定义如下:

*A(x) =最大值(0，x)*

ReLU 函数如下图所示:

![](Images/4dcd75ac-2556-41d9-a36f-8d520dfc0932.png)

ReLU is a non-linear function and the combination of ReLU functions are also non-linear. The range of ReLU is from 0 to infinity.

接下来，我们讨论 tanh 函数，它与 sigmoid 函数非常相似，但这里的值低于 0。

# 正切函数

tanh 函数也被称为**双曲正切函数**。值从-1 到+1。

其数学公式如下:

![](Images/711193e2-5102-4f1c-8a60-c3643e86b109.png)

tanh 函数的输出以零为中心。它也是一个非线性函数，因此可以用于堆叠不同的层。tanh 功能如下图所示:

![](Images/dda21853-a069-4122-89cd-234e405c5b93.png)

现在我们已经对什么是神经网络、神经网络的结构及其不同的组成部分有了一些了解，让我们使用 Keras 创建一个前馈神经网络。

# 一种基于 Keras 的前馈神经网络

Keras 是一个 DL 库，最初是基于 Python 构建的，运行在 TensorFlow 或 antao 之上。开发它是为了让 DL 实现更快:

1.  我们在您的操作系统的命令提示符下使用以下命令调用`install keras`:

```py
pip install keras
```

2.  我们从导入`numpy`和`pandas`库进行数据操作开始。此外，我们设置了一个`seed`，允许我们重现脚本的结果:

```py
import numpy as np
import pandas as pd
numpy.random.seed(8)
```

3.  接下来，分别从`keras.models`和`keras.layers`导入序列模型和密集层。Keras 模型被定义为一系列层。顺序构造允许用户配置和添加层。密集层允许用户构建完全连接的网络:

```py
from keras.models import Sequential
from keras.layers import Dense
```

4.  然后加载`HR`磨损数据集，该数据集有 14，999 行和 10 列。`salary`和`sales`属性是一次性编码的，由 Keras 用于构建 DL 模型:

```py
#load hrdataset
hr_data = pd.read_csv('data/hr.csv', header=0)
# split into input (X) and output (Y) variables
data_trnsf = pd.get_dummies(hr_data, columns =['salary', 'sales'])
data_trnsf.columns
X = data_trnsf.drop('left', axis=1)
X.columns
```

以下是前面代码的输出:

![](Images/e08d03de-0749-4c9a-af6e-9d1cebaafac2.png)

5.  然后以 70:30 的比例分割数据集，以训练和测试模型:

```py
from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, data_trnsf.left, test_size=0.3, random_state=42)
```

6.  接下来，我们开始创建一个完全连接的神经网络，使用三层定义一个顺序模型。第一层是输入层。在这一层中，我们使用`input_dim`参数、神经元数量和激活函数来定义输入特征的数量。我们将预处理数据集`X_train`中的 20 个输入要素的`input_dim`参数设置为`20`。第一层的神经元数量被指定为`12`。目标是预测员工流失，这是一个二元分类问题。因此，我们在前两层使用整流器`activation`功能将非线性引入模型并激活神经元。第二层为隐藏层，配置`10`神经元。第三层是输出层，有一个神经元具有`sigmoid`激活功能。这确保了二进制分类任务的输出介于 0 和 1 之间:

```py
# create model
model = Sequential()
model.add(Dense(12, input_dim=20, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
```

7.  一旦我们配置了模型，下一步就是编译模型。在编译过程中，我们指定了`loss`功能、`optimizer`和`metrics`。由于我们处理的是两类问题，我们将`loss`功能指定为`binary_crossentropy`。我们声明`adam`是用于本练习的优化器。优化算法的选择对模型的良好性能至关重要。`adam`优化器是随机梯度下降算法的扩展，是广泛使用的优化器:

```py
# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
```

8.  接下来，我们使用`fit`方法将模型拟合到训练集。纪元用于指定向前和向后传递的次数。`batch_size`参数用于声明每个纪元中要使用的训练示例的数量。在我们的示例中，我们将`epochs`的编号指定为`100`，其中`batch_size`为`10`:

```py
# Fit the model
X_train = np.array(X_train)
model.fit(X_train, Y_train, epochs=100, batch_size=10)
```

9.  一旦我们执行了前面的代码片段，执行就开始了，我们可以看到进度，如下图所示。一旦达到模型的`fit`方法中指定的时期数，处理停止:

![](Images/470d1381-f528-4cad-8e29-72db9136cc3b.png)

10.  最后一步是评估模型。我们在前面的评估指标中指定了准确性。在最后一步，我们使用以下代码片段检索模型的准确性:

```py
# evaluate the model
scores = model.evaluate(X_train, Y_train)
print("%s: %.4f%%" % (model.metrics_names[1], scores[1]*100))

X_test = np.array(X_test)

scores = model.evaluate(X_test, Y_test)
print("%s: %.4f%%" % (model.metrics_names[1], scores[1]*100))
```

下面的结果显示模型精度为`93.56%`，测试精度为`93.20%`，这是一个相当不错的结果。我们可能会得到与根据种子描述的结果略有不同的结果:

![](Images/8a48957c-7889-4040-a8cb-303e551d1e9d.png)

Data scaling is often required to obtain good results from neural networks.

在下一节中，我们将讨论自动编码器，这是一种无监督的 DL 技术，广泛用于非线性降维。

# 自动编码器

自动编码器是一种可用于无监督学习的 DL。它类似于我们之前研究的其他降维技术，如**主成分分析** ( **主成分分析**)。然而，PCA 使用线性变换将数据从较高维度投影到较低维度，但是自动编码器使用非线性变换。

在自动编码器中，其结构由两部分组成:

*   **编码器**:该部分将输入压缩成较少的元素或比特数。输入被压缩到最大点，称为**潜伏空间**或**瓶颈**。这些压缩位被称为**编码位**。
*   **解码器**:解码器尝试根据编码的位重建输入。如果解码器能够从编码的比特中再现精确的输入，那么我们可以说有一个完美的编码。然而，这是一个理想的案例场景，并不总是发生。重构误差提供了一种测量解码器重构努力和判断自动编码器精度的方法。

现在我们已经对自动编码器的结构有了一些了解，让我们使用下图将其可视化:

![](Images/fcb33330-fa68-49c2-a1a1-cf451dc6ae32.png)

有不同类型的自动编码器，例如:

*   **香草自动编码器**:有两层神经网络架构，一个隐藏层。
*   **稀疏自动编码器**:用于学习数据的稀疏表示。这里，对其损失函数施加约束，以约束自动编码器的重构。
*   **去噪自动编码器**:在这些自动编码器中，引入了部分损坏的输入。这样做是为了防止自动编码器简单地学习输入的结构，并迫使网络发现更健壮的特征来学习输入模式。

异常检测是自动编码器最广泛使用的用例之一。这是一个从已知中发现未知的过程。在异常检测练习中，输入数据总是有一个类，即*已知的*。当自动编码器通过重构输入数据来学习数据模式时，它往往会发现可能是数据异常的未知模式:

1.  与前面的示例一样，这里我们使用以下代码片段导入所需的库:

```py
%matplotlib inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from keras.models import Model, load_model
from keras.layers import Input, Dense
np.random.seed(8)
```

2.  接下来，加载用于使用自动编码器构建异常检测器的数据集。演示使用的数据摘自 1974 年《汽车趋势》美国杂志；它包括 32 辆汽车(1973–74 款)的油耗和汽车设计与性能的 10 个方面。数据集做了一些修改，引入了一些数据异常:

```py
# load autodesign
auto_data = pd.read_csv('data/auto_design.csv')
# split into input (X) and output (Y) variables
X =auto_data.drop('Unnamed: 0', 1)
from sklearn.model_selection import train_test_split
X_train, X_test = train_test_split(X, test_size=0.3, random_state=42)
```

```py
print(X_train)
X_train.shape
```

对于前面的代码，我们得到以下输出:

![](Images/6ca05f73-0941-4cd7-b450-ec9294119ac8.png)

3.  接下来，定义输入维度。由于有 12 个不同的输入特征，并且我们计划使用自动编码器中的所有特征，我们将输入神经元的数量定义为`12`。这嵌入在输入层中，如下面的代码片段所示:

```py
input_dim = X_train.shape[1]
encoding_dim = 12
input_layer = Input(shape=(input_dim, ))
```

4.  接下来，我们创建一个编码器和解码器。编码器中使用了 ReLU 函数，这是一个非线性激活函数。编码层被传递到解码器，在那里它试图重建输入数据模式:

```py
encoded = Dense(encoding_dim, activation='relu')(input_layer)
decoded = Dense(12, activation='linear')(encoded)
```

5.  下面的模型将输入映射到它的重构，这是在解码器层`decoded`中完成的。接下来，使用`compile`方法定义`optimizer`和`loss`功能。`adadelta`优化器使用指数衰减的梯度平均值，是一种高度自适应的学习速率方法。重建是一个线性过程，在解码器中使用线性激活函数来定义。`loss`定义为`mse`，均方误差，我们在[第 2 章](2.html)*Python 机器学习入门*中研究过:

```py
autoencoder = Model(input_layer, decoded)
autoencoder.compile(optimizer='adadelta', loss='mse')
```

6.  接下来，训练数据`X_train`被装入自动编码器。让我们用`4`的`batch_size`为`100`时期训练我们的自动编码器，并观察它是否达到稳定的列车或测试损失值:

```py
X_train = np.array(X_train)
autoencoder.fit(X_train, X_train,epochs=100,batch_size=4)
```

7.  一旦我们执行了前面的代码片段，执行就开始了，我们可以在下面的截图中看到进度。一旦达到模型的`fit`方法中指定的时期数，处理停止:

![](Images/65cd7f68-55fb-4baa-89d7-202026f895ca.png)

8.  一旦模型被拟合，我们通过将相同的`X_train`数据集传递给自动编码器的`predict`方法来预测输入值。接下来，我们计算`mse`值，以了解自动编码器是否能够正确重建数据集，以及重建误差有多大:

```py
predictions = autoencoder.predict(X_train)
mse = np.mean(np.power(X_train - predictions, 2), axis=1)
```

9.  我们可以绘制`mse`来查看重建误差和它无法正确重建的输入数据的索引:

```py
plt.plot(mse)
```

10.  从下图中我们可以观察到，自动编码器无法正确重建数据集的第 16 条<sup class="calibre55">记录。重建误差对于记录来说太高了，这是一种异常。第 13 条<sup class="calibre55">记录也有一个小的重建误差，这可能也是一个异常:</sup></sup>

![](Images/7584622d-faa6-4bf7-abb1-6d2d2c9ed71e.png)

在下一节中，我们将重点介绍**卷积神经网络** ( **CNN** )，它们广泛用于图像处理和图像识别。

# 卷积神经网络

这一部分将集中讨论美国有线电视新闻网的架构。虽然有线电视新闻网是一个可能不会在一章中完全涵盖的话题，但我们将重点关注一个有线电视新闻网可以让您轻松开始使用有线电视新闻网的重要因素。在我们的讨论中，我们将使用 Keras 包，使用包中的样本`MNIST`数据集创建 CNN。

当我们听到有线电视新闻网这个术语时，脑海中浮现的问题是，*为什么是有线电视新闻网？*我们将尝试用一个简短的解释来回答这个问题。

# 为什么是 CNN？

我们在前面的章节中讨论了前馈神经网络。尽管它们功能强大，但它们的主要缺点之一是 FNN 忽略了输入数据的结构。所有输入网络的数据必须首先转换成 1D 数字阵列。然而，对于像图像这样的高维数组，很难处理这种转换。保持图像的结构是至关重要的，因为有很多隐藏的信息存储在里面，这是美国有线电视新闻网进入画面的地方。美国有线电视新闻网在处理图像时会考虑图像的结构。

我们的下一个问题是困难项——卷积。这是什么？

# 什么是卷积？

卷积是一种特殊的数学运算，涉及两个函数`f`和`g`的乘法，以产生一个新的修正函数(`f * g`)。例如，图像(假设函数`f`)与过滤器函数`g`之间的卷积将产生图像的新版本。

我们刚刚讨论了过滤器，所以让我们试着理解什么是过滤器。

# 什么是过滤器？

美国有线电视新闻网使用过滤器来识别图像中的特征，如边缘、线条或拱门。他们在图像中寻找某些重要的模式或特征。过滤器用于搜索图像中的某些特征，并检测图像是否包含这些特征。在图像的不同位置应用滤镜，直到它覆盖整个图像。滤镜在卷积层中形成关键元素，这是有线电视新闻网的一个重要步骤。

美国有线电视新闻网主要有四个不同的层次:

*   卷积层
*   图层继电器
*   汇集层
*   全连接层

我们来讨论卷积层，这是 CNN 的第一个阶段。

# 卷积层

这是在输入图像和我们刚才讨论的滤波器之间进行卷积运算的层。执行此步骤是为了减小图像的整体大小，以便更容易在下一层处理图像。让我们用一个简单的问题来理解这一层的功能，*如何识别狗还是猫？*当我们看到它们时，它会在一秒钟内自然而然地出现。我们不会分析它们的所有特征来确定狗是狗还是猫是猫。

我们识别重要的特征，如它们的眼睛、耳朵或尾巴，然后识别生物。这也是在卷积层中所做的。在这一层中，重要的特征被识别，其余的都被忽略。过滤器在图像中移动，以检测图像中的基本特征。移动过滤器的过程称为**步**。

卷积层的结果然后通过非线性激活函数传递，例如 ReLU 函数。

# ReLU 层

这个额外的步骤被应用于卷积层，以在卷积特征图中引入非线性。我们在前面的章节中学习了 ReLU 函数。图像具有高度非线性的模式。当我们应用卷积时，它有可能变成线性的，因为有像乘法和求和这样的线性运算。因此，非线性激活函数，如 ReLU，被用来保持图像中的非线性。

有线电视新闻网的下一个阶段是汇集层。

# 汇集层

通过应用汇集功能，汇集层进一步减小了要素表示的大小。有不同种类的池功能，如`average`、`min`、`max`。最大池被广泛使用，因为它倾向于为每个步幅保持特征图的`max`值。这类似于卷积层，其中我们有一个滑动窗口，该窗口在特征地图上滑动以找到每个步幅内的`max`值。池层中的窗口大小通常小于卷积层中使用的窗口大小。

然后，合并后的要素地图将展平为 1D 表示，用于完全连接的图层。

# 完全连接的层

在一个 CNN 中可以有多个卷积、ReLU 和池运算。然而，总有最后一个单独的阶段是完全连接的层。全连接层是我们前面讨论过的前馈神经网络。这一步的目的是对`image`数据集进行不同的预测，比如对图像进行分类。

下图展示了美国有线电视新闻网基本架构的最终图片:

![](Images/1c94e938-1321-4b3e-8944-cffdd4b3c3fa.png)

现在我们了解了一些关于有线电视新闻网的基础知识，让我们使用 Keras 创建一个有线电视新闻网。我们将使用喀拉斯本身的`MNIST`数据集。`MNIST`数据集是一个众所周知的书面数字数据集。数据集已经被分成一个训练集和测试集。它有大约 7 万张图片。每幅图像的灰度为 28 * 28。

本节的完整代码可以在本书的代码库中找到。我们将演示重要的代码部分。

我们开始构建一个 Keras DL 模型，通过定义一个顺序模型:

1.  如上所述，顺序方法使我们能够在按顺序执行的其他方法之上添加一层。添加的第一层是由`Conv2D`方法定义的卷积层。由于`MNIST`数据集由 2D 图像组成，我们添加了 2D 卷积层。`kernel_size`参数用于定义滤镜的大小，步长用于定义移动窗口。
2.  喀拉斯没有不同的 ReLU 层。然而，我们可以在卷积层本身定义激活函数。我们为这个任务选择的激活函数是 ReLU。
3.  第三步是使用`MaxPooling2D`方法添加一个最大池层。`pool_size`定义为 2 * 2，汇聚层的步长为 2 * 2。
4.  数据扁平化的第四步是增加`Flatten2D`方法。最后一层是全连接层，其定义类似于前馈神经网络:

```py
#Model Definition
cnn_model = Sequential()
cnn_model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),activation='relu',input_shape=input))
cnn_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
cnn_model.add(Flatten())
cnn_model.add(Dense(1000, activation='relu'))
cnn_model.add(Dense(num_classes, activation='softmax'))
```

5.  下面的代码片段类似于我们看到的其他 Keras 代码。我们首先需要用`loss`函数、`optimizer`和`metrics`编译模型。然后，使用模型拟合方法中的重要参数`batch_size`和`epochs`用训练集拟合模型:

```py
cnn_model.compile(loss=keras.losses.categorical_crossentropy,
 optimizer=keras.optimizers.Adam(),
 metrics=['accuracy'])
 cnn_model.fit(x_train, y_train,
 batch_size=10,
 epochs=10,
 verbose=1,
 validation_data=(x_test, y_test))
```

6.  一旦我们执行了前面的代码，我们需要等待一段时间才能得到结果。由于训练数据集庞大且图像复杂，仅完成 10 个时期就需要大量时间:

![](Images/3ffb8df3-1ad6-4dda-886a-bab54789dc98.png)

7.  训练完成后，我们可以使用以下代码片段来评估模型的准确性:

```py
model_score = cnn_model.evaluate(x_test, y_test, verbose=0)
print('Loss on the test data:', model_score[0])
print('Model accuracy on the test data:', model_score[1])
```

该模型在测试数据上的`0.9875`准确度令人印象深刻，为 98.75%:

![](Images/5d135fcf-8b64-4c96-a34f-f0a74b1e92aa.png)

# 摘要

在这一章中，我们向您介绍了神经网络和深度学习的世界。我们讨论了不同的激活函数、神经网络的结构，并使用 Keras 演示了一个前馈神经网络。

深度学习本身就是一个话题，有几本深度学习的书都有深度聚焦。本章的目的是为您提供一个探索深度学习的开端，因为它是机器学习自动化的下一个前沿。我们见证了自动编码器的降维能力。此外，中枢神经系统具有强大的特征处理机制，是构建未来自动化系统的重要组成部分。

我们将在下一章中结束我们的讨论，在这一章中，我们将回顾到目前为止所涵盖的内容、接下来的步骤以及创建完整的机器学习系统所需的技能。
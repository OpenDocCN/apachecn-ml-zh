# 第十章。生物识别人脸识别

在本章中，我们将介绍以下食谱:

*   从网络摄像头捕捉和处理视频
*   使用哈尔级联构建人脸检测器
*   构建眼睛和鼻子探测器
*   执行主成分分析
*   执行核心主成分分析
*   执行盲源分离
*   利用局部二值模式直方图构建人脸识别器

# 简介

人脸识别是指在给定的图像中识别人的任务。这与人脸检测不同，在人脸检测中，我们在给定的图像中定位人脸。在人脸检测过程中，我们不在乎这个人是谁。我们只是识别图像中包含人脸的区域。因此，在典型的生物特征人脸识别系统中，我们需要确定人脸的位置才能识别它。

人脸识别对人类来说非常容易。我们似乎毫不费力地做到了，而且我们一直都在这样做！我们如何让机器做同样的事情？我们需要了解面部的哪些部位可以用来唯一地识别一个人。我们的大脑有一个内部结构，它似乎对特定的特征做出反应，比如边缘、角落、运动等等。人类视觉皮层将所有这些特征结合成一个连贯的推论。如果我们想让我们的机器准确地识别人脸，我们需要用类似的方式来表述这个问题。我们需要从输入图像中提取特征，并将其转换为有意义的表示。

# 从网络摄像头捕捉和处理视频

我们将在本章中使用网络摄像头来捕获视频数据。让我们看看如何使用 OpenCV-Python 从网络摄像头捕捉视频。

## 怎么做…

1.  新建一个 Python 文件，导入以下包:

    ```
    import cv2
    ```

2.  OpenCV 提供了一个视频捕获对象，我们可以使用它从网络摄像头中捕获图像。`0`输入参数指定网络摄像头的 ID。如果你连接一个 USB 摄像头，那么它会有一个不同的 ID:

    ```
    # Initialize video capture object
    cap = cv2.VideoCapture(0)
    ```

3.  定义使用网络摄像头拍摄的帧的比例因子:

    ```
    # Define the image size scaling factor
    scaling_factor = 0.5
    ```

4.  开始一个无限循环，并保持捕捉帧，直到您按下 *Esc* 键。从网络摄像头读取画面:

    ```
    # Loop until you hit the Esc key
    while True:
        # Capture the current frame
        ret, frame = cap.read()
    ```

5.  调整框架大小是可选的，但在代码中仍然是有用的:

    ```
        # Resize the frame
        frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, 
                interpolation=cv2.INTER_AREA)
    ```

6.  显示画面:

    ```
        # Display the image
        cv2.imshow('Webcam', frame)
    ```

7.  等待 1 ms，然后捕捉下一帧:

    ```
        # Detect if the Esc key has been pressed
        c = cv2.waitKey(1)
        if c == 27:
            break
    ```

8.  释放视频拍摄对象:

    ```
    # Release the video capture object
    cap.release()
    ```

9.  退出代码前关闭所有活动窗口:

    ```
    # Close all active windows
    cv2.destroyAllWindows()
    ```

10.  The full code is given in the `video_capture.py` file that's already provided to you for reference. If you run this code, you will see the video from the webcam, similar to the following screenshot:

    ![How to do it…](images/B05485_10_01.jpg)

# 使用哈尔级联构建人脸检测器

正如我们前面讨论的，人脸检测是确定人脸在输入图像中的位置的过程。我们将使用**哈尔级联**进行人脸检测。这是通过在多个尺度上从图像中提取大量简单特征来实现的。简单的特征基本上是非常容易计算的边、线和矩形特征。然后通过创建一系列简单的分类器来训练它。 **自适应增压**技术用于使该过程稳健。可以在[http://docs . opencv . org/3 . 1 . 0/D7/d8b/tutorial _ py _ face _ detection . html # GSC . tab = 0](http://docs.opencv.org/3.1.0/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0)了解更多。让我们来看看如何在网络摄像头拍摄的视频帧中确定人脸的位置。

## 怎么做…

1.  新建一个 Python 文件，导入以下包:

    ```
    import cv2
    import numpy as np 
    ```

2.  加载面探测器级联文件。这是一个训练好的模型，我们可以用作检测器:

    ```
    # Load the face cascade file
    face_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')
    ```

3.  检查级联文件是否加载正确:

    ```
    # Check if the face cascade file has been loaded
    if face_cascade.empty():
        raise IOError('Unable to load the face cascade classifier xml file')
    ```

4.  创建视频采集对象:

    ```
    # Initialize the video capture object
    cap = cv2.VideoCapture(0)
    ```

5.  定义图像下采样的比例因子:

    ```
    # Define the scaling factor
    scaling_factor = 0.5
    ```

6.  继续循环直到你按下 *Esc* 键:

    ```
    # Loop until you hit the Esc key
    while True:
        # Capture the current frame and resize it
        ret, frame = cap.read()
    ```

7.  调整框架大小:

    ```
        frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, 
                interpolation=cv2.INTER_AREA)
    ```

8.  将图像转换为灰度。我们需要灰度图像来运行面部检测器:

    ```
        # Convert to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    ```

9.  对灰度图像运行面部检测器。`1.3`参数是指每个阶段的比例乘数。`5`参数是指每个候选矩形应该具有的最小邻居数量，以便我们可以保留它。这个候选矩形基本上是一个有可能检测到人脸的潜在区域:

    ```
        # Run the face detector on the grayscale image
        face_rects = face_cascade.detectMultiScale(gray, 1.3, 5)
    ```

10.  对于每个检测到的人脸区域，在它周围画一个矩形:

    ```
        # Draw rectangles on the image
        for (x,y,w,h) in face_rects:
            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)
    ```

11.  显示输出图像:

    ```
        # Display the image
        cv2.imshow('Face Detector', frame)
    ```

12.  等待 1 ms，然后进行下一次迭代。如果用户按下 *Esc* 键，跳出循环:

    ```
        # Check if Esc key has been pressed
        c = cv2.waitKey(1)
        if c == 27:
            break
    ```

13.  退出代码前释放并销毁对象:

    ```
    # Release the video capture object and close all windows
    cap.release()
    cv2.destroyAllWindows()
    ```

14.  The full code is given in the `face_detector.py` file that's already provided to you for reference. If you run this code, you will see the face being detected in the webcam video:

    ![How to do it…](images/B05485_10_02.jpg)

# 建造眼睛和鼻子探测器

哈尔级联方法可以扩展到检测所有类型的物体。让我们看看如何使用它来检测输入视频中的眼睛和鼻子。

## 怎么做…

1.  新建一个 Python 文件，导入以下包:

    ```
    import cv2
    import numpy as np
    ```

2.  加载面部、眼睛和鼻子级联文件:

    ```
    # Load face, eye, and nose cascade files
    face_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')
    eye_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_eye.xml')
    nose_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_mcs_nose.xml')
    ```

3.  检查文件是否正确加载:

    ```
    # Check if face cascade file has been loaded
    if face_cascade.empty():
        raise IOError('Unable to load the face cascade classifier xml file')

    # Check if eye cascade file has been loaded
    if eye_cascade.empty():
        raise IOError('Unable to load the eye cascade classifier xml file')

    # Check if nose cascade file has been loaded
    if nose_cascade.empty():
        raise IOError('Unable to load the nose cascade classifier xml file')
    ```

4.  初始化视频采集对象:

    ```
    # Initialize video capture object and define scaling factor
    cap = cv2.VideoCapture(0)
    ```

5.  定义比例因子:

    ```
    scaling_factor = 0.5
    ```

6.  继续循环，直到用户按下 *Esc* 键:

    ```
    while True:
        # Read current frame, resize it, and convert it to grayscale
        ret, frame = cap.read()
    ```

7.  调整框架大小:

    ```
        frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, 
                interpolation=cv2.INTER_AREA)
    ```

8.  将图像转换为灰度:

    ```
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    ```

9.  在灰度图像上运行人脸检测器:

    ```
        # Run face detector on the grayscale image
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    ```

10.  因为我们知道眼睛和鼻子总是在脸上，所以我们只能在面部区域运行这些检测器:

    ```
        # Run eye and nose detectors within each face rectangle
        for (x,y,w,h) in faces:
    ```

11.  提取人脸感兴趣区域:

    ```
            # Grab the current ROI in both color and grayscale images
            roi_gray = gray[y:y+h, x:x+w]
            roi_color = frame[y:y+h, x:x+w]
    ```

12.  运行眼睛检测器:

    ```
            # Run eye detector in the grayscale ROI
            eye_rects = eye_cascade.detectMultiScale(roi_gray)
    ```

13.  运行鼻子检测器:

    ```
            # Run nose detector in the grayscale ROI
            nose_rects = nose_cascade.detectMultiScale(roi_gray, 1.3, 5)
    ```

14.  在眼睛周围画圈:

    ```
            # Draw green circles around the eyes
            for (x_eye, y_eye, w_eye, h_eye) in eye_rects:
                center = (int(x_eye + 0.5*w_eye), int(y_eye + 0.5*h_eye))
                radius = int(0.3 * (w_eye + h_eye))
                color = (0, 255, 0)
                thickness = 3
                cv2.circle(roi_color, center, radius, color, thickness)
    ```

15.  在鼻子周围画一个矩形:

    ```
            for (x_nose, y_nose, w_nose, h_nose) in nose_rects:
                cv2.rectangle(roi_color, (x_nose, y_nose), (x_nose+w_nose, 
                    y_nose+h_nose), (0,255,0), 3)
                break
    ```

16.  显示图像:

    ```
        # Display the image
        cv2.imshow('Eye and nose detector', frame)
    ```

17.  等待 1 ms，然后进行下一次迭代。如果用户按下 *Esc* 键，则断开循环。

    ```
        # Check if Esc key has been pressed
        c = cv2.waitKey(1)
        if c == 27:
            break
    ```

18.  退出代码前释放并销毁对象。

    ```
    # Release video capture object and close all windows
    cap.release()
    cv2.destroyAllWindows()
    ```

19.  The full code is given in the `eye_nose_detector.py` file that's already provided to you for reference. If you run this code, you will see the eyes and nose being detected in the webcam video:

    ![How to do it…](images/B05485_10_03.jpg)

# 进行主成分分析

**主成分分析** ( **主成分分析**)是一种降维技术，在计算机视觉和机器学习中使用非常频繁。当我们处理大维度的特征时，训练机器学习系统变得极其昂贵。因此，在训练一个系统之前，我们需要降低数据的维数。然而，当我们降低维度时，我们不想丢失数据中存在的信息。这就是 PCA 进入画面的地方！主成分分析识别数据的重要组成部分，并按重要性顺序排列。你可以在[http://dai.fmph.uniba.sk/courses/ml/sl/PCA.pdf](http://dai.fmph.uniba.sk/courses/ml/sl/PCA.pdf)了解更多。它在人脸识别系统中被大量使用。让我们看看如何对输入数据执行 PCA。

## 怎么做…

1.  新建一个 Python 文件，导入以下包:

    ```
    import numpy as np
    from sklearn import decomposition 
    ```

2.  让我们为输入数据定义五个维度。前两个维度将是独立的，但后三个维度将依赖于前两个维度。这基本上意味着我们可以在没有最后三个维度的情况下生活，因为它们没有给我们任何新的信息:

    ```
    # Define individual features
    x1 = np.random.normal(size=250)
    x2 = np.random.normal(size=250)
    x3 = 2*x1 + 3*x2
    x4 = 4*x1 - x2
    x5 = x3 + 2*x4
    ```

3.  让我们用这些特征创建一个数据集。

    ```
    # Create dataset with the above features
    X = np.c_[x1, x3, x2, x5, x4]
    ```

4.  创建主成分分析对象:

    ```
    # Perform Principal Components Analysis
    pca = decomposition.PCA()
    ```

5.  在输入数据上拟合主成分分析模型:

    ```
    pca.fit(X)
    ```

6.  打印尺寸差异:

    ```
    # Print variances
    variances = pca.explained_variance_
    print '\nVariances in decreasing order:\n', variances
    ```

7.  如果某个特定的维度是有用的，那么它将具有有意义的方差值。让我们设定一个阈值，并确定重要的维度:

    ```
    # Find the number of useful dimensions
    thresh_variance = 0.8
    num_useful_dims = len(np.where(variances > thresh_variance)[0])
    print '\nNumber of useful dimensions:', num_useful_dims
    ```

8.  就像我们之前讨论的，主成分分析发现在这个数据集中只有两个维度是重要的:

    ```
    # As we can see, only the 2 first components are useful
    pca.n_components = num_useful_dims
    ```

9.  让我们将数据集从五维集转换为二维集:

    ```
    X_new = pca.fit_transform(X)
    print '\nShape before:', X.shape
    print 'Shape after:', X_new.shape
    ```

10.  The full code is given in the `pca.py` file that's already provided to you for reference. If you run this code, you will see the following on your Terminal:

    ![How to do it…](images/B05485_10_04.jpg)

# 进行核主成分分析

主成分分析擅长减少维数，但它以线性方式工作。如果数据不是以线性方式组织的，主成分分析就不能完成要求的工作。这就是内核主成分分析进入画面的地方。你可以在上了解更多。让我们看看如何对输入数据执行内核主成分分析，并将其与主成分分析对相同数据的执行进行比较。

## 怎么做…

1.  新建一个 Python 文件，导入以下包:

    ```
    import numpy as np
    import matplotlib.pyplot as plt

    from sklearn.decomposition import PCA, KernelPCA
    from sklearn.datasets import make_circles
    ```

2.  定义随机数生成器的种子值。这是生成数据样本进行分析所需要的:

    ```
    # Set the seed for random number generator
    np.random.seed(7)
    ```

3.  生成同心圆分布的数据，以演示在这种情况下 PCA 如何不起作用:

    ```
    # Generate samples
    X, y = make_circles(n_samples=500, factor=0.2, noise=0.04)
    ```

4.  对该数据进行主成分分析:

    ```
    # Perform PCA
    pca = PCA()
    X_pca = pca.fit_transform(X)
    ```

5.  对该数据进行核主成分分析:

    ```
    # Perform Kernel PCA
    kernel_pca = KernelPCA(kernel="rbf", fit_inverse_transform=True, gamma=10)
    X_kernel_pca = kernel_pca.fit_transform(X)
    X_inverse = kernel_pca.inverse_transform(X_kernel_pca)
    ```

6.  绘制原始输入数据:

    ```
    # Plot original data
    class_0 = np.where(y == 0)
    class_1 = np.where(y == 1)
    plt.figure()
    plt.title("Original data")
    plt.plot(X[class_0, 0], X[class_0, 1], "ko", mfc='none')
    plt.plot(X[class_1, 0], X[class_1, 1], "kx")
    plt.xlabel("1st dimension")
    plt.ylabel("2nd dimension")
    ```

7.  绘制主成分分析转换数据:

    ```
    # Plot PCA projection of the data
    plt.figure()
    plt.plot(X_pca[class_0, 0], X_pca[class_0, 1], "ko", mfc='none')
    plt.plot(X_pca[class_1, 0], X_pca[class_1, 1], "kx")
    plt.title("Data transformed using PCA")
    plt.xlabel("1st principal component")
    plt.ylabel("2nd principal component")
    ```

8.  绘制内核主成分分析转换数据:

    ```
    # Plot Kernel PCA projection of the data
    plt.figure()
    plt.plot(X_kernel_pca[class_0, 0], X_kernel_pca[class_0, 1], "ko", mfc='none')
    plt.plot(X_kernel_pca[class_1, 0], X_kernel_pca[class_1, 1], "kx")
    plt.title("Data transformed using Kernel PCA")
    plt.xlabel("1st principal component")
    plt.ylabel("2nd principal component")
    ```

9.  使用 Kernel 方法将数据转换回原始空间，以显示保留了逆空间:

    ```
    # Transform the data back to original space
    plt.figure()
    plt.plot(X_inverse[class_0, 0], X_inverse[class_0, 1], "ko", mfc='none')
    plt.plot(X_inverse[class_1, 0], X_inverse[class_1, 1], "kx")
    plt.title("Inverse transform")
    plt.xlabel("1st dimension")
    plt.ylabel("2nd dimension")

    plt.show()
    ```

10.  The full code is given in the `kpca.py` file that's already provided to you for reference. If you run this code, you will see four figures. The first figure is the original data:

    ![How to do it…](images/B05485_10_05.jpg)

    第二个图描述了使用主成分分析转换的数据:

    ![How to do it…](images/B05485_10_06.jpg)

    第三幅图描绘了使用核主成分分析转换的数据。请注意图中右侧的点是如何聚集的:

    ![How to do it…](images/B05485_10_07.jpg)

    第四张图描绘了数据到原始空间的逆变换:

    ![How to do it…](images/B05485_10_08.jpg)

# 执行盲源分离

**盲源分离**指的是从混合物中分离信号的过程。假设一堆不同的信号发生器产生信号，一个公共接收器接收所有这些信号。现在，我们的工作是利用这些信号的特性从混合物中分离出这些信号。我们将使用 **独立分量分析** ( **ICA** )来实现这一点。你可以在[http://www . MIT . edu/~ gari/teaching/6.555/LEASE _ NOtes/ch15 _ BSS . pdf](http://www.mit.edu/~gari/teaching/6.555/LECTURE_NOTES/ch15_bss.pdf)了解更多。让我们看看怎么做。

## 怎么做…

1.  新建一个 Python 文件，导入以下包:

    ```
    import numpy as np
    import matplotlib.pyplot as plt
    from scipy import signal

    from sklearn.decomposition import PCA, FastICA 
    ```

2.  我们将使用已经提供给您的`mixture_of_signals.txt`文件中的数据。让我们加载数据:

    ```
    # Load data
    input_file = 'mixture_of_signals.txt'
    X = np.loadtxt(input_file)
    ```

3.  创建独立分量分析对象:

    ```
    # Compute ICA
    ica = FastICA(n_components=4)
    ```

4.  基于独立分量分析重构信号:

    ```
    # Reconstruct the signals
    signals_ica = ica.fit_transform(X)
    ```

5.  提取混合矩阵:

    ```
    # Get estimated mixing matrix
    mixing_mat = ica.mixing_  
    ```

6.  进行主成分分析比较:

    ```
    # Perform PCA 
    pca = PCA(n_components=4)
    signals_pca = pca.fit_transform(X)  # Reconstruct signals based on orthogonal components
    ```

7.  定义要绘制的信号列表:

    ```
    # Specify parameters for output plots 
    models = [X, signals_ica, signals_pca]
    ```

8.  指定图的颜色:

    ```
    colors = ['blue', 'red', 'black', 'green']
    ```

9.  绘制输入信号:

    ```
    # Plotting input signal
    plt.figure()
    plt.title('Input signal (mixture)')
    for i, (sig, color) in enumerate(zip(X.T, colors), 1):
        plt.plot(sig, color=color)
    ```

10.  绘制独立分量分析分离信号:

    ```
    # Plotting ICA signals 
    plt.figure()
    plt.title('ICA separated signals')
    plt.subplots_adjust(left=0.1, bottom=0.05, right=0.94, 
            top=0.94, wspace=0.25, hspace=0.45)
    ```

11.  用不同的颜色绘制支线剧情:

    ```
    for i, (sig, color) in enumerate(zip(signals_ica.T, colors), 1):
        plt.subplot(4, 1, i)
        plt.title('Signal ' + str(i))
        plt.plot(sig, color=color)
    ```

12.  绘制主成分分析分离信号:

    ```
    # Plotting PCA signals  
    plt.figure()
    plt.title('PCA separated signals')
    plt.subplots_adjust(left=0.1, bottom=0.05, right=0.94, 
            top=0.94, wspace=0.25, hspace=0.45)
    ```

13.  在每个子剧情中使用不同的颜色:

    ```
    for i, (sig, color) in enumerate(zip(signals_pca.T, colors), 1):
        plt.subplot(4, 1, i)
        plt.title('Signal ' + str(i))
        plt.plot(sig, color=color)

    plt.show()
    ```

14.  The full code is given in the `blind_source_separation.py` file that's already provided to you for reference. If you run this code, you will see three figures. The first figure depicts the input, which is a mixture of signals:

    ![How to do it…](images/B05485_10_09.jpg)

    第二幅图描绘了使用独立分量分析分离的信号:

    ![How to do it…](images/B05485_10_10.jpg)

    第三幅图描绘了使用主成分分析分离的信号:

    ![How to do it…](images/B05485_10_11.jpg)

# 利用局部二值模式直方图构建人脸识别器

我们现在准备构建一个人脸识别器。我们需要一个人脸数据集进行训练，所以我们给你提供了一个名为`faces_dataset`的文件夹，里面包含了少量足以进行训练的图像。该数据集是可在[上获得的数据集的子集。这个数据集包含了大量的图像，我们可以用来训练一个人脸识别系统。](http://www.vision.caltech.edu/Image_Datasets/faces/faces.tar)

我们将使用**局部二值模式直方图**来构建我们的人脸识别系统。在我们的数据集中，你会看到不同的人。我们的工作是建立一个系统，可以学会将这些人彼此分开。当我们看到一个未知的图像时，这个系统会把它分配给一个现有的类。您可以在[上了解更多关于本地二进制模式直方图的信息。来看看](http://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html#local-binary-patterns-histograms)如何构建人脸识别器。

## 怎么做…

1.  新建一个 Python 文件，导入以下包:

    ```
    import os

    import cv2
    import numpy as np
    from sklearn import preprocessing 
    ```

2.  让我们定义一个类来处理与类的标签编码相关的所有任务:

    ```
    # Class to handle tasks related to label encoding
    class LabelEncoder(object):
    ```

3.  定义一种对标签进行编码的方法。在输入的训练数据中，标签由单词表示。然而，我们需要数字来训练我们的系统。该方法将定义一个预处理器对象，该对象可以通过维护向前和向后映射来以有组织的方式将单词转换为数字:

    ```
        # Method to encode labels from words to numbers
        def encode_labels(self, label_words):
            self.le = preprocessing.LabelEncoder()
            self.le.fit(label_words)
    ```

4.  定义一种将单词转换成数字的方法:

    ```
        # Convert input label from word to number
        def word_to_num(self, label_word):
            return int(self.le.transform([label_word])[0])
    ```

5.  定义一种将数字转换回原始单词的方法:

    ```
        # Convert input label from number to word
        def num_to_word(self, label_num):
            return self.le.inverse_transform([label_num])[0]
    ```

6.  定义从输入文件夹中提取图像和标签的方法:

    ```
    # Extract images and labels from input path
    def get_images_and_labels(input_path):
        label_words = []
    ```

7.  递归迭代输入文件夹，提取所有图像路径:

    ```
        # Iterate through the input path and append files
        for root, dirs, files in os.walk(input_path):
            for filename in (x for x in files if x.endswith('.jpg')):
                filepath = os.path.join(root, filename)
                label_words.append(filepath.split('/')[-2]) 
    ```

8.  初始化变量:

    ```
        # Initialize variables
        images = []
        le = LabelEncoder()
        le.encode_labels(label_words)
        labels = []
    ```

9.  解析输入目录进行训练:

    ```
        # Parse the input directory
        for root, dirs, files in os.walk(input_path):
            for filename in (x for x in files if x.endswith('.jpg')):
                filepath = os.path.join(root, filename)
    ```

10.  以灰度格式读取当前图像:

    ```
                # Read the image in grayscale format
                image = cv2.imread(filepath, 0) 
    ```

11.  从文件夹路径中提取标签:

    ```
                # Extract the label
                name = filepath.split('/')[-2]
    ```

12.  对该图像进行人脸检测:

    ```
                # Perform face detection
                faces = faceCascade.detectMultiScale(image, 1.1, 2, minSize=(100,100))
    ```

13.  提取感兴趣区域并与标签编码器一起返回:

    ```
                # Iterate through face rectangles
                for (x, y, w, h) in faces:
                    images.append(image[y:y+h, x:x+w])
                    labels.append(le.word_to_num(name))

        return images, labels, le
    ```

14.  定义`main`功能，定义人脸级联文件的路径:

    ```
    if __name__=='__main__':
        cascade_path = "cascade_files/haarcascade_frontalface_alt.xml"
        path_train = 'faces_dataset/train'
        path_test = 'faces_dataset/test'
    ```

15.  加载人脸级联文件:

    ```
        # Load face cascade file
        faceCascade = cv2.CascadeClassifier(cascade_path)
    ```

16.  创建局部二进制模式直方图人脸识别器对象:

    ```
        # Initialize Local Binary Patterns Histogram face recognizer
        recognizer = cv2.face.createLBPHFaceRecognizer()
    ```

17.  提取该输入路径的图像、标签和标签编码器:

    ```
        # Extract images, labels, and label encoder from training dataset
        images, labels, le = get_images_and_labels(path_train)
    ```

18.  使用我们提取的数据训练人脸识别器:

    ```
        # Train the face recognizer 
        print "\nTraining..."
        recognizer.train(images, np.array(labels))
    ```

19.  在未知数据上测试人脸识别器:

    ```
        # Test the recognizer on unknown images
        print '\nPerforming prediction on test images...'
        stop_flag = False
        for root, dirs, files in os.walk(path_test):
            for filename in (x for x in files if x.endswith('.jpg')):
                filepath = os.path.join(root, filename)
    ```

20.  加载图像:

    ```
                # Read the image
                predict_image = cv2.imread(filepath, 0)
    ```

21.  使用面部检测器确定面部位置:

    ```
                # Detect faces
                faces = faceCascade.detectMultiScale(predict_image, 1.1, 
                        2, minSize=(100,100))
    ```

22.  对于每个人脸 ROI，运行人脸识别器:

    ```
                # Iterate through face rectangles
                for (x, y, w, h) in faces:
                    # Predict the output
                    predicted_index, conf = recognizer.predict(
                            predict_image[y:y+h, x:x+w])
    ```

23.  将标签转换为单词:

    ```
                    # Convert to word label
                    predicted_person = le.num_to_word(predicted_index)
    ```

24.  将文本叠加在输出图像上并显示:

    ```
                    # Overlay text on the output image and display it
                    cv2.putText(predict_image, 'Prediction: ' + predicted_person, 
                            (10,60), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 6)
                    cv2.imshow("Recognizing face", predict_image)
    ```

25.  检查用户是否按下了 *Esc* 键。如果是，打破循环:

    ```
                c = cv2.waitKey(0)
                if c == 27:
                    stop_flag = True
                    break

            if stop_flag:
                break
    ```

26.  The full code is in the `face_recognizer.py` file that's already provided to you for reference. If you run this code, you will get an output window, which displays the predicted outputs for test images. You can press the *Space* button to keep looping. There are three different people in the test images. The output for the first person looks like the following:

    ![How to do it…](images/B05485_10_12.jpg)

    第二个人的输出如下所示:

    ![How to do it…](images/B05485_10_13.jpg)

    第三人称的输出如下图所示:

    ![How to do it…](images/B05485_10_14.jpg)
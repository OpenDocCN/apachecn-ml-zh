# 第八章。集成方法

随着本书前面章节的深入，您学习了如何应用一些新技术。我们开发了几种先进的机器学习算法，并获得了广泛的配套技术，通过更有效的特征选择和准备来提高您对学习技术的使用。本章试图使用集成方法来增强您现有的技术集:将多个不同的模型绑定在一起以解决现实问题的技术。

集成技术已经成为数据科学家工具集的一个基本部分。在竞争的机器学习环境中，集成的使用已经成为一种常见的做法，集成现在被认为是许多环境中不可或缺的工具。我们将在本章中开发的技术为我们的模型提供了性能优势，同时增强了它们对底层数据变化的鲁棒性。

我们将研究一系列集合选项，讨论这些技术的代码和应用。我们将通过指导和参考现实世界的应用程序，包括由成功的卡格尔斯创建的模型来丰富这个解释。

我们在本标题中回顾的任何模型的开发都允许我们解决广泛的数据问题，但是将我们的模型应用于生产环境会带来一系列额外的问题。我们的解决方案仍然容易受到潜在观察结果变化的影响。无论是在不同的个体群体中、在时间变化中(例如，被捕捉的现象的季节性变化)还是通过潜在条件的其他变化来表达，最终结果往往是相同的——在他们被训练的条件下运行良好的模型通常不能推广并继续表现良好久而久之。

本章的最后一节描述了将本书中的技术转移到操作环境的方法，以及如果您的预期应用程序必须能够适应变化，您应该考虑的附加监控和支持的种类。

# 引入合奏

|   | *“这就是你赢得 ML 比赛的方式:你拿着别人的作品，一起合奏。”* |   |
|   | - *维塔利·库兹涅佐夫 nip 2014* |

在机器学习的上下文中，集成是一组用于解决共享问题的模型。集成由两个部分组成:一组模型和一组决定规则，这些决定规则决定了如何将这些模型的结果组合成单个输出。

集成为数据科学家提供了为给定问题构建多个解决方案的能力，然后将这些解决方案组合成单个最终结果，该结果从每个输入解决方案的最佳元素中提取。这提供了对噪声的鲁棒性，这反映在针对初始数据集的更有效的训练(导致更低水平的过拟合和训练误差的减少)以及针对前面部分讨论的那种数据变化。

毫不夸张地说，集成是机器学习中最重要的最新发展。

此外，集成使人们能够更灵活地解决给定的问题，因为它们使数据科学家能够测试解决方案的不同部分，并解决特定于输入数据子集或正在使用的模型部分的问题，而无需完全重新调整整个模型。正如我们将看到的，这可以让生活变得更容易！

根据所使用的决策规则的性质，系综通常被认为属于几个类别之一。主要的合奏类型如下:

*   **平均方法**:他们并行开发模型，然后使用平均或投票技术来开发组合估计器
*   **堆叠(或混合)方法**:它们使用多个分类器的加权输出作为下一层模型的输入
*   **增强方法**:它们涉及按顺序构建模型，其中每个添加的模型旨在提高组合估计器的得分

考虑到这两类集成方法的重要性和实用性，我们将依次讨论每一个:讨论理论、算法选项和真实世界的例子。

## 理解平均系综

平均系综在物理科学和统计建模领域有着悠久而丰富的历史，在包括分子动力学和音频信号处理在内的许多领域都有着广泛的应用。这种集合通常被视为给定系统的几乎完全相同的复制情况。该系统中病例间的平均值和方差是整个系统的关键值。

在机器学习环境中，平均集成是在同一数据集上训练的模型的集合，其结果以一系列方式聚集。根据实现目标，平均集成可以带来几个好处。

平均系综可用于降低模型性能的可变性。一种常见的方法是创建多个模型配置，这些配置采用不同的参数子集作为输入。采用这种方法的技术统称为打包算法。

### 使用打包算法

不同的打包实现将有不同的操作，但是共享随机获取特征空间的子集的共同属性。打包方法有四种主要类型。粘贴绘制样本的随机子集，而不进行替换。当替换完成后，这种方法简单地称为**装袋**。粘贴在计算上通常比打包便宜，并且可以在更简单的应用程序中产生类似的结果。

当以特征方式采集样本时，该方法被称为 **随机子空间**。随机子空间方法提供了稍微不同的能力；它们基本上减少了对广泛的、高度优化的特征选择的需求。在这种活动通常导致具有优化输入的单个模型的情况下，随机子空间允许并行使用多个配置，并使任何一个解决方案的方差变平。

### 注

虽然使用合奏来减少模型性能的可变性听起来像是一个性能打击(自然的反应可能是，但是为什么不在合奏中选择一个表现最好的模型呢？)，这种方法有很大的优势。

首先，如前所述，平均提高了模型集适应不熟悉的噪声的能力(也就是说，它减少了过拟合)。其次，可以使用集成来针对输入数据集的不同元素进行有效建模。这是竞争机器学习环境中的一种常见方法，其中数据科学家将基于分类结果和特定类型的故障案例迭代调整集成。在某些情况下，这是一个详尽的过程，包括检查模型结果(通常作为正常的迭代模型开发过程的一部分)，但是许多数据科学家更喜欢他们将首先实现的技术或解决方案。

随机子空间可以是一种非常强大的方法，尤其是如果有可能使用多个子空间大小并彻底检查特征组合的话。随机子空间方法的成本随着数据集的大小非线性地增加，超过某个点，测试多个子空间大小的每个参数配置将变得昂贵。

最后，可以用一种称为 **随机面片**的方法，从样本和特征抽取的子集创建一个集合的估计器。在相似的情况下，随机补丁的性能通常与随机子空间技术的性能大致相同，内存消耗显著降低。

由于我们已经讨论了打包套装背后的理论，让我们看看如何实现一个。以下代码描述了使用 sklearn 的`BaggingClassifier`类实现的随机补丁分类器:

```py
from sklearn.cross_validation import cross_val_score
from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_digits
from sklearn.preprocessing import scale

digits = load_digits()
data = scale(digits.data)
X = data
y = digits.target

bagging = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)
scores = cross_val_score(bagging, X, y)
mean = scores.mean() 
print(scores)
print(mean)
```

与许多 sklearn 分类器一样，所需的核心代码非常简单；分类器被初始化并用于对数据集进行评分。交叉验证(通过`cross_val_score`)不会增加任何有意义的复杂性。

这个打包分类器使用了一个 **K 近邻** ( **KNN** )分类器(`KNeighboursClassifier`)作为基础，特征和案例的采样率各设置为 50%。这相对于数字数据集输出了非常强的结果，在交叉验证后正确地对 93%的病例进行了平均分类:

```py
[ 0.94019934  0.92320534  0.9295302 ]

0.930978293043

```

### 使用随机森林

另一组平均集合技术统称为随机森林。随机森林可能是竞争数据科学家使用的最成功的集成技术，它开发了并行的决策树分类器集。通过给分类器结构引入两个主要的随机性来源，森林最终包含了不同的树。用于构建每个树的数据通过替换从训练集中采样，而树创建过程不再使用来自所有特征的最佳分割，而是从特征的随机子集选择最佳分割。

使用`sklearn`中的`RandomForestClassifier`类可以很容易地调用随机森林。举个简单的例子，考虑以下内容:

```py
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_digits
from sklearn.preprocessing import scale

digits = load_digits()
data = scale(digits.data)

n_samples, n_features = data.shape
n_digits = len(np.unique(digits.target))
labels = digits.target

clf = RandomForestClassifier(n_estimators=10)
clf = clf.fit(data, labels)
scores = clf.score(data,labels)
print(scores)
```

这个合奏输出的分数 0.999，很难打。事实上，我们在前面几章中使用的任何单个模型都没有看到这种水平的性能。

随机森林的变体，称为 **极随机树**(**extracrees**)，使用相同的随机特征子集方法来选择树中每个分支的最佳分割。然而，它也随机化了辨别阈值；决策树通常选择最有效的类间分割，而提取树以随机值分割。

由于决策树的训练相对有效，随机森林算法可以潜在地支持大量不同的树，分类器的有效性随着节点数量的增加而提高。引入的随机性为噪声或数据变化提供了一定程度的鲁棒性；然而，就像我们前面回顾的 bagging 算法一样，这种增益通常是以性能略微下降为代价的。在提取树的情况下，稳健性可能会进一步提高，而性能度量会提高(通常偏差值会降低)。

下面的代码描述了提取树在实践中是如何工作的。就像我们的随机子空间实现一样，代码非常简单。在这种情况下，我们将开发一组模型来比较树外树和随机森林方法的效果:

```py
from sklearn.cross_validation import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_digits
from sklearn.preprocessing import scale

digits = load_digits()
data = scale(digits.data)
X = data
y = digits.target

clf = DecisionTreeClassifier(max_depth=None, min_samples_split=1,
    random_state=0)
scores = cross_val_score(clf, X, y)                      
print(scores)

clf = RandomForestClassifier(n_estimators=10, max_depth=None,
    min_samples_split=1, random_state=0)
scores = cross_val_score(clf, X, y)       
print(scores)

clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,
    min_samples_split=1, random_state=0)
scores = cross_val_score(clf, X, y)
print(scores)
```

分数分别如下:

```py
[ 0.74252492  0.82136895  0.75671141]
[ 0.88372093  0.9015025   0.8909396 ]
[ 0.91694352  0.93489149  0.91778523]

```

假设我们在这里使用的是完全基于树的方法，分数就是正确标注的案例的比例。我们可以在这里看到，这两种森林方法之间没有太大的区别，它们都表现强劲，平均得分为 *0.9* 。在这个例子中，随机森林实际上比提取树略胜一筹(大约增加了 *0.002* ，而这两种技术都大大优于基本决策树，基本决策树的平均得分为 *0.77* 。

使用随机森林时的一个缺点是(特别是随着森林规模的增加)很难检查或调整给定实现的有效性。虽然单独的树非常容易处理，但是一个开发的集合中的树的数量以及随机分裂所产生的混淆会使改进随机森林实现变得非常困难。一种选择是开始查看单个模型所画的决策边界。通过对比一个集合中的模型，可以更容易地识别出一个模型在划分类时比其他模型表现更好的地方。

例如，在这个例子中，我们可以很容易地看到我们的模型在高水平上的表现，而不需要挖掘具体的细节:

![Using random forests](images/B03722_08_01.jpg)

虽然超越简单的层次(使用高层次的图和汇总分数)理解随机森林实现的表现可能是具有挑战性的，但困难是值得的。随机森林的性能非常强，只需要最小的额外计算成本。在早期阶段，当一个人还在确定攻击角度时，他们往往是解决问题的好方法，因为他们快速产生强有力结果的能力可以提供一个有用的基准。一旦您知道了随机森林实现的性能，您就可以开始优化和扩展您的集成。

为此，我们应该继续探索不同的集合技术，以便进一步构建我们的集合选项工具包。

## 应用助推方法

系综创建的另一种方法是构建增强模型。这些模型的特点是它们按顺序使用多个模型来迭代地“提升”或提高集合的性能。

增强模型经常使用一系列弱学习者，与随机猜测相比，这些模型只能提供边际收益。在每次迭代中，一个新的弱学习者在一个调整过的数据集上被训练。在多次迭代中，集成在每次迭代中用一个新的树(优化集成性能分数的树)扩展。

也许最著名的提升方法是 **AdaBoost** ，它通过执行以下操作在每次迭代时调整数据集:

*   选择一个决策树桩(一个浅的、通常是一级的决策树，实际上是所讨论数据集最重要的决策边界)
*   增加决策树桩标注不正确的案例的权重，同时减少标注正确的案例的权重

这种迭代权重调整使得集成中的每个新分类器优先训练错误标记的案例；该模型通过瞄准高度加权的数据点进行调整。最终，树桩被组合成最终的分类器。

AdaBoost 可以在分类和回归上下文中使用，并获得令人印象深刻的结果。以下示例显示了在`heart`数据集上运行的 AdaBoost 实现:

```py
import numpy as np

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.datasets.mldata import fetch_mldata
from sklearn.cross_validation import cross_val_score

n_estimators = 400
# A learning rate of 1\. may not be optimal for both SAMME and SAMME.R
learning_rate = 1.

heart = fetch_mldata("heart")
X = heart.data
y = np.copy(heart.target)
y[y==-1]=0

X_test, y_test = X[189:], y[189:]
X_train, y_train = X[:189], y[:189]

dt_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)
dt_stump.fit(X_train, y_train)
dt_stump_err = 1.0 - dt_stump.score(X_test, y_test)

dt = DecisionTreeClassifier(max_depth=9, min_samples_leaf=1)
dt.fit(X_train, y_train)
dt_err = 1.0 - dt.score(X_test, y_test)

ada_discrete = AdaBoostClassifier(
    base_estimator=dt_stump,
    learning_rate=learning_rate,
    n_estimators=n_estimators,
    algorithm="SAMME")
ada_discrete.fit(X_train, y_train)

scores = cross_val_score(ada_discrete, X_test, y_test)
print(scores)                  
means = scores.mean()
print(means)
```

在这种情况下，`n_estimators`参数指示使用的弱学习者的数量；在平均方法的情况下，添加估计器总是会降低模型的偏差，但会增加模型过度训练其训练数据的概率。`base_estimator`参数可以用来定义不同的弱学习者；默认值是决策树(因为训练一棵弱树很简单，可以使用树桩，非常浅的树)。当应用于`heart`数据集时，如本例所示，AdaBoost 在略高于 79%的情况下实现了正确标注，这对于第一遍来说是相当可靠的性能:

```py
[ 0.77777778  0.81481481  0.77777778]

0.79012345679

```

增压模型比平均模型具有显著优势；它们使得创建识别问题案例或问题案例类型并解决它们的集合变得容易得多。增强模型通常会首先针对最容易预测的案例，每个添加的模型都适合剩余的错误预测案例的子集。

由此产生的一个风险是增强模型开始过度拟合(在最极端的情况下，你可以想象集成组件已经适合特定的情况！)的训练数据。管理集合组件的正确数量是一个棘手的问题，但谢天谢地我们可以借助一种熟悉的技术来解决它。在[第 1 章](01.html "Chapter 1. Unsupervised Machine Learning")、*无监督机器学习*中，我们讨论了一种称为 **肘关节法**的视觉启发式方法。在的情况下，该图是 *K* (平均值的数量)，而不是集群实现的性能度量。在这种情况下，我们可以使用类似的过程，使用估计量的数量( *n* )和总体的偏差或误差率(我们称之为 e)。对于一系列不同的增强估计器，我们可以将它们的输出绘制如下:

![Applying boosting methods](images/B03722_08_02.jpg)

通过确定曲线开始变平的点，我们可以降低我们的模型过度拟合的风险，随着曲线开始变平，这种风险变得越来越有可能。这是真的，原因很简单，随着曲线水平，这必然意味着来自每个新的估计器的附加增益是越来越少的情况的正确分类！

这种视觉辅助工具的部分吸引力在于，它使我们能够感受到我们的解决方案可能会过度拟合。我们可以(也应该！)尽可能地应用验证技术，但在某些情况下(例如，当目标是实现模型实现的特定 MVP 目标时，无论是通过用例还是 Kaggle 公共排行榜上的分数分布来通知)，我们可能会倾向于推进性能实现。当我们添加每一个新的估计量时，准确理解我们所获得的收益是如何衰减的，这对于理解过度拟合的风险至关重要。

### 使用 XGBoost

2015 年年中，一种解决结构化机器学习问题的新算法——XGboost，在竞争激烈的数据科学领域掀起了一阵风暴。**极限梯度增强** ( **XGBoost** )是一个编写良好的性能库，提供了一个通用的增强算法(梯度增强)。

XGBoost 的工作方式很像 AdaBoost，但有一个关键区别——改进模型的方式不同。

在每次迭代中，XGBoost 都试图通过减少该集合的残差(目标和标签预测之间的差异)来提高现有模型集的性能。每次迭代，所添加的模型都是根据它是否最能减少现有集合的残差来选择的。这类似于梯度下降(通过逆着损失梯度移动来迭代地最小化函数)；因此，这个名字叫做梯度增强。

事实证明，Gradient Boosting 在最近的 Kaggle 竞赛中非常成功，它在 2015 年下半年支持了 CrowdFlower 竞赛和微软恶意软件分类挑战赛以及许多其他结构化数据竞赛的获胜者。

要应用 XGBoost，让我们获取 XGBoost 库。最好的方法是通过`pip`，命令行上有`pip install xgboost`命令。对于 Windows 用户，`pip`安装目前(2015 年末)在 Windows 上被禁用。为了您的利益，在本书的 GitHub 资源库的`Chapter 8`文件夹中提供了一份 XGBoost 的冷拷贝。

应用 XGBoost 相当简单。在这种情况下，我们将使用 UCI 皮肤病学数据集将该库应用于多类分类任务。该数据集包含一个年龄变量和大量分类变量。示例数据行如下所示:

```py
3,2,0,2,0,0,0,0,0,0,0,0,1,2,0,2,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,10,2

```

少数年龄值(倒数第二特征)缺失，由`?`编码。使用该数据集的目的是根据以下类别分布正确分类六种不同皮肤状况中的一种:

```py
 Database:  Dermatology

 Class code:   Class:                  Number of instances:
 1             psoriasis      112
 2             seboreic dermatitis             61
 3             lichen planus                   72
 4             pityriasis rosea                49
 5             cronic dermatitis               52 
 6             pityriasis rubra pilaris        20

```

我们将通过加载数据并通过 70/30 分割将其划分为测试和训练案例来开始对这个问题应用 XGBoost:

```py
import numpy as np
import xgboost as xgb

data = np.loadtxt('./dermatology.data', delimiter=',',converters={33: lambda x:int(x == '?'), 34: lambda x:int(x)-1 } )
sz = data.shape

train = data[:int(sz[0] * 0.7), :]
test = data[int(sz[0] * 0.7):, :]

train_X = train[:,0:33]
train_Y = train[:, 34]

test_X = test[:,0:33]
test_Y = test[:, 34]
```

此时，我们初始化并参数化我们的模型。`eta`参数定义步长收缩。在梯度下降算法中，使用收缩参数来减小更新的大小是非常常见的。梯度下降算法有一种趋势(特别接近收敛)在最优值上来回曲折；使用收缩参数来缩小变化的大小可以使梯度下降的效果更加精确。常见的(也是默认的)缩放值是`0.3`。在这个例子中，`eta`已经被设置为`0.1`以获得更高的精度(以更多迭代的可能代价)。

`max_depth`参数直观；它定义了示例中任何树的最大深度。给定六个输出类，六是一个合理的开始值。`num_round`参数定义了算法将执行多少轮梯度增强。同样，对于有更多类的多类问题，通常需要更多轮次。同时，`nthread`参数定义了代码将运行多少个 CPU 线程。

这里使用的`DMatrix`结构纯粹是为了训练速度和记忆优化。使用 XGBoost 时使用这些通常是个好主意；它们可以从`numpy.arrays`开始建造。使用`DMatrix`启用`watchlist`功能，解锁一些高级功能。特别是，`watchlist`允许我们监控所提供列表中所有数据的评估结果:

```py
xg_train = xgb.DMatrix( train_X, label=train_Y)
xg_test = xgb.DMatrix(test_X, label=test_Y)

param = {}

param['objective'] = 'multi:softmax'

param['eta'] = 0.1
param['max_depth'] = 6
param['nthread'] = 4
param['num_class'] = 6

watchlist = [ (xg_train,'train'), (xg_test, 'test') ]
num_round = 5
bst = xgb.train(param, xg_train, num_round, watchlist );
```

我们训练我们的模型`bst`，以生成初始预测。然后，我们重复训练过程，生成启用`softmax`的预测(通过`multi:softprob`):

```py
pred = bst.predict( xg_test );

print ('predicting, classification error=%f' % (sum( int(pred[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))

param['objective'] = 'multi:softprob'
bst = xgb.train(param, xg_train, num_round, watchlist );

yprob = bst.predict( xg_test ).reshape( test_Y.shape[0], 6 )
ylabel = np.argmax(yprob, axis=1)

print ('predicting, classification error=%f' % (sum( int(ylabel[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))
```

## 使用堆叠集合

我们在本章前面看到的传统集成都有一个共同的设计理念:它们涉及多个经过训练的分类器来适应一组目标标签，并涉及模型本身被应用来通过包括模型投票和增强在内的策略生成一些元函数。

关于整体创作，有一种替代的设计理念，称为堆叠，或者称为混合。堆叠涉及配置中的多层模型，其中一层模型的输出被用作下一层模型的训练数据。有可能成功地融合数百种不同的模式。

堆叠系综还可以从多个子混合(有时称为**混合)中组成图层输出的混合要素集。为了增加乐趣，还可以从堆叠集合的模型中提取特别有效的参数，并在不同级别的混合或子混合中将其用作元特征。**

 **所有这些结合在一起，使堆叠集成成为一种非常强大和可扩展的技术。卡格尔网飞奖(以及相关的 100 万美元奖金)的获奖者在数百个特写镜头上使用了叠加合奏，效果非常好。他们使用了一些额外的技巧来提高预测的有效性:

*   他们在保留一些数据的同时训练和优化了他们的整体。然后，他们使用保留的数据进行再培训，并在将模型应用于测试数据集之前再次优化。这并不是一个罕见的做法，但它产生了良好的结果，值得记住。
*   他们使用梯度下降和 RMSE 作为性能函数进行训练。至关重要的是，他们使用整体的 RMSE，而不是任何模型的，作为相关的性能指标(残差的度量)。无论何时与合奏团合作，这都应该被视为一种健康的做法。
*   他们使用已知的模型组合来改善其他模型的残差。例如，基于邻域的方法改进了 RBM 残差，我们在本书前面已经讨论过了。通过了解机器学习算法的相对优势和劣势，您可以找到理想的集成配置。
*   他们使用 k 倍交叉验证计算混合的残差，这是我们在本书前面探索和应用的另一种技术。这有助于克服这样一个事实，即他们已经使用与最终混合相同的数据集训练了混合的组成模型。

从曾经获得网飞奖的**务实混沌**模型的高度定制化本质中抽离出来的要点是，一流的模型通常是密集迭代和一些创造性的网络配置变化的产物。另一个关键要点是堆叠集合的基本架构模式如下:

![Using stacking ensembles](images/B03722_08_03.jpg)

既然你已经学习了堆叠集合如何工作的基本原理，让我们尝试应用它们来解决数据问题。为了让我们开始，我们将使用`Chapter 8`附带的 GitHub 存储库中提供的`blend.py`代码。这种混合代码的版本已经被多个比赛中得分较高的卡格勒使用。

首先，我们将研究如何应用堆叠系综来解决一个真正的数据科学问题:卡格尔竞赛*预测生物反应*旨在建立一个尽可能有效的模型，以预测给定化学性质的分子的生物反应。我们将关注本次竞赛中一个特别成功的参赛作品，以了解堆叠合奏如何在实践中发挥作用。

在这个数据集中，每行代表一个分子，而 1，776 个特征中的每一个都描述了所讨论的分子的特征。考虑到这些特性，我们的目标是预测相关分子的二元反应。

我们将应用的代码来自该锦标赛中的一个竞争对手，他使用堆叠集成来组合五个分类器:两个不同配置的随机森林分类器、两个额外的树分类器和一个梯度提升分类器，这有助于产生与其他四个组件略有不同的预测。

重复的分类器具有不同的划分标准。其中一个使用了基尼不纯度 T2(基尼)，这是一种衡量随机记录被错误标记的频率的方法，如果它根据潜在的有问题的分支中的标记分布被随机标记。另一棵树使用信息增益(熵)，一种衡量信息内容的方法。潜在分支的信息内容可以通过对其编码所需的比特数来测量。使用熵作为衡量标准来确定适当的分割会导致分支变得越来越不多样化，但重要的是要认识到熵和`gini`标准会产生完全不同的结果:

```py
if __name__ == '__main__':

    np.random.seed(0)

    n_folds = 10
    verbose = True
    shuffle = False

    X, y, X_submission = load_data.load()

    if shuffle:
        idx = np.random.permutation(y.size)
        X = X[idx]
        y = y[idx]

    skf = list(StratifiedKFold(y, n_folds))

    clfs = [RandomForestClassifier(n_estimators=100, n_jobs=-1, 
criterion='gini'),
            RandomForestClassifier(n_estimators=100, n_jobs=-1, 
criterion='entropy'),
            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, 
criterion='gini'),
            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, 
criterion='entropy'),
            GradientBoostingClassifier(learning_rate=0.05, 
subsample=0.5, max_depth=6, n_estimators=50)]

    print "Creating train and test sets for blending."

    dataset_blend_train = np.zeros((X.shape[0], len(clfs)))
    dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))

    for j, clf in enumerate(clfs):
        print j, clf
        dataset_blend_test_j = np.zeros((X_submission.shape[0], 
len(skf)))
        for i, (train, test) in enumerate(skf):
            print "Fold", i
            X_train = X[train]
            y_train = y[train]
            X_test = X[test]
            y_test = y[test]
            clf.fit(X_train, y_train)
            y_submission = clf.predict_proba(X_test)[:,1]
            dataset_blend_train[test, j] = y_submission
            dataset_blend_test_j[:, i] = 
clf.predict_proba(X_submission)[:,1]
        dataset_blend_test[:,j] = dataset_blend_test_j.mean(1)

    print
    print "Blending."
    clf = LogisticRegression()
    clf.fit(dataset_blend_train, y)
    y_submission = clf.predict_proba(dataset_blend_test)[:,1]

    print "Linear stretch of predictions to [0,1]"
    y_submission = (y_submission - y_submission.min()) / 
(y_submission.max() - y_submission.min())

    print "Saving Results."
    np.savetxt(fname='test.csv', X=y_submission, fmt='%0.9f')
```

当我们尝试在私人排行榜上运行这个提交时，我们发现自己处于相当令人印象深刻的第 12 位<sup>位置(在 699 个竞争对手中)！自然，我们不能从完成后进入的竞赛中得出太多结论，但是，考虑到代码的简单性，这仍然是一个相当令人印象深刻的结果！</sup>

### 在实践中应用合奏

在应用集成方法时需要注意的一个特别重要的品质是，您的目标是调整集成的性能，而不是组成集成的模型。因此，你的方法应该主要集中在建立一个强有力的合奏表演得分上，而不是最强的单个模型表演。

你对整体中的模特的关注程度会有所不同。对于单一类型(例如，随机森林)的不同配置或初始化模型的排列，明智的做法是几乎完全专注于集合的性能和塑造它的元参数。

对于更具挑战性的问题，我们经常需要更密切地关注我们整体中的单个模型。当我们试图为更具挑战性的问题创建更小的集成时，这显然是正确的，但是要构建真正优秀的集成，通常需要考虑您构建的结构背后的参数和算法。

说了这么多，你就会一直在看合奏的表现以及布景中模特的表现。你将检查你的模型的结果，试图找出每个模型做得好的地方。您还将寻找影响集合性能的不太明显的因素，最显著的是模型预测的相关性。人们普遍认为，一个更有效的合奏往往包含有表演性但不相关的成分。

要理解这种说法，可以考虑相关度量和主成分分析等技术，我们可以使用这些技术来度量数据集变量中存在的信息量。同样，我们可以使用皮尔逊相关系数与我们每个模型输出的预测进行比较，以了解每个模型的性能和相关性之间的关系。

具体地说，让我们回到堆叠系综，我们的系综模型输出元特征，这些元特征然后被用作下一层模型的输入。就像我们检查更传统的神经网络所使用的特征一样，我们希望确保由我们的集成组件输出的特征作为数据集工作良好。在这方面，计算模型输出之间的皮尔逊相关系数并在模型选择中使用结果是一个很好的起点。

当我们处理单模型问题时，我们几乎总是要花一些时间来检查问题并确定一个合适的学习算法。如果我们面临一个两类分类问题，其中有适量的特征( *10 个*)和标记的训练案例，我们可能会选择逻辑回归、SVM 或其他适合上下文的算法。不同的方法将适用于不同的问题，并通过反复试验，平行测试和经验(个人和网上发布！)，您将确定给定特定输入数据的特定目标的适当方法。

类似的逻辑也适用于合奏创作。挑战不是识别单一的适当模型，而是识别有效描述输入数据集不同元素的模型组合，从而充分描述数据集整体。通过了解您的组件模型的优势和劣势，以及通过探索和可视化您的数据集，您将能够得出关于如何通过多次迭代有效地开发您的集成的结论。

最终，在这个层面上，数据科学是一个拥有大量技术的领域。最好的实践者能够应用他们自己的算法和选项的知识，在多次迭代中开发出非常有效的解决方案。

这些解决方案涉及算法知识和模型组合的交互、模型参数调整、数据集转换和集成操作。同样重要的是，它们需要一种无拘无束和创造性的心态。

这方面的一个很好的例子是著名的卡格尔竞争对手亚历山大·古斯钦的作品。关注一个具体的例子——奥托产品分类竞赛——可以让我们了解自信而有创造力的数据科学家可以选择的范围。

大多数模型开发过程都是从一个阶段开始的，在这个阶段中，您会针对问题抛出不同的解决方案，试图找到数据背后的技巧，并找出有效的方法。亚历山大决定采用堆叠模型，开始构建图元特征。虽然我们将 XGBoost 视为一个独立的集成，但在这种情况下，它被用作堆叠集成的一个组件，以便生成一些元特征供最终模型使用。除了梯度增强树之外，还使用了神经网络，因为这两种算法都倾向于产生好的结果。

为了给混合物添加一些对比，Alexander 添加了一个 KNN 实现，特别是因为 KNN 生成的结果(以及元参数)往往与已经包含的模型有很大不同。这种拾取输出往往不同的组件的方法对于创建有效的堆叠集合(以及大多数集合类型)至关重要。

为了进一步开发这个模型，亚历山大在他的模型的第二层增加了一些定制元素。在结合 XGBoost 和神经网络预测的同时，他还在这一层增加了装袋。在这一点上，我们在本章中讨论的大多数技术已经在这个模型的某些部分出现了。除了模型开发之外，一些特征工程(特别是在一半的训练和测试数据中使用 TF-IDF)和使用绘图技术来识别类别差异也被贯穿始终。

一个真正成熟的模型可以解决最重要的数据科学挑战，它结合了我们在本书中看到的技术，通过对底层算法以及这些技术如何相互作用的可能性的深入理解而创建。

到目前为止，这本书已经教授了许多从业者必须收集的基础知识。它使用了许多例子和越来越多的真实案例来展示广泛的知识基础如何变得越来越强大，让你开发出解决困难问题的有效方法。

作为一名数据科学家，你需要做的是首先应用这一系列广泛的技术来发展一种经验，了解他们如何表现以及他们能为你做些什么。接下来就看你如何培养那种创造力和实验思维，这种思维让一些最优秀的数据科学家与众不同。

# 在动态应用中使用模型

我们花了这一章讨论在条件下管理模型性能的技术的使用，这些条件可能被视为理想的；具体来说，所有数据提前可用的条件，以便可以在所有数据上训练模型。这些假设在研究环境中或在处理一次性问题时通常是有效的，但在许多情况下，它们是不安全的假设。不安全环境的范围超出了数据根本不可用的情况，例如数据科学竞赛，使用一个保留的数据集来建立最终的排行榜。

回到本章前面的主题，你会想起获得网飞奖的实用混沌算法？当网飞开始评估实现算法时，业务环境和需求都发生了巨大的变化，以至于该算法提供的最小精度增益无法证明实现成本是合理的。100 万美元的算法是多余的，从未在生产中实现过！从这个例子中可以看出，在商业环境中，我们的模型尽可能具有适应性是至关重要的。

机器学习算法真正具有挑战性的应用是跨时间(或其他维度)发生真实数据变化的应用，在这些应用中，我们现有的运行一次的方法变得不那么有价值。在这些情况下，人们知道将会发生实质性的数据变化，并且现有的模型不容易被训练来适应这种数据变化。在这一点上，需要新的技术和新的信息。

为了适应和收集这些信息，我们需要更好地预测数据变化可能发生的方式。有了这些信息，我们的模型构建和集合的内容可以开始改变，以涵盖我们看到的最有可能的数据变化场景。这种自适应让我们能够抢先进行数据更改，并减少所需的调整时间。正如我们将在本章后面看到的，在现实世界的应用程序中，任何基于数据变化的数据透视时间的减少都是有价值的。

在下一节中，我们将研究可以用来使我们的模型对不断变化的数据更加健壮的工具。我们将讨论如何维护一组广泛的模型选项，同时适应一个或多个数据更改场景，而不降低模型的性能。

## 理解模型的鲁棒性

重要的是要准确理解这里的问题是什么，以及它是如何和何时出现的。这包括定义两件事；首先是鲁棒性，因为它适用于机器学习算法。第二，当然是数据变化。本节第一部分的一些内容处于入门水平，但是有经验的数据科学家可能仍然会发现回顾本节的价值！

用学术术语来说，机器学习算法的健壮性是一个属性，它描述了当应用于数据集而不是训练它的数据集时，你的算法有多有效。

健壮性测试是任何环境下机器学习方法的核心部分。k-fold 交叉验证等验证技术的重要性以及在为最简单的上下文开发模型时使用测试是机器学习算法易受数据变化影响的结果。

大多数数据集包含信号和噪声。噪音可能是可预测的(因此更容易管理)，也可能是随机的，难以处理。数据集可能包含或多或少的噪声。通常，具有或多或少的可预测噪声的数据集在去除该噪声的相同数据集上更难训练和测试(可以容易地测试)。

当一个人在给定的数据集上训练了一个模型时，几乎不可避免的是，这个模型是基于信号和噪声来学习的。过拟合的概念通常用于描述一个模型，该模型非常适合给定的数据集，以至于它学会了基于信号和噪声进行预测，这使得它对其他样本的预测能力不如拟合不太精确的模型。

训练模型的部分目标是尽可能减少任何局部噪声对学习的影响。保留一组数据进行测试的验证技术的目的是确保在训练期间对噪声的任何学习只发生在训练集本地的噪声上。训练误差和测试误差之间的差异可以用来理解模型实现之间的过度拟合程度。

我们已经在[第 1 章](01.html "Chapter 1. Unsupervised Machine Learning")、*无监督机器学习*中应用了交叉验证。测试过拟合模型的另一种有用的方法是以抖动的形式直接向训练数据集中添加随机噪声。2015 年 10 月，亚历山大·安希金通过卡格尔笔记本引入了这项技术，并提供了一个非常有趣的测试。概念简单；通过添加抖动并查看训练数据的预测精度，我们可以区分过度拟合的模型(随着我们添加抖动，其训练误差将更快增加)和拟合良好或拟合不良的模型:

![Understanding model robustness](images/B03722_08_04.jpg)

在这种情况下，我们能够绘制抖动测试的结果，以轻松识别模型是否过度抖动。从非常强的初始位置开始，随着少量抖动的增加，overfit 模型的性能通常会迅速下降。对于拟合较好的模型，增加抖动时的性能损失会大大降低，在低水平的增加抖动时，模型的过拟合程度尤其明显(拟合较好的模型往往优于过拟合的模型)。

让我们看看如何实现过度拟合的抖动测试。我们用一个熟悉的分数，`accuracy_score`，定义为正确预测的类标签比例，作为考试评分的依据。抖动是通过简单地向数据添加随机噪声(使用`np.random.normal`)来定义的，噪声量由可配置的`scale`参数定义:

```py
from sklearn.metrics import accuracy_score

def jitter(X, scale):
    if scale > 0:        
        return X + np.random.normal(0, scale, X.shape)
    return X

def jitter_test(classifier, X, y, metric_FUNC = accuracy_score, sigmas = np.linspace(0, 0.5, 30), averaging_N = 5):
    out = []

    for s in sigmas:
        averageAccuracy = 0.0
        for x in range(averaging_N):
            averageAccuracy += metric_FUNC( y, classifier.predict(jitter(X, s)))

        out.append( averageAccuracy/averaging_N)

    return (out, sigmas, np.trapz(out, sigmas))

allJT = {}
```

给定一个分类器、训练数据和一组目标标签，`jitter_test`本身就是定义为正常 sklearn 分类的包装器。然后调用分类器，根据首先调用`jitter`操作的数据版本进行预测。

此时，我们将开始创建大量数据集来运行抖动测试。我们将使用 sklearn 的`make_moons`数据集，通常用作可视化聚类和分类算法性能的数据集。这个数据集由两个类组成，它们的数据点形成交错的半圆。通过向`make_moons`添加不同数量的噪声并使用不同数量的样本，我们可以创建一系列示例来运行抖动测试:

```py
import sklearn
import sklearn.datasets

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

Xs = []
ys = []

#low noise, plenty of samples, should be easy
X0, y0 = sklearn.datasets.make_moons(n_samples=1000, noise=.05)
Xs.append(X0)
ys.append(y0)

#more noise, plenty of samples
X1, y1 = sklearn.datasets.make_moons(n_samples=1000, noise=.3)
Xs.append(X1)
ys.append(y1)

#less noise, few samples
X2, y2 = sklearn.datasets.make_moons(n_samples=200, noise=.05)
Xs.append(X2)
ys.append(y2)

#more noise, less samples, should be hard
X3, y3 = sklearn.datasets.make_moons(n_samples=200, noise=.3)
Xs.append(X3)
ys.append(y3)
```

完成后，我们接着创建一个`plotter`对象，我们将使用该对象直接根据输入数据显示模型的性能:

```py
def plotter(model, X, Y, ax, npts=5000):

    xs = []
    ys = []
    cs = []
    for _ in range(npts):
        x0spr = max(X[:,0])-min(X[:,0])
        x1spr = max(X[:,1])-min(X[:,1])
        x = np.random.rand()*x0spr + min(X[:,0])
        y = np.random.rand()*x1spr + min(X[:,1])
        xs.append(x)
        ys.append(y)
        cs.append(model.predict([x,y]))
    ax.scatter(xs,ys,c=list(map(lambda x:'lightgrey' if x==0 else 'black', cs)), alpha=.35)
    ax.hold(True)
    ax.scatter(X[:,0],X[:,1],
                 c=list(map(lambda x:'r' if x else 'lime',Y)), 
                 linewidth=0,s=25,alpha=1)
    ax.set_xlim([min(X[:,0]), max(X[:,0])])
    ax.set_ylim([min(X[:,1]), max(X[:,1])])
    return
```

我们将使用 SVM 分类器作为抖动测试的基础模型:

```py
import sklearn.svm
classifier = sklearn.svm.SVC()

allJT[str(classifier)] = list()

fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(11,13))
i=0
for X,y in zip(Xs,ys): 
    classifier.fit(X,y)
    plotter(classifier,X,y,ax=axes[i//2,i%2])
    allJT[str(classifier)].append (jitter_test(classifier, X, y))
    i += 1
plt.show()
```

抖动测试为评估模型过拟合提供了一种有效的手段，其性能与交叉验证相当；事实上，Minushkin 提供的证据表明，作为衡量模型拟合质量的工具，它的表现可以超过交叉验证。

这两种减轻过度拟合的工具在您的算法一次性处理数据或者底层趋势变化不大的情况下都能很好地工作。对于大多数单数据集问题(如大多数学术或网络存储库数据集)或底层趋势变化缓慢的数据问题来说，情况确实如此。

然而，在许多情况下，建模中涉及的数据可能会随着时间的推移在一个或几个维度上发生变化。这可能是因为数据采集方法的改变，通常是因为使用了新的仪器或技术。例如，自 2005 年以来的十年间，普通设备捕获的视频数据在分辨率和质量(以及大小！)的数据有所增加。无论您是使用视频帧本身，还是使用文件大小作为参数，您都将观察到特性的性质、质量和分布的显著变化。

或者，数据集变量的变化可能是由潜在趋势的差异引起的。度量和维度的经典数据模式概念又回来了，因为我们可以通过考虑哪些维度影响我们的度量来更好地理解数据变化是如何受到影响的。

关键的例子是时间。根据具体情况，许多变量会受到星期几、月份或季节变化的影响。在许多情况下，一个有用的选择可能是参数化这些变量(正如我们在上一章中所讨论的，诸如 one-hot 编码之类的技术可以帮助我们的算法学习解析这样的趋势)，特别是如果我们处理的是容易预测的周期性趋势(例如，一年中某个月份对给定位置围巾销售的影响)并且容易建模的话。

更成问题的类型的时间序列趋势是非周期性变化。就像前面的摄像机例子一样，某些类型的时间序列趋势会不可逆转地发生变化，而且变化的方式可能不容易预测。来自软件的遥测往往会受到发射遥测时软件实时构建的质量和功能的影响。随着构建随时间变化，遥测发送的值和从这些值创建的变量可能会在一夜之间以难以预测的方式发生根本变化。

人类行为是许多数据集中非常重要的因素，它有助于周期性和非周期性地变化。人们更多地在季节性假期购物，但也会根据新的社会或技术发展永久地改变他们的购物习惯。

这里增加的一些复杂性不仅来自于单个变量及其分布受时间序列趋势影响的事实，还来自相关因素及其相关变量之间的关系将如何变化。变量之间的关系可能会以可量化的方式发生变化。一个例子是，对于人类来说，身高和体重是两个变量，它们的关系因时间和地点而异。我们可以使用身体质量指数特征来跟踪这种关系，当在不同时间段或不同位置进行采样时，它显示出不同的分布。

此外，变量可以以另一种严肃的方式变化；也就是说，它们对高性能建模算法的重要性可能会随着时间而变化！某些变量的值在某些时间段高度相关，但在其他时间段相关性较低。例如，考虑气候和天气变量如何影响农业市场。对于一些作物和经营这些作物的公司来说，这些变量在一年的大部分时间里都相当不重要。然而，在作物生长和收获的时候，它们变得至关重要。更复杂的是，这些因素的重要性还与位置(和当地气候)有关。

建模的挑战显而易见。对于经过一次训练并在新数据上再次运行的模型，管理数据更改可能会带来严重的挑战。对于基于新输入数据动态重新计算的模型，随着变量分布和关系的变化以及可用变量在生成有效解决方案时变得或多或少有价值，数据变化仍然会产生问题。

在您的 ML 应用程序中，成功管理数据变更的部分关键是识别变更可能影响特性分布、关系和特性重要性的维度(也有共同的过失)，模型将尝试了解这些维度。

一旦您了解了数据中哪些因素可能会影响过度拟合，您就可以更好地开发有效管理这些因素的解决方案。

尽管如此，构建一个能够解决任何潜在问题的单一模型仍将极具挑战性。对此的简单回答是，如果一个人面临严重的数据更改问题，解决方案可能不是试图用单一模型来解决它们！在下一节中，我们将研究集成方法来提供更好的答案。

### 识别建模风险因素

虽然在许多情况下，随着时间的推移，识别哪些元素会给模型带来风险是非常简单的，但是使用结构化的过程进行识别会有所帮助。本节简要描述了一些启发式方法和技术，您可以使用它们来筛选模型中的数据变更风险。

大多数数据科学家都有一个数据字典，用于一般用途或自动化应用的数据集。如果数据或应用程序很复杂，这种情况尤其可能发生，但是保存数据字典通常是一种很好的做法。在识别风险因素时，您可以做的一些最有效的工作是浏览这些功能，并根据不同的风险类型对它们进行标记。

我倾向于使用的一些标签包括:

*   **纵向变量**:该参数是否会由于纵向趋势而在很长一段时间内发生变化，而这些趋势在您现有的训练数据范围内并不完全可见？最明显的例子是生态季节，它影响着人类行为的许多领域，以及许多依赖于一些更基本的气候变量的事物。其他纵向趋势包括财政年度和工作月份，但扩展到包括与您的调查领域相关的许多其他纵向趋势。新 iPhone 机型的生命周期或田鼠的种群流动可能是一个重要的纵向因素，这取决于你的工作性质。
*   **缓慢变化**:随着时间的推移，这个分类参数有可能获得新的值吗？这个概念是从数据仓库最佳实践中借用来的。经典意义上缓慢变化的维度将获得新的参数代码(例如，当一家新店开业或一个新案例被识别时)。如果管理不当或者出现的数量足够多，这些可以完全抛弃你的模型。缓慢变化的数据的另一个影响是，它会开始影响你的特性的分布，这可能会更难处理。这可能会对模型的有效性产生重大影响。
*   **关键参数**:数据值监控和决策边界/回归方程重新计算的组合通常可以很好地处理一定数量的缓慢变化的数据和季节性方差，但是如果您看到意外大量的新案例或案例类型，特别是当它们影响您的模型严重依赖的变量时，请考虑采取行动。因此，也要确保你知道你的解决方案最依赖哪些变量！

以这种方式标记的过程是有帮助的(不仅仅是作为你自己记忆的输出)，主要是因为它帮助你做以下事情:

*   组织你的期望，并为你监控准备的发展制定一个清单。如果您不能至少跟踪您的纵向变量和缓慢变化的参数变化，那么除了重新计算时支持的参数变化及其(可能缓慢下降的)性能度量之外，您实际上对模型的任何输出都是盲目的。
*   调查缓解措施(例如，改进的规范化或额外的参数，这些参数编码了数据变化的维度)。在许多方面，缓解和添加参数是处理数据更改的最佳解决方案。
*   使用构建的数据集设置稳健性测试，其中您的风险特征被故意改变以模拟数据变化。在这些条件下对你的模型进行压力测试，找出它到底能承受多大的方差。有了这些信息，您可以轻松地将自己设置为使用您的监控值作为早期警报系统；一旦数据变化超过某个安全阈值，您就知道模型性能会下降多少。

## 管理模型稳健性的策略

我们已经讨论了许多有效的集成技术，这些技术使我们能够平衡对高性能和健壮模型的双重需求。然而，在我们阐述和使用这些技术的过程中，我们必须决定如何以及何时降低模型的性能以提高健壮性。

事实上，本章的一个共同主题是如何平衡创建一个有效的、高性能的模型的冲突目标，同时又不会使这个模型过于不灵活而无法响应数据变化。到目前为止，我们看到的许多解决方案都要求我们权衡一种结果和另一种结果，这并不理想。

在这一点上，值得我们从更广的角度来看待我们的选择，并借鉴互补的技术。在不断发展的商业环境中，对稳健的、高性能的统计模型的需求既不是新的，也不是未得到处理的；信用风险建模等领域在不断变化的领域中应用统计建模的历史悠久，并且已经开发出有效的决策管理方法以取得成功。数据科学家可以通过使用这些既定技术来帮助组织我们自己的模型，从而将其中一些技术转化为我们自己的利益。

一种有效的方法是 **冠军/挑战者**，一种以测试为中心的方法，包括运行多个并行模型配置。除了其输出被应用的模型(用于指导业务活动或信息报告)，冠军/挑战者方法培训一个或多个替代模型配置。

通过维护和监控多个模型，可以安排在替代模型性能超过当前模型时替换当前模型。这通常是通过维护所有模型的性能评分过程并观察结果来完成的，这样就可以手动决定是否以及何时切换到挑战者。

虽然最简单的实现可能涉及到在性能超过主模型时立即切换到挑战者，但这很少实现，因为特定挑战者模型存在暴露于局部最小值的风险(例如，一周中的某一天或一年中的某一月的局部趋势)。花费大量时间评估挑战者模型是正常的，尤其是在敏感应用程序之前。在复杂的真实案例中，人们甚至可能希望通过向有希望的挑战者提供治疗案例的样本来进行额外的测试，以确定它是否对冠军产生了显著的提升。

除了简单的“取代挑战者”继任规则，还有一些创新的空间。基于投票的方法非常常见，其中训练好的集合的顶级子集在个案的基础上提供分数，这些分数被视为(加权或未加权)投票。另一种方法是使用“T2”投票系统，即每个投票人按照偏好对候选方案进行排序。在集合的上下文中，人们通常会给每个单独模型的预测分配一个与其逆秩相等的点值(保持每个模型独立！).然后人们可以将这些投票组合起来(通常尝试一系列不同的权重)以产生一个结果。

投票可以在大量模型的情况下相当好地执行，但是取决于特定的建模环境和因素，例如不同投票者的相似性。正如我们在本章前面所讨论的，使用皮尔逊相关系数等测试来确保您的模型集既有性能又不相关是至关重要的。

人们可能发现特定类别的输入数据(例如，具有特定分段标签的用户)被给定的挑战者更有效地对待，并且可能实现一个案例路由系统，其中多个冠军处理不同的用户子组。这种方法与增强集成的好处有些重叠，但可以通过分离关注点来帮助生产环境。然而，维护多个冠军将增加您的数据团队的监控和监督负担，因此如果不是完全必要的话，最好避免这种选择。

需要解决的一个主要问题是我们如何对我们的模型进行评分，尤其是因为存在直接的实际挑战。特别是，考虑到类标签(用于指导正确性)通常不可用，很难在实际环境中比较多个模型。在预测环境中，这个问题由于冠军模型的预测通常用于采取改变预测事件的行动而变得更加复杂。这项活动使得很难断言挑战者模型的预测会有怎样的表现；根据冠军的预测采取行动，我们无法确认我们模型的结果！

最常见的实施过程是为每个挑战者模型提供一个统计上可行的输入数据样本，然后比较每种方法的升力。这种方法固有地限制了一些建模问题可以支持的挑战者的数量。另一个选择是从任何治疗活动中只留下一个统计上可行的样本，并使用它来创建一个单一的回归测试。这项测试适用于冠军和挑战者的整套模型，为比较提供了有意义的基础。

这种方法的缺点是，无论为测试用例生成正确的类标签需要多长时间，到一个更有效的模型的变化总是会跟踪数据的变化。虽然在许多情况下，这并不严重(冠军模型在生成精确模型所需的时间内保持不变)，但在基础条件与模型的训练时间相比变化迅速的背景下，它可能会出现问题。

### 注

模型训练时间和数据变化频率之间的关系值得简单评论一下。它并不总是如此明确地陈述，但是应用机器学习环境中的典型目标是将训练时间与数据变化频率的因子减少到尽可能小的值。从最坏的情况来看，如果训练一个模型所需的时间长于该模型精确的时间长度(并且该比率等于或大于 1)，那么您的模型将永远不会生成可以直接驱动当前动作的当前结果。一般而言，高比率应促进审查和调整活动(要么调查在较低置信度下更快的分数交付是否带来更多价值，要么调整可控环境变量的变化速度)。

这个比率变得越小，你的团队就有越多的余地来应用你的模型的输出来驱动行动和产生价值。根据这个比率在您的建模环境中的变化和可量化程度，它可以作为您的自动化建模解决方案的健康度量在您的组织中推广。

这些替代模型可能只是下一个性能最好的集合配置；他们可能是老型号，留在周围观察。在复杂的操作中，一些挑战者被配置为处理不同的*假设*场景(例如，*如果该地区的温度比预期低 2°C 怎么办*或*如果销售额明显低于预期怎么办*)。这些模型可能是在与主模型相同的数据上训练的，或者是在模拟假设情景的故意扭曲或准备好的数据上训练的。

更多的挑战者往往更好(提供改进的健壮性和性能)，前提是挑战者不都是同一主题的微小变化。挑战者模型还为创新和测试提供了一个安全的场所，同时观察有效的挑战者可以提供有用的见解，了解您的冠军团队对一系列可能的环境变化有多强大。

您在本节中学习应用的技术为我们提供了工具，可以将我们现有的模型工具包应用到不断发展的环境中的实际应用中。本章还讨论了将 ML 模型应用于生产时可能出现的复杂情况；样本之间或跨维度的数据变化将导致我们的模型变得越来越无效。通过彻底解开数据变化的概念，我们变得能够更好地描述这种风险，并认识到它可能出现在哪里以及如何出现。

一章的剩余部分专门介绍了提高模型鲁棒性的技术。我们讨论了如何通过查看底层数据来识别模型降级风险，并讨论了一些有用的启发式方法。我们从现有的决策管理方法中学习和使用 Champion/Challenger，这是一个在包括应用机器学习在内的环境中有着悠久历史的备受关注的过程。冠军/挑战者帮助我们在良性竞争中组织和测试多个模型。结合有效的性能监控，模型替代的主动战术计划将为您提供更快、更可控的模型生命周期和质量管理，同时提供大量有价值的运营见解。

# 进一步阅读

也许最广泛和信息最丰富的合奏和合奏类型之旅是由卡格勒的竞争对手特里克里昂在 http://mlwave.com/kaggle-ensembling-guide/提供的。

关于 Netflix 获奖模式《务实的混沌》的讨论，请参考[http://www . stat . OSU . edu/~ dmsl/grand Prize 2009 _ BPC _ bellkor . pdf](http://www.stat.osu.edu/~dmsl/GrandPrize2009_BPC_BellKor.pdf)。关于网飞对不断变化的商业环境如何让这种 100 万美元的模式变得多余的解释，请参考网飞理工大学的博客。

关于将随机森林集合应用于商业环境的演练，为所有重要的诊断图表和推理提供了大量空间，请考虑 Arshavir Blackwell 的博客，网址为[https://citizen net . com/blog/2012/11/10/random-forests-ensembles-and-performance-metrics/](https://citizennet.com/blog/2012/11/10/random-forests-ensembles-and-performance-metrics/)。

关于随机森林的更多信息，我发现 scikit-learn 文档很有帮助:[http://sci kit-learn . org/stable/modules/generated/sklearn . ensemble . randomforestclaider . html](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)。

在[http://xgboost.readthedocs.io/en/latest/model.html](http://xgboost.readthedocs.io/en/latest/model.html)的 XGBoost 文档中提供了一个关于梯度增强树的很好的介绍。

有关 Alexander Guschin 参加 Otto 产品分类挑战赛的报道，请参考 No Free Hunch 博客:[http://blog . kaggle . com/2015/06/09/Otto-产品-分类-获奖者-面试-第二名-alexander-guschin/](http://blog.kaggle.com/2015/06/09/otto-product-classification-winners-interview-2nd-place-alexander-guschin/) 。

Alexander Minushkin 的过拟合抖动测试描述在[https://www . kaggle . com/miniushkin/introduction-kaggle-scripts/抖动-过拟合测试-笔记本](https://www.kaggle.com/miniushkin/introducing-kaggle-scripts/jitter-test-for-overfitting-notebook)中。

# 总结

在这一章中，我们涉及了很多方面。我们从引入集成开始，集成是竞争机器学习环境中一些最强大和最受欢迎的技术。我们结合专家知识和实际例子，介绍了将集成应用于机器学习项目所需的理论和代码。

此外，本章还专门用一节来讨论当您一次运行几周或几个月的模型时出现的独特注意事项。我们讨论了数据变化意味着什么，如何识别它，以及如何考虑防范它。我们特别考虑了如何创建并行运行的模型集的问题，您可以根据模型集中的季节变化或性能漂移在这些模型集之间进行切换。

在我们回顾这些技术的过程中，我们花了大量时间研究现实世界中的例子，具体目的是了解最佳数据科学家所需的创造性思维和广泛的知识。

这本书中的技术已经达到了这样一个程度，有了技术知识、可以重新应用的代码和对可能性的理解，你真的能够接受任何数据建模挑战。**
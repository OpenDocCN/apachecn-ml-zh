# 基于人工智能的系统基础

**人工智能** ( **AI** )在过去几年中一直走在技术的前沿，并已进入主流应用，如专家系统、移动设备上的个性化应用、自然语言处理中的机器翻译、聊天机器人、自动驾驶汽车等。然而，人工智能的定义一直是争议的话题。这主要是因为所谓的**人工智能效应**将过去已经通过人工智能解决的工作归类为非人工智能。根据一位著名的计算机科学家的说法:

Intelligence is whatever machines haven't done yet. – Larry Tesler

构建一个可以下棋的智能系统被认为是人工智能，直到 1996 年 IBM 计算机深蓝击败加里·卡斯帕罗夫。同样，处理视觉、语音和自然语言的问题曾经被认为是复杂的，但由于人工智能的影响，它们现在只会被认为是计算，而不是真正的人工智能。最近，人工智能已经能够解决复杂的数学问题、创作音乐和创作抽象画，人工智能的这些能力正在不断增加。未来人工智能系统与人类智力水平相当的点被科学家称为人工智能奇点。机器是否真的能达到人类的智力水平这个问题非常有趣*。*

许多人会认为，机器永远不会达到人类的智能水平，因为它们学习或执行智能任务的人工智能逻辑是由人类编程的，它们缺乏人类拥有的意识和自我意识。然而，一些研究人员提出了另一种观点，即人类意识和自我意识就像通过反馈从周围环境中学习的无限循环程序。因此，也有可能将意识和自我意识编程到机器中。然而，就目前而言，我们将把人工智能的这一哲学方面留到另一天，并将简单地讨论我们所知道的人工智能。

简而言之，人工智能可以被定义为机器(通常是计算机或机器人)以类似人类的智能执行任务的能力，拥有诸如推理、从经验中学习、归纳、破译含义和拥有视觉感知的能力等属性。我们将坚持这个更实际的定义，而不是看人工智能效应提出的哲学内涵和人工智能奇点的前景。虽然可能会有关于人工智能能实现什么和不能实现什么的争论，但最近基于人工智能的系统的成功故事已经铺天盖地。下图描述了人工智能最近的一些主流应用:

![](assets/623d9065-122c-4066-bfed-634f7ac3cd75.png)

Figure 1.1: Applications of AI

这本书将涵盖人工智能所有核心学科项目的详细实施，概述如下:

*   基于迁移学习的人工智能系统
*   基于自然语言的人工智能系统
*   基于生成性对抗网络的应用
*   专家系统
*   视频到文本的翻译应用
*   基于人工智能的推荐系统
*   基于人工智能的移动应用
*   基于人工智能的聊天机器人
*   强化学习应用

在这一章中，我们将简要地涉及到机器学习和深度学习的概念，这些概念是实现将在以下章节中涵盖的项目所需要的。

# 神经网络

神经网络是受人脑启发的机器学习模型。它们由神经处理单元组成，并以分层的方式相互连接。这些神经处理单元被称为**人工神经元**，它们执行与人脑中轴突相同的功能。在人脑中，树突接收来自邻近神经元的输入，并在将输入传递到神经元的胞体之前衰减或放大输入。在神经元的胞体中，这些被修饰的信号被加在一起并传递到神经元的轴突上。如果轴突的输入超过特定的阈值，信号就会传递到邻近神经元的树突。

人工神经元的工作原理可能与生物神经元的工作原理相同。它接收来自邻近神经元的输入。输入通过神经元的输入连接进行缩放，然后相加在一起。最后，相加的输入通过激活函数，激活函数的输出传递给下一层的神经元。

为了进行比较，生物神经元和人工神经元在下图中进行了说明:

![](assets/6527d133-7918-4ab3-96e8-36fa4181c4dc.png)

Figure 1.2: Biological neuron

下图显示了一个人工神经元:

![](assets/ed578913-a219-4604-be04-530487b57afa.png)

Figure 1.3: Artificial neuron 

现在，让我们看看人工神经网络的结构，如下图所示:

![](assets/b767da6e-2a08-4790-8e59-3081c2ab9651.png)

Figure 1.4: Artificial neural network

输入，即 *x ∈ R <sup>N</sup>* ，通过连续的神经单元层，以分层的方式排列。特定层中的每个神经元接收来自前一层神经元的输入，通过它们之间连接的权重进行衰减或放大。重量![](assets/4e191d12-e7be-4994-a0e2-cb0864478dd8.png)对应于层 *l* 中的*I<sup>th</sup>T8】神经元与层 *(l+1)* 中的*j<sup>th</sup>T14】神经元之间的重量连接。此外，特定层中的每个神经元单元*I**l*都伴有偏差![](assets/b6085bec-f07c-40e8-b725-bdbfef33657a.png)。神经网络预测输出![](assets/5ec2c1e6-86bc-435e-ad5c-67685b979479.png)，对于输入向量， *x ∈ R <sup> N </sup>* 。如果数据的实际标签是 *y* ，其中 *y* 取连续值，那么神经元网络通过最小化预测误差来学习权重和偏差，![](assets/686860b4-bb80-4174-b4cc-b61f26a86869.png)。当然，对于所有标记的数据点，误差必须最小化: *(* *x <sub>i</sub> ，y <sub> i </sub> )∀ <sub> i </sub> ∈ 1，2，。。。m* 。**

如果我们用一个共同的向量 *W* 来表示权重和偏差的集合，并且预测中的总误差用 *C* 来表示，那么通过训练过程，估计的 *W* 可以表示如下:

![](assets/973e52ab-5ebb-40a0-941c-20665d118f10.png)

同样，预测输出![](assets/ef875e3c-8643-4f92-a309-b92aefc033b7.png)可以由输入的函数 *x* 表示，该函数由权重向量 *W* 参数化，如下所示:

![](assets/9e08ed5e-7e12-46d1-a2cb-a2e343d9c8d2.png)

这样一个预测输出连续值的公式叫做**回归问题**。

对于两类二进制分类，交叉熵损失被最小化而不是平方误差损失，并且网络输出正类的概率而不是输出。交叉熵损失可以表示如下:

![](assets/c0fb9371-3b94-4ffa-9443-f51299bb5cb8.png)

这里， *p <sub>i</sub>* 是输出类的预测概率，给定输入 *x* ，并且可以表示为输入的函数， *x* ，由权重向量参数化，如下所示:

![](assets/90eddcaa-84e7-46c8-8b42-d34e3fd7ef91.png)

一般来说，对于多类分类问题(比如说 *n 个*类)，交叉熵损失由下式给出:

![](assets/b8e45aea-221b-44e3-bbc3-0d9e88a4cf2d.png)

这里，![](assets/82b31af0-64ea-440f-b4f3-281460353497.png)是 *j <sup>第</sup>T4】类的输出标签，用于 *i <sup>第</sup>T8】数据点。**

# 神经激活单位

神经网络中使用几种神经激活单元，这取决于体系结构和手头的问题。我们将讨论最常用的激活函数，因为这些函数在确定网络架构和性能方面起着重要作用。线性和 sigmoid 单位激活函数主要用于人工神经网络，直到 Hinton 等人发明的**校正线性单位** ( **ReLUs** )彻底改变了神经网络的性能。

# 线性激活单元

一个**线性激活单元**输出被衰减的神经元的总输入，如下图所示:

![](assets/d1c95a3f-f648-44c6-88be-744da68e0aee.png)

Figure 1.5: Linear neuron

如果 *x* 是线性激活单元的总输入，那么输出 *y* 可以表示如下:

![](assets/7db1c93b-6ac7-4b2c-b464-dd69836c6854.png)

# 乙状结肠激活单位

**sigmoid** **激活单元**、 *y* 的输出，作为其总输入的函数， *x* ，表示如下:

![](assets/e72ceed8-eaaa-4d3e-bc39-256e36d389e2.png)

由于 sigmoid 激活单元响应是一个非线性函数，如下图所示，它用于在神经网络中引入非线性:

![](assets/f54ce333-0cdb-400f-b9d1-22d60475291f.png)

Figure 1.6: Sigmoid activation function

自然界中任何复杂过程的输入输出关系一般都是非线性的，因此，我们需要非线性激活函数通过神经网络对其进行建模。用于两类分类的神经网络的输出概率通常由 sigmoid 神经单元的输出给出，因为它输出从 0 到 1 的值。输出概率可以表示如下:

![](assets/4e502901-d686-46cf-ba1c-e0b11d2c2707.png)

这里， *x* 表示输出层中 sigmoid 单元的总输入。

# 双曲正切激活函数

**双曲正切激活函数** ( **tanh** )的输出 *y* 是其总输入 *x* 的函数，如下所示:

![](assets/ff09283d-c4ae-42d3-8b20-5c6cb9523899.png)

tanh 激活功能输出范围为[ **-1** 、 **1** 的值，如下图所示:

![](assets/58f98f0c-6a81-4acc-bafb-9b0f683ad9c9.png)

Figure 1.7: Tanh activation function

需要注意的是，sigmoid 和 tanh 激活函数在输入的小范围内都是线性的，超过这个范围，输出就会饱和。在饱和区，激活函数的梯度(相对于输入)非常小或接近于零；这意味着它们非常容易出现消失梯度问题。正如您稍后将看到的，神经网络从反向传播方法中学习，其中一层的梯度取决于后续层中激活单元的梯度，直到最终输出层。因此，如果激活单元中的单元工作在饱和区域，那么很少的误差被反向传播到神经网络的早期层。神经网络最小化预测误差，以便通过利用梯度来学习权重和偏差。这意味着，如果梯度很小或消失为零，那么神经网络将无法正确学习这些权重。

# 整流线性单元

当神经元的总输入大于零时，ReLU 的输出是线性的，当神经元的总输入为负时，输出为零。这个简单的激活函数为神经网络提供了非线性，同时，它提供了一个相对于总输入的恒定梯度。这种恒定的梯度有助于防止神经网络出现饱和或消失的梯度问题，如激活函数，如 sigmoid 和 tanh 激活单元。ReLU 功能输出(如图*图 1.8* 所示)可以表示如下:

![](assets/f3c8b630-6ebc-4f71-903a-d192d27621f7.png)

ReLU 激活函数可以绘制如下:

![](assets/56ed1747-01f7-48fa-9a00-db7d1b05a8f9.png)

Figure 1.8: ReLU activation function

ReLU 的一个限制是输入负值的零梯度。这可能会减慢训练速度，尤其是在初始阶段。漏 ReLU 激活函数(如图*图 1.9* 所示)在这种情况下非常有用，在这种情况下，输出和梯度都是非零的，即使输入为负值。泄漏 ReLU 输出函数可以表示如下:

![](assets/048015a0-395a-46f0-bf04-524539aea052.png)

![](assets/66329819-1528-4067-afc8-bf3e505ecb09.png)

![](assets/7e701921-1d53-4bbb-9ed7-e386eacc553c.png)参数是为泄漏 ReLU 激活函数提供的，而对于参数 ReLU，![](assets/21c3900a-a283-44ba-b15e-21d1faf0b243.png)是神经网络将通过训练学习的参数。下图显示了泄漏 ReLU 激活函数的输出:

![](assets/908a6fec-a34a-4e27-a0a4-27dd3b5d84cc.png)

Figure 1.9: Leaky ReLU activation function

# softmax 激活单元

在多类分类问题的情况下， **softmax 激活单元**通常用于输出类概率。假设我们正在处理一个 *n* 类分类问题，对应于这些类的总输入由下式给出:

![](assets/1e6529dc-c80f-4914-b540-4a7a23382feb.png)

在这种情况下，软最大激活单元的 *k <sup>第</sup>* 类的输出概率由以下公式给出:

![](assets/2c4f3f2d-fb61-4823-bad9-632d16200fe2.png)

还有其他几个激活功能，大部分是这些基本版本的变体。我们将在接下来的章节中讨论不同项目中遇到的问题。

# 训练神经网络的反向传播方法

在反向传播方法中，通过梯度下降技术训练神经网络，其中组合权重向量 *W* 迭代更新，如下所示:

![](assets/80a9c3b5-27aa-462b-a309-dec4fdbf49cb.png)

这里，η是学习率， *W <sup>(t+1)</sup>* 和 *W <sup>(t)</sup>* 分别是迭代时的权重向量 *(t+1)* 和 *(t)* ， *∇C(W <sup>(t)</sup> )* 是成本函数或误差函数相对于权重向量的梯度， *W* 由 *w ∈ W* 概括的个体权重或偏差的先前算法可以表示如下:

![](assets/2a2d7a65-e5d6-4570-8400-3895193259bb.png)

从前面的表达式中可以看出，梯度下降学习方法的核心依赖于计算成本函数或误差函数相对于每个权重的梯度。

从微分的链式法则我们知道，如果我们有 *y = f(x)，z = f(y)* ，那么以下是正确的:

![](assets/c53a0c79-d20d-4f73-9d61-f2f8e93e8f00.png)

这个表达式可以推广到任何数量的变量。现在，让我们看看一个非常简单的神经网络，如下图所示，以便理解反向传播算法:

![](assets/98bc8f7e-872a-46ef-a018-c9ad01d911f8.png)

Figure 1.10: A network illustrating backpropagation

让网络的输入为二维向量，*x =【x<sub>1</sub>x<sub>2</sub><sup>T</sup>*，对应的输出标签和预测分别为 *![](assets/df5f56eb-23da-40f8-900d-1da3eecfb2d3.png)* 和 *![](assets/b3cffb09-935e-4bc2-a6d1-330919797695.png)* 。此外，让我们假设神经网络中的所有激活单元都是乙状结肠。让层 *(l-1)* 中连接任意单元 *i* 到层 *l* 中单元 *j* 的广义权重用 *![](assets/29efb244-a597-41d7-baee-9826abbacd0b.png)* 表示，层 *l* 中任意单元 *i* 中的偏差用 *![](assets/99d2725a-1b33-4aea-a0b1-7631b21edbc1.png)* 表示。让我们导出一个数据点的梯度；总梯度可以计算为训练(或小批量)中使用的所有数据点的总和。如果输出是连续的，那么可以选择损失函数 *C* 作为预测误差的平方:

![](assets/bb6a924b-9414-4008-b7a8-ee6cc0d11649.png)

由集合 *W* 累积表示的网络的权重和偏差可以通过相对于 *W* 向量最小化成本函数来确定，如下所示:

![](assets/7de557d6-4617-45f4-8e7f-aeb5523343d5.png)

为了通过梯度下降迭代地执行成本函数的最小化，我们需要计算成本函数相对于每个权重的梯度 *w ∈ W* ，如下所示:

![](assets/c4b40a1e-3fc2-4c2c-b5be-1d20c9b34f17.png)

现在我们已经有了我们需要的一切，让我们计算成本函数的梯度， *C* ，相对于权重， *![](assets/8ef28fd7-2ae7-4473-bfcd-9020f9bb8903.png)* 。利用微分的链式法则，我们得到如下结果:

![](assets/0b0d48f2-769e-4477-bc38-ba07495015a2.png)

现在让我们看看下面的公式:

![](assets/8c25c79b-a37b-455f-95cc-e0501608846b.png)

正如你在前面的表达式中看到的，导数只不过是预测中的误差。通常，在回归问题的情况下，输出单元激活函数是线性的，因此以下表达式适用:

*![](assets/714abd7d-0c22-40db-80f2-bfc0e479ef6a.png)*

因此，如果我们计算成本函数相对于输出单位的总输入的梯度，它将是 *![](assets/45edd36c-31ff-4c19-b6e9-2fd00488402a.png)* 。这仍然等于输出预测的误差。

作为传入权重和激活的函数，输出单元的总输入可以表示如下:

![](assets/153c33ee-f998-4650-be8d-a77f9ef8ffbe.png)

这意味着， *![](assets/23be1d62-249e-47a0-8ddc-72bf17094dbb.png)* 和成本函数相对于权重的导数， *![](assets/4bc4d5a7-a122-417f-b35d-479e4a793029.png)* ，对输出层的输入有贡献是通过以下给出的:

![](assets/34c1605c-eb43-4d09-b029-b8177ecd1dc6.png)

如您所见，在计算成本函数的梯度时，相对于最终输出层之前的层中的权重，误差是反向传播的。当我们计算成本函数相对于广义权重的梯度时，这变得更加明显。我们取 *j=1* 和 *k=2* 对应的权重；也就是![](assets/5b8b2334-2462-449b-b31f-360dc3027ca7.png)。成本函数 *C* 相对于该权重的梯度可以表示如下:

![](assets/474751ea-71f8-4c57-9d16-1679ed2fbea5.png)

现在，![](assets/e3b5f588-54b7-4b7f-a624-20c8c63fe4f5.png)，也就是说，![](assets/d5f34043-fdeb-48ca-bf1b-d1a1915ba77d.png)。

因此，一旦我们计算出成本函数相对于神经元总输入的梯度![](assets/01b2beed-5ae3-478a-b99c-77eca4595b96.png)，任何权重的梯度 *w* ，对总输入的贡献 *s* ，可以通过简单地乘以与权重相关的激活 *z* 来获得。

现在，成本函数相对于总输入的梯度![](assets/e254c4c2-01df-42fe-a32b-94153a25e69b.png)可以通过链式法则再次导出，如下所示:

![](assets/ff5d7314-4a37-458c-933b-25a883f492bd.png)

由于神经网络的所有单元(输出单元除外)都是 sigmoid 激活函数，因此情况如下:

![](assets/665d5aaa-1fa7-4ab0-a7a8-5961d7faaf77.png)

![](assets/b43669e7-d10c-4ad9-bc67-b404ec992de1.png)

结合 *(1)* 、 *(2)* 、 *(3)* ，我们得到如下结果:

![](assets/ed1832d2-e65e-4568-8594-f5ded856cfe3.png)

在前面导出的梯度表达式中，您可以看到预测中的误差![](assets/60984e36-9d78-4e8d-9518-fc92f78f55a4.png)通过将其与相关激活和权重(根据微分链规则)相结合进行反向传播，以计算每一层权重的梯度，因此在人工智能术语中称为反向传播。

# 卷积神经网络

**卷积神经网络** ( **中枢神经系统**)利用卷积运算从具有相关拓扑结构的数据中提取有用信息。这最适合图像和音频数据。当输入图像通过卷积层时，产生几个输出图像，称为**输出特征图**。输出要素图检测要素。初始卷积层中的输出特征映射可以学习检测基本特征，例如边缘和颜色成分变化。

第二卷积层可以检测稍微复杂的特征，例如正方形、圆形和其他几何结构。当我们通过神经网络前进时，卷积层学习检测越来越复杂的特征。例如，如果我们有一个分类图像是猫还是狗的美国有线电视新闻网，神经网络底部的卷积层可能会学习检测头部、腿部等特征。

*图 1.11* 展示了一个 CNN 的架构图，它处理猫和狗的图像，以便对它们进行分类。图像通过一个卷积层，帮助检测相关特征，如边缘和颜色组成。ReLU 激活增加了非线性。跟随激活层的汇集层总结了局部邻域信息，以便提供一定量的**平移不变性**。在理想的有线电视新闻网中，这种卷积-激活-汇集操作在网络到达密集连接之前要执行几次:

![](assets/332c2f90-aae5-4b98-b417-ce942177e184.png)

Figure 1.11: CNN architecture 

当我们通过这样一个具有几个卷积-激活-汇集操作的网络时，图像的空间分辨率降低，而输出特征图的数量在每个层中增加。卷积层中的每个输出特征图都与一个滤波器内核相关联，其权重通过 CNN 训练过程来学习。

在卷积运算中，滤波器核的翻转版本被放置在整个图像或特征图上，并且为输入图像或特征图上的每个位置计算滤波器核输入值与相应图像像素或特征图值的点积。已经习惯于普通图像处理的读者可能已经使用了不同的滤波器核，例如高斯滤波器、索贝尔边缘检测滤波器等，其中滤波器的权重是预先定义的。卷积神经网络的优点是通过训练过程确定不同的滤波器权重；这意味着，针对卷积神经网络正在处理的问题，滤波器被更好地定制。

当卷积运算涉及在输入的每个位置覆盖滤波器内核时，卷积被称为具有一个步长。如果我们选择跳过一个位置，同时覆盖滤波器内核，那么卷积是以两个步长执行的。一般来说，如果在将滤波器内核覆盖在输入上时跳过了 *n* 个位置，则卷积被认为是以 *(n+1)* 的步长执行的。大于 1 的步幅减小了卷积输出的空间维度。

通常，卷积层后面是汇集层，它基本上总结了邻域中的输出特征图激活，由汇集的感受野决定。例如，一个 2×2 感受野将收集四个相邻输出特征图激活的局部信息。对于最大池操作，选择四次激活的最大值作为输出，而对于平均池操作，选择四次激活的平均值。池化会降低要素地图的空间分辨率。例如，对于具有 2×2 感受野的 224×224 大小的特征图汇集操作，特征图的空间维度将减少到 112×112。

需要注意的一点是，卷积运算减少了每一层要学习的权重数量。例如，如果我们有一个空间维度为 224 x 224 的输入图像，并且下一层的期望输出是 224 x 224 的维度，那么对于具有全连接的传统神经网络，要学习的权重数是 224 x 224 x 224 x 224。对于输入输出维数相同的卷积层，我们需要学习的只是滤波器核的权重。因此，如果我们使用 3×3 的滤波器内核，我们只需要学习 9 个权重，而不是 224×224×224×224*权重。这种简化是可行的，因为像图像和音频这样的结构在局部空间邻域中具有很高的相关性。*

 *输入图像经过几层卷积和汇集操作。随着网络的发展，要素地图的数量会增加，而图像的空间分辨率会降低。在卷积汇集层的末端，特征映射的输出被馈送到完全连接的层，随后是输出层。

输出单位取决于手头的任务。如果我们执行回归，则输出激活单元是线性的，而如果是二元分类问题，则输出单元是 sigmoid。对于多类分类，输出层是 softmax 单元。

在本书的所有图像处理项目中，我们将以某种形式使用卷积神经网络。

# 递归神经网络

**递归神经网络** ( **RNNs** )在处理顺序或时间数据时非常有用，其中给定实例或位置的数据与先前时间步长或位置的数据高度相关。RNNs 在处理文本数据方面已经非常成功，因为给定实例中的一个单词与它前面的单词高度相关。在 RNN，在每个时间步长，网络执行相同的功能，因此，术语**在其名称中重复出现**。下图展示了 RNN 的架构:

![](assets/0c426b93-140c-48a7-b982-e649cbaac4e3.png)

Figure 1.12: RNN architecture 

在每个给定的时间步， *t* ，一个记忆状态，*h*<sub xmlns:epub="http://www.idpf.org/2007/ops">T5【t】</sub>是基于先前的状态， *h <sub>t-1</sub>* ，在步骤 *(t-1)* 和输入， *x <sub>t</sub>* ，在时间步 *t* 。新状态下， *h <sub>t</sub>* <sub xmlns:epub="http://www.idpf.org/2007/ops">*，*</sub> 用于预测输出， *o <sub>t</sub>* <sub xmlns:epub="http://www.idpf.org/2007/ops">*，*</sub> at step *t* 。控制 RNNs 的方程式如下:

![](assets/438f6f9e-0b82-497a-a27a-b6908e54889f.png)

![](assets/4ce6cd6d-4a3d-4c78-9aa6-364d288f20c7.png)

如果我们在预测一个句子中的下一个单词，那么函数 *f <sub>2</sub>* 通常是词汇中单词的软最大函数。功能 *f <sub>1</sub>* 可以是基于手边问题的任何激活功能。

在 RNN 中，步骤 *t* 中的输出误差试图校正由 *k ∈ 1，2，.。。t-1* ，通过传播先前时间步骤中的错误。这有助于 RNN 了解彼此相距甚远的单词之间的长期依存关系。实际上，由于渐变问题的消失和爆发，通过 RNN 学习如此长的依赖关系并不总是可能的。

众所周知，神经网络是通过梯度下降来学习的，时间步长 *t* 中的单词与先前序列步长 *k* 中的单词之间的关系可以通过记忆状态![](assets/f6a98a54-7272-4859-bbdd-8f2347ec8a72.png)相对于记忆状态 *![](assets/bf39a48c-cbc5-4c7d-aa22-c80e1a0f3b9c.png) ∀ i* 的梯度来学习。这用下面的公式表示:

![](assets/4b851df6-5d8f-4c92-861e-2c0066c19254.png)

如果从序列步骤 *k* 处的记忆状态![](assets/b7da7650-c906-4c3d-9191-77ef72550882.png)到序列步骤 *(k+1)* 处的记忆状态![](assets/ce311540-8fcf-46a5-bf55-4b9506efed8f.png)的权重连接是由*u<sub>ii</sub>∈W<sub>hh</sub>*给出的，则以下情况成立:

![](assets/94bf384a-86e7-413d-ae16-9b3f5249eef1.png)

在上式中，![](assets/6e3eda2d-3282-41ef-a0eb-12a7860c951b.png)是在时间步长*(k+1)*时对记忆状态 *i* 的总输入，因此情况如下:

![](assets/82fd4549-3b28-4289-9145-320579f8f364.png)

![](assets/6034762c-e89b-43a9-823a-588dae6f05fd.png)

现在我们已经准备好了一切，很容易理解为什么消失梯度问题会出现在 RNN。从前面的等式 *(3)* 和*(4)*中，我们得到以下结果:

![](assets/a5818e53-89c6-4a7a-8f79-f71fdfc2535d.png)

对于 RNNs，函数 *f <sub>2</sub>* 通常为 sigmoid 或 tanh，其存在饱和问题，即低梯度超出输入值的指定范围。现在，由于 *f <sub>2</sub>* 导数彼此相乘，如果激活函数的输入在饱和区操作，梯度![](assets/262411c9-5926-4e82-913c-5a58147cc084.png)可以变为零，即使对于相对适中的值 *(t-k)* 。即使 *f <sub> 2 </sub>* 函数不在饱和区运行，乙状结肠的 *f <sub> 2 </sub>* 函数的梯度始终小于 *1* ，因此很难学习序列中单词之间的遥远依赖关系。类似地，由于![](assets/0a6a961e-803e-4a05-aa14-d1b9b444e272.png)因素，可能会出现爆炸性的梯度问题。假设台阶 *t* 和 *k* 之间的距离在 *10* 左右，而重量 *u <sub>ii</sub> ，*在 2 左右。在这种情况下，梯度将被放大两倍，2 <sup> 10 </sup> = 1024，导致爆炸梯度问题。

# 长短期记忆(LSTM)细胞

消失的梯度问题在很大程度上由 RNNs 的修改版本处理，称为**长短期记忆** ( **LSTM** )细胞。长短期存储单元的架构图如下:

![](assets/eab0d93b-3c6d-4fb8-a9ac-d49481457c76.png)

Figure 1.13: LSTM architecture 

LSTM 介绍了细胞状态，*C<sub>t</sub>T3，除了记忆状态，*h<sub>t</sub>T7】，这些你在学习 RNNs 的时候就已经看到了。单元状态由三个门调节:忘记门、更新门和输出门。遗忘门决定从先前的单元状态 *C <sub>t-1</sub>* 保留多少信息，其输出表示如下:**

![](assets/00985346-4740-4212-97ff-0506b23e7d21.png)

更新门的输出表示如下:

![](assets/16cfb5c1-3e84-497e-8725-fc5c0e571a30.png)

潜在的新候选小区状态![](assets/9da8cf00-c42f-4fd3-be55-18a2334cf1c6.png)表示如下:

![](assets/d10b017e-3e19-4c63-8ece-90ca7b3d2dfe.png)

基于先前的单元状态和当前的潜在单元状态，通过以下方式给出更新的单元状态输出:

![](assets/e4d692b3-3335-41cb-a793-1d6504dda376.png)

单元状态的信息并非全部传递到下一步，应释放多少单元状态到下一步由**输出门**决定。输出门的输出通过下式给出:

![](assets/959381ee-2245-42ab-92a9-fd26d61d3756.png)

基于当前单元状态和输出门，通过以下方式给出传递到下一步的更新的存储器状态:

![](assets/55a8e2c1-d673-4016-b4f2-a2baf36f73ed.png)

现在来了一个大问题:LSTM 如何避免消失的梯度问题？在 LSTM![](assets/f1facab3-c62a-44c3-8892-0b8ead3bec9e.png)的等价物由![](assets/b8df6cd0-edae-4d0f-9cf8-a2815a1a3d8f.png)给出，可以用乘积形式表示如下:

![](assets/0467935c-2261-4019-86e5-d5cb976fdcfb.png)

现在，单元状态单位的循环由下式给出:

![](assets/eb7d80c6-f2eb-44c2-8272-555b5611da6d.png)

由此，我们得出以下结论:

![](assets/636e59ba-65ee-410a-8dce-c19ce20565c6.png)

结果，梯度表达式![](assets/b78e0488-2d7f-46c7-a991-ca4eaf621665.png)变成如下:

![](assets/78f1eac4-0f48-4f0f-8521-344d3a317e9d.png)

正如你所看到的，如果我们能保持遗忘细胞状态在 1 附近，梯度几乎不会减弱，LSTM 不会受到消失梯度问题的影响。

我们将在本书中看到的大多数文本处理应用程序都将使用 LSTM 版本的 RNNs。

# 生成性对抗网络

**生成性对抗网络**，俗称 **GANs** ，是通过生成器 *G* 学习特定概率分布的生成模型。生成器 *G* 用鉴别器 *D* 玩零和极小极大游戏，两者都在达到纳什均衡之前随着时间演变。生成器尝试生成与给定概率分布 *P(x)* 生成的样本相似的样本，而鉴别器 *D* 尝试将生成器 *G* 生成的假数据样本与原始分布的数据样本区分开来。生成器 *G* 试图通过转换从噪声分布 *P(z)* 提取的样本 *z* 来生成与来自 *P(x)* *、*的样本相似的样本。鉴别器 *D* 在造假时学习将生成器 *G* 生成的样本标记为*G(z)*； *x* 原属 *P(x)* 。在极小极大博弈的均衡状态下，生成器将学会产生与原始分布 *P(x)* 生成的样本相似的样本，从而出现以下情况:

![](assets/0bb90a7f-37ac-4079-8896-baa81ed7b81d.png)

下图说明了学习 MNIST 数字概率分布的 GAN 网络:

![](assets/c8c7095f-4435-4ed0-a46b-3b89ed954f90.png)

Figure 1.14: GAN architecture 

鉴别器最小化的代价函数是二进制交叉熵，用于区分属于概率分布 *P(x)* 的真实数据点和生成器生成的虚假数据点(即 *G(z)* ):

![](assets/b9cb9aa1-7eac-4174-983d-cb5be41b1eff.png)

生成器将尝试最大化由(1)给出的相同成本函数。这意味着，优化问题可以用效用函数 *U(G，D)* 公式化为一个极小极大玩家，如下图所示:

![](assets/56db8673-21ba-456d-94a5-f78f8d33506b.png)

通常，为了测量给定概率分布与给定分布的匹配程度，使用了*f*-散度度量，例如**库尔巴克-莱布勒** ( **KL** )散度、詹森香农散度和巴特查亚距离。例如，两个概率分布 *P* 和 *Q* 之间的 KL 散度由下式给出，其中期望是关于分布 *P* :

![](assets/a28bf1ff-ec23-480a-9740-060b00b8ab64.png)

类似地， *P* 和 *Q* 之间的詹森香农散度如下:

![](assets/17bdf041-b5b0-442c-aea2-d56561c1f54e.png)

现在回到 *(2)* ，表达式可以写成:

![](assets/0c60cfa5-eb0a-4114-aa84-beab07d5a6cc.png)

这里， *G(x)* 是发生器的概率分布。将期望扩展成它的积分形式，我们得到如下结果:

![](assets/f5932e0c-dc8c-4041-abe9-24e33bcfc95f.png)

对于固定的发电机分布，*G(x)**如果下列条件成立，效用函数相对于鉴别器将处于最小值:*

 *![](assets/ec1949f8-e469-4633-9aaf-d857c5f0831c.png)

将 *(3)* 中的 *(5)* 代入 *D(x)* ，得到如下结果:

![](assets/9dd0ea39-6a35-49d3-aa07-47e8242fd453.png)

现在，发电机的任务是最大化效用，![](assets/171ac44a-3b7b-4819-9214-46d7b1e58324.png)，或者最小化效用，![](assets/0e8e967d-8582-409c-ae34-4c843db5d7f7.png)。![](assets/52aebda1-9abf-47bc-a5cc-f5ae4530e691.png)的表达可以重新安排如下:

![](assets/2e348883-3d4b-421d-940e-8c0c8a593af0.png)

![](assets/63acc434-0231-447f-a331-5afab842bd9a.png)

![](assets/8893fadf-3fbf-4c42-bb8d-7a27f14dcb76.png)

因此，我们可以看到生成器最小化![](assets/18728b2c-5f24-4bbc-888d-541116e69eeb.png)相当于最小化真实分布 *P(x)* 和生成器生成的样本分布 *G* (即 *G(x)* )之间的詹森香农散度。

训练一个 GAN 不是一个简单的过程，在训练这样一个网络时，我们需要考虑几个技术因素。我们将使用先进的 g an 网络在[第 4 章](04.html)、*使用 GAN*构建时尚行业的跨域风格转移应用。

# 强化学习

**强化学习**是机器学习的一个分支，通过采取特定的行动，使机器和/或代理能够在特定的环境中最大化某种形式的奖励。强化学习不同于有监督和无监督学习。强化学习广泛应用于博弈论、控制系统、机器人学和其他新兴的人工智能领域。下图说明了强化学习问题中代理和环境之间的交互作用:

![](assets/13aa6565-1619-42b6-a595-a2bf486f0a6e.png)

Figure 1.15: Agent-environment interaction in a reinforcement learning model

# q 学习

我们现在来看一个流行的强化学习算法，叫做 **Q 学习**。q 学习用于为给定的有限马尔可夫决策过程确定最优动作选择策略。一个**马尔可夫决策过程**由一个状态空间 *S* 定义；一个动作空间，*A*；一个立竿见影的奖励集，*R*；下一个状态的概率， *S <sup>(t+1)</sup>* ，给定当前状态，*S<sup>(t)</sup>*；一个电流动作，*一个<sup>(t)</sup>T21；*P(S<sup>(t+1)</sup>/S<sup>(t)</sup>；r<sup>(t)</sup>)*；和折扣系数![](assets/a8f10f38-6189-4147-99f7-5cecb3de6abd.png)。下图说明了一个马尔可夫决策过程，其中下一个状态取决于当前状态和在当前状态下采取的任何操作:*

![](assets/83330458-c0b9-4660-a1e3-6cd4927244a6.png)

Figure 1.16: A Markov decision process

假设我们有一系列状态、动作和相应的奖励，如下所示:

![](assets/3c565184-9ac9-488b-8caa-6136105ef059.png)

如果考虑长期奖励， *R <sub>t</sub>* ，在第 *t* 步，等于每一步的即时奖励之和，从 *t* 一直到结束，如下:

![](assets/94a7a7da-3528-4fb2-9e42-1af592e0c024.png)

现在，一个马尔可夫决策过程是一个随机过程，不可能每次都得到同样的下一步， *S <sup>(t+1)</sup>* ，基于 *S <sup>(t)</sup>* 和*a<sup>(t)</sup>*；所以，我们对未来的奖励应用一个折扣因子![](assets/ea70164f-5568-4256-8b57-5b94e2423042.png)。这意味着，长期奖励可以更好地表示如下:

![](assets/4a4b48fe-0a74-4d0f-92ad-bad7fdc7fb35.png)

既然在时间步 *t* 上，眼前的奖励已经实现了，要使长期奖励最大化，我们需要通过选择一个最优的动作，使时间步 *t+1* (即 *R <sub>t+1</sub>* 上的长期奖励最大化。通过采取动作 a *<sup>(t)</sup>* 在状态 a*S<sup>(t)</sup>*预期的最大长期奖励由以下 Q 函数表示:

![](assets/b3ecdb7c-d4cf-48a2-af93-c969b62fb41e.png)

在每个状态下， *s ∈ S* ，Q-learning 中的代理试图采取一个动作，![](assets/06b5dce2-74cb-4521-869a-cdf586c86f70.png)，使其长期回报最大化。Q 学习算法是一个迭代过程，其更新规则如下:

![](assets/b6e4a367-e0aa-406d-bd8b-5e1b2cb8c1d7.png)

如您所见，该算法的灵感来自长期奖励的概念，如 *(1)* 所示。

状态 *s <sup>(t)</sup>* 采取行动*a<sup>(t)</sup>*的整体累计奖励 *Q(s <sup>(t)</sup> 、a <sup>(t)</sup> )* ，取决于眼前的奖励 r *<sup>(t)</sup>* ，以及我们在新的一步所能期望的最大长期奖励 s*在马尔可夫决策过程中，新状态 s *<sup>(t+1)</sup>* 随机依赖于当前状态 s *<sup>(t)</sup>* ，通过形式的概率密度/质量函数*P(S<sup>(t+1)</sup>/S<sup>(t)</sup>采取的行动；r <sup>(t)</sup> )* 。*

 *该算法基于![](assets/bdb0479f-f8a3-491a-a423-17d150e6d6fe.png)的值，通过对旧的期望和新的长期奖励进行加权平均，不断更新期望的长期累积奖励。

一旦我们通过迭代算法构建了 *Q(s，a)* 函数，在基于给定状态 *s* 玩游戏时，我们可以采取最佳动作![](assets/d91fdd02-4626-4db2-9fc4-1a656f64dde2.png)，作为最大化 Q 函数的策略:

![](assets/88e6ee5c-d64d-4d70-a9cf-ee3eb0e6c32a.png)

# 深度学习

在 Q 学习中，我们通常使用有限的一组状态和动作；这意味着，表格足以保存 Q 值和奖励。然而，在实际应用中，状态和适用动作的数量大多是无限的，需要更好的 Q 函数逼近器来表示和学习 Q 函数。这就是深层神经网络的拯救之处，因为它们是通用函数逼近器。我们可以用一个神经网络来表示 Q 函数，该网络将状态和动作作为输入，并提供相应的 Q 值作为输出。或者，我们可以仅使用状态来训练神经网络，并将输出作为对应于所有动作的 Q 值。下图说明了这两种情况。由于 Q 值是奖励，我们正在处理这些网络中的回归:

![](assets/673b706b-7aa2-488e-851d-860dffe3abfb.png)

Figure 1.17: Deep Q-learning function approximator network

在本书中，我们将通过深度 Q 学习，使用强化学习来训练一辆赛车自己驾驶。

# 迁移学习

一般来说，**迁移学习**是指利用一个领域获得的知识来解决另一个领域的相关问题的概念。然而，在深度学习中，它具体指的是将为特定任务训练的神经网络重新用于不同领域中类似任务的过程。新任务使用从以前任务中学习的特征检测器，因此我们不必训练模型来学习它们。

由于不同层的单元之间的连接模式的性质，深度学习模型往往具有大量的参数。训练这么大的模型，需要相当大的数据量；否则，模型可能会因过度拟合而受损。对于许多需要深度学习解决方案的问题，大量数据将不可用。例如，在用于对象识别的图像处理中，深度学习模型提供了最先进的解决方案。在这种情况下，基于从现有的训练深度学习模型中学习的特征检测器，转移学习可以用于创建特征。然后，这些特征可以用来用可用的数据建立一个简单的模型，以解决手头的新问题。因此，新模型需要学习的唯一参数是与构建简单模型相关的参数，从而减少过度拟合的机会。预处理后的模型通常是在一个庞大的数据集上训练的，因此，它们具有可靠的参数作为特征检测器。

当我们在中枢神经系统中处理图像时，初始层学习检测非常一般的特征，例如卷曲、边缘、颜色组成等。随着网络越来越深，更深层次的卷积层学习检测与特定类型数据集相关的更复杂的特征。我们可以使用一个预训练的网络，选择不训练前几层，因为它们学习非常通用的特性。相反，我们可以只专注于训练最后几层的参数，因为这些参数将学习到特定于当前问题的复杂特征。这将确保我们需要训练的参数更少，并且我们明智地使用数据，只训练所需的复杂参数，而不训练通用特征。

转移学习广泛应用于通过中枢神经系统的图像处理，其中滤波器充当特征检测器。用于迁移学习的最常见的预处理中枢神经系统是`AlexNet`、`VGG16`、`VGG19`、`Inception V3`和`ResNet`等。下图说明了用于迁移学习的预处理`VGG16`网络:

![](assets/04ca3848-86ab-45e6-81f2-1c1d1011ef88.png)

Figure 1.18: Transfer learning with a pretrained VGG 16 network

由 **x** 表示的输入图像被馈送到**预训练的 VGG 16** 网络，并且从最后一个完全连接的层提取 **4096** 维输出特征向量**x’**、。提取的特征**x’**与对应的类标签 **y** 一起用于训练一个简单的分类网络，减少了解决问题所需的数据。

我们将通过使用[第 2 章](02.html)、*迁移学习*中的迁移学习来解决医疗保健领域的图像分类问题。

# 受限玻尔兹曼机器

**受限玻尔兹曼机器** ( **RBMs** )是一类无监督的机器学习算法，学习数据的内部表示。一个 RBM 有一个可见层 *v ∈ R <sup>m</sup>* ，还有一个隐藏层 *h ∈ R <sup>n</sup>* 。RBMs 学习将可见层中的输入呈现为隐藏层中的低维表示。给定可见层输入，所有隐藏层单元都是有条件独立的。同样，给定隐藏层输入，所有可见层都是有条件独立的。这允许 RBM 独立地采样可见单元的输出，给定隐藏层输入，反之亦然。

下图展示了 RBM 的架构:

![](assets/0c7517cc-ffec-4988-956f-e2258a4c314d.png)

Figure 1.19: Restricted Boltzmann machines 

重量 *w <sub>ij</sub> ∈ W* 将可见单位 *i、*连接到隐藏单位 *j* ，其中 *W ∈ R <sup>m x n</sup>* 是所有此类重量的集合，从可见单位到隐藏单位。可见单元中的偏差用 *b <sub>i</sub> ∈ b* 表示，而隐藏单元中的偏差用 *c <sub>j</sub> ∈ c* 表示。

受统计物理学中玻尔兹曼分布的启发，可见层矢量 *v、*和隐藏层矢量 *h、*的联合分布与组态的负能量指数成正比:

![](assets/1aea1d38-4ac6-4663-b3a2-31b6849a03a0.png) (1)

构型的能量由下式给出:

![](assets/e92fb4ee-090a-4067-b628-b1f0dcf9eac0.png) (2)

给定可见输入向量， *v，*，隐藏单元的概率， *j，*可以表示如下:

![](assets/7e50218c-8aa9-4d4b-8d38-761ba1efb7ff.png) (2)

类似地，给定隐藏输入向量， *h，*的可见单位， *i，*的概率由下式给出:

![](assets/7bab8697-ec6f-46d1-8e2f-9ec1cf2bf5cc.png) (3)

因此，一旦我们通过训练了解了 RBM 的权重和偏差，给定隐藏状态，就可以对可见表示进行采样，而给定可见状态，就可以对隐藏状态进行采样。

类似于**主成分分析** ( **主成分分析**)，径向基函数是一种在一个维度上表示数据的方式，由可见层 *v、*提供，进入不同的维度，由隐藏层 *h* 提供。当隐藏层的维数小于可见层的维数时，径向基函数网络执行降维任务。成果管理制通常以二进制数据为基础。

通过最大化训练数据的可能性来训练成果管理制。在成本函数相对于权重和偏差的梯度下降的每次迭代中，采样进入画面，这使得训练过程昂贵并且在计算上有些棘手。一种聪明的采样方法，叫做**对比发散**——使用吉布斯采样——被用来训练径向基函数。

我们将在[第 6 章](06.html)、*智能推荐系统*中使用 RBMs 来构建推荐系统。

# 自动编码器

很像 RBMs，**自动编码器**是一类无监督学习算法，旨在揭示数据中的隐藏结构。在**主成分分析** ( **主成分分析**)中，我们试图捕捉输入变量之间的线性关系，并试图通过采用(输入变量的)线性组合来表示降维空间中的数据，这些线性组合占了数据中的大部分方差。然而，主成分分析无法捕捉输入变量之间的非线性关系。

自动编码器是一种神经网络，可以捕捉输入变量之间的非线性相互作用，同时在隐藏层中以不同的维度表示输入。大多数情况下，隐藏层的尺寸小于输入层的尺寸。我们跳过了这一点，假设高维数据有一个固有的低维结构。例如，高维图像可以由低维流形表示，自动编码器通常用于发现该结构。下图说明了自动编码器的神经架构:

![](assets/594d3d11-05f5-4367-a760-726135cf225b.png)

Figure 1.20: Autoencoder architecture

自动编码器有两个部分:编码器和解码器。编码器试图将输入数据 *x、*投影到隐藏层 *h* 中。解码器试图从隐藏层 *h* 重建输入。伴随这种网络的权重是通过最小化重构误差来训练的，即来自解码器的重构输入![](assets/359986dd-2b2c-43d7-a706-1730baaa010c.png)和原始输入之间的误差。如果输入是连续的，则最小化重构误差的平方和，以便学习自动编码器的权重。

如果我们用一个函数来表示编码器， *f <sub>W</sub> (x)* ，用 *f <sub>U</sub> (x)* 来表示解码器，其中 *W* 和 *U* 是与编码器和解码器相关联的权重矩阵，那么情况如下:

![](assets/40f56474-8d03-49d3-9567-3a30fce2337b.png) (1)

![](assets/7e6dae4f-91dc-43af-a351-d93afff1ecd7.png) (2)

重建误差， *C，*过训练集， *x <sub>i</sub> ，i = 1，2，3，...m* ，可以表示为:

![](assets/5ecc227c-e830-4604-898b-f08d92be4d0a.png) (3)

自动编码器最佳权重![](assets/3f710299-ee2e-40cf-b7ae-7be06074f7c9.png)可以通过最小化 *(3)* 的成本函数来学习，如下所示:

![](assets/1a645659-bc76-482d-9d08-7c790e29013e.png) (4)

自动编码器用于各种目的，例如学习数据的潜在表示、降噪和特征检测。降噪自动编码器将实际输入的噪声版本作为输入。他们试图构建实际的输入，作为重建的标签。同样，自动编码器可以用作创成式模型。一类可以作为创成式模型工作的自动编码器叫做**变分自动编码器**。目前，变分自动编码器和 GANs 作为图像处理的生成模型非常流行。

# 摘要

我们现在已经到了这一章的结尾。我们研究了人工神经网络的几种变体，包括用于图像处理的中枢神经系统和用于自然语言处理的神经网络。此外，我们将 RBMs 和 GANs 视为生成模型，将自动编码器视为无监督方法，以解决许多问题，例如降噪或破译数据的内部结构。此外，我们还谈到了强化学习，它对机器人和人工智能产生了巨大的影响。

现在，您应该已经熟悉了本书其余章节中构建智能人工智能应用程序时我们将使用的核心技术。在构建应用程序时，我们会在需要时进行一些小的技术上的离题。建议刚接触深度学习的读者更多地探索本章中涉及的核心技术，以获得更透彻的理解。

在后续章节中，我们将讨论实际的人工智能项目，并将使用本章中讨论的技术来实现它们。在[第 2 章](02.html)、*迁移学习*中，我们将从使用迁移学习实现医学图像分析的医疗保健应用开始。我们希望您能参与进来。***
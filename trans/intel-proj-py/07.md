# 七、电影评论情感分析手机应用

在这个现代时代，将数据发送到云中基于人工智能的应用程序进行推理是司空见惯的事情。例如，用户可以将在手机上拍摄的图像发送到亚马逊 Rekognition API，该服务可以标记图像中存在的各种对象、人物、文本、场景等。使用托管在云中的基于人工智能的应用程序的服务的优势在于它的易用性。移动应用只需要向基于人工智能的服务发出一个 HTTPS 请求，并附上图像，几秒钟内，服务就会提供推理结果。其中一些**机器学习即服务**提供商如下:

*   亚马逊索赔案
*   亚马逊波利
*   亚马逊 Lex
*   微软 Azure 认知服务
*   IBM 沃森
*   谷歌云视觉

下图，*图 7.1，*说明了这种应用程序在云上托管时的体系结构，以及它如何与移动设备交互:

![](img/71528e0e-5829-47db-a724-312dc884f6f7.png)

Figure 7.1: Mobile app communicating with an AI model hosted on the cloud

正如您在上图中看到的那样，移动应用程序向托管在云上的模型发送图像定位和分类请求以及图像，模型在对提供的图像运行推理后发回结果。在云上使用这种服务的优势如下:

*   没有必要收集数据来训练这种模型
*   将人工智能模型作为一项服务来托管没有任何痛苦
*   没有必要担心模型的重新训练

所有这些都将由服务提供商负责。然而，在云上使用这种人工智能应用程序也有几个缺点，包括以下几点:

*   用户不能在本地移动设备上运行推理。所有的推断都需要通过向托管人工智能应用程序的服务器发送网络请求来完成。在没有网络连接的情况下，移动应用程序将无法工作。此外，通过网络从模型中获取预测可能会有一些延迟。
*   如果它不是一个免费托管的云应用程序，用户通常会为他们运行的推理数量付费。
*   托管在云上的模型非常通用，用户无法控制用自己的数据训练这些模型。如果数据是唯一的，这种基于通用数据训练的应用程序可能不会提供很好的结果。

部署在云上的人工智能应用程序的上述缺点可以通过在移动设备本身上运行推理来克服，而不是通过互联网将数据发送给人工智能应用程序。

该模型可以在任何具有适当的中央处理器和图形处理器的系统上进行训练，使用针对移动应用程序设计的问题的训练数据。然后可以将训练好的模型转换成优化的文件格式，只需要运行推理所需的权重和操作。然后，优化后的模型可以与移动应用程序集成，整个项目可以作为应用程序加载到移动设备上。训练好的模型的优化文件应该尽可能的小，因为模型会和手机应用程序代码一起存储在手机上。在本章中，我们将使用 TensorFlow mobile 开发一个安卓手机应用程序。

# 技术要求

您将需要具备 Python 3、TensorFlow 和 Java 的基本知识

本章代码文件可在 GitHub:
[https://GitHub . com/PacktPublishing/Intelligent-Projects-use-Python/tree/master/chapter 07](https://github.com/PacktPublishing/Intelligent-Projects-using-Python/tree/master/Chapter07)上找到

查看以下视频，查看正在运行的代码:
[http://bit.ly/2S1sddw](http://bit.ly/2S1sddw)

# 使用 TensorFlow 手机构建安卓手机应用

在这个项目中，我们将使用 TensorFlow 的移动功能来优化作为协议缓冲对象的训练模型。然后，我们将该模型与一个安卓应用程序集成，其逻辑将用 Java 编写。我们需要执行以下步骤:

1.  在 TensorFlow 中建立一个模型，并用相关数据进行训练。
2.  一旦模型在验证数据集上表现令人满意，就将 TensorFlow 模型转换为优化的 protobuf 对象(例如，`optimized_model.pb`)。

3.  下载安卓工作室及其先决条件。用 Java 开发核心应用逻辑，用 XML 开发接口页面。
4.  将 TensorFlow 训练的模型 protobuf 对象及其关联的依赖项集成到项目的资产文件夹中。
5.  构建项目并运行它。

这个安卓应用的实现如下图所示(*图 7.2* ):

![](img/28904c06-b8aa-49ab-be57-95d06788ef97.png)

Figure 7.2: Mobile app deployment architectural diagram

# 安卓应用中的电影评论评级

我们将构建一个安卓应用程序，该应用程序将电影评论作为输入，并根据对电影评论的情感分析，提供从`0`到`5`的评级作为输出。LSTM 版本的递归神经网络将首先被训练来对电影的情感进行二元分类。训练数据将包括基于文本的电影评论，以及二进制标签`0`或`1`。`1`的标签代表有积极情绪的评论，而`0`表示电影有消极情绪。从模型中，我们将预测情绪为正的概率，然后将概率放大五倍，将其转换为合理的评级。该模型将使用 TensorFlow 构建，然后将训练好的模型转换为优化的冻结 protobuf 对象，以与安卓应用程序逻辑集成。冻结对象的大小将比原始训练模型小得多，并且仅用于推断目的。

我们将在[http://ai.stanford.edu/~amaas/data/sentiment/](http://ai.stanford.edu/~amaas/data/sentiment/)使用可用的数据集，在下面的文章中使用，标题为*学习用于情感分析的词向量*:

```py
@InProceedings{maas-EtAl:2011:ACL-HLT2011,
  author    = {Maas, Andrew L.  and  Daly, Raymond E. and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}
```

# 预处理电影评论文本

电影评论文本需要被预处理并转换成数字标记，对应于语料库中的不同单词。通过获取第一个`50000`频繁单词，Keras 标记器将用于将单词转换为数字索引或标记。我们已经限制了电影评论的字数上限。如果电影评论的单词标记少于`1000`单词标记，评论的开头用零填充。预处理之后，数据被分成训练集、验证集和测试集。Keras `Tokenizer`对象被保存以供推理时使用。

对电影评论进行预处理的详细代码如下:

```py
# -*- coding: utf-8 -*-
"""
Created on Sun Jun 17 22:36:00 2018
@author: santanu
"""
import numpy as np
import pandas as pd
import os
import re
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
import pickle
import fire 
from elapsedtimer import ElapsedTimer

# Function to clean the text and convert it into lower case 
def text_clean(text):
    letters = re.sub("[^a-zA-z0-9\s]", " ",text)
    words = letters.lower().split()
    text = " ".join(words)

    return text

def process_train(path):
    review_dest = []
    reviews = []
    train_review_files_pos = os.listdir(path + 'train/pos/')
    review_dest.append(path + 'train/pos/')
    train_review_files_neg = os.listdir(path + 'train/neg/')
    review_dest.append(path + 'train/neg/')
    test_review_files_pos = os.listdir(path + 'test/pos/') 
    review_dest.append(path + 'test/pos/')
    test_review_files_neg = os.listdir(path + 'test/neg/')
    review_dest.append(path + 'test/neg/')

    sentiment_label = [1]*len(train_review_files_pos) + \
                      [0]*len(train_review_files_neg) + \
                      [1]*len(test_review_files_pos) + \
                      [0]*len(test_review_files_neg)

    review_train_test = ['train']*len(train_review_files_pos) + \
                        ['train']*len(train_review_files_neg) + \
                        ['test']*len(test_review_files_pos) + \
                        ['test']*len(test_review_files_neg)

    reviews_count = 0 

    for dest in review_dest:
        files = os.listdir(dest)
        for f in files:
            fl = open(dest + f,'r')
            review = fl.readlines()
            review_clean = text_clean(review[0])
            reviews.append(review_clean)
            reviews_count +=1

    df = pd.DataFrame()
    df['Train_test_ind'] = review_train_test
    df['review'] = reviews
    df['sentiment_label'] = sentiment_label
    df.to_csv(path + 'processed_file.csv',index=False)
    print ('records_processed',reviews_count)
    return df

def process_main(path):
    df = process_train(path)
    # We will tokenize the text for the most common 50000 words.
    max_fatures = 50000
    tokenizer = Tokenizer(num_words=max_fatures, split=' ')
    tokenizer.fit_on_texts(df['review'].values)
    X = tokenizer.texts_to_sequences(df['review'].values) 
    X_ = []
    for x in X:
        x = x[:1000] 
        X_.append(x) 
    X_ = pad_sequences(X_)
    y = df['sentiment_label'].values
    index = list(range(X_.shape[0]))
    np.random.shuffle(index)
    train_record_count = int(len(index)*0.7)
    validation_record_count = int(len(index)*0.15)

    train_indices = index[:train_record_count]
    validation_indices = index[train_record_count:train_record_count + 
                              validation_record_count]
    test_indices = index[train_record_count + validation_record_count:]
    X_train,y_train = X_[train_indices],y[train_indices]
    X_val,y_val = X_[validation_indices],y[validation_indices]
    X_test,y_test = X_[test_indices],y[test_indices]

    np.save(path + 'X_train',X_train)
    np.save(path + 'y_train',y_train)
    np.save(path + 'X_val',X_val)
    np.save(path + 'y_val',y_val)
    np.save(path + 'X_test',X_test)
    np.save(path + 'y_test',y_test)

    # saving the tokenizer oject for inference
    with open(path + 'tokenizer.pickle', 'wb') as handle:
        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

if __name__ == '__main__':
    with ElapsedTimer('Process'):
        fire.Fire(process_main)

```

代码`preprocess.py`可以如下调用:

```py
python preprocess.py --path /home/santanu/Downloads/Mobile_App/aclImdb/ 
```

其输出日志如下所示:

```py
Using TensorFlow backend.
records_processed 50000
24.949 s: Process
```

# 构建模型

我们将建立一个简单的 LSTM 版本的递归神经网络，在输入层后面有一个嵌入层。嵌入层词向量用维数为 100 的预训练手套向量初始化，层定义为`trainable`，这样词向量嵌入可以基于训练数据进行自我更新。隐藏状态和单元状态的维度也保持为`100`。该模型使用二元交叉熵损失进行训练。为了避免过拟合，在损失函数中加入了脊线正则化。**亚当优化器** 用于训练模型。

下面的代码片段显示了用于在 TensorFlow 中构建模型的函数:

```py
def _build_model(self):

        with tf.variable_scope('inputs'):
            self.X = tf.placeholder(shape=[None, self.sentence_length],dtype=tf.int32,name="X")
            print (self.X)
            self.y = tf.placeholder(shape=[None,1], dtype=tf.float32,name="y")
            self.emd_placeholder = tf.placeholder(tf.float32,shape=[self.n_words,self.embedding_dim]) 

        with tf.variable_scope('embedding'):
            # create embedding variable
            self.emb_W =tf.get_variable('word_embeddings',[self.n_words, self.embedding_dim],initializer=tf.random_uniform_initializer(-1, 1, 0),trainable=True,dtype=tf.float32)
            self.assign_ops = tf.assign(self.emb_W,self.emd_placeholder)

            # do embedding lookup
            self.embedding_input = tf.nn.embedding_lookup(self.emb_W,self.X,"embedding_input") 
            print( self.embedding_input )
            self.embedding_input = tf.unstack(self.embedding_input,self.sentence_length,1) 
            #rint( self.embedding_input)

        # define the LSTM cell
        with tf.variable_scope('LSTM_cell'):
            self.cell = tf.nn.rnn_cell.BasicLSTMCell(self.hidden_states)

        # define the LSTM operation
        with tf.variable_scope('ops'):
            self.output, self.state = tf.nn.static_rnn(self.cell,self.embedding_input,dtype=tf.float32)

        with tf.variable_scope('classifier'):
            self.w = tf.get_variable(name="W", shape=[self.hidden_states,1],dtype=tf.float32)
            self.b = tf.get_variable(name="b", shape=[1], dtype=tf.float32)
        self.l2_loss = tf.nn.l2_loss(self.w,name="l2_loss")
        self.scores = tf.nn.xw_plus_b(self.output[-1],self.w,self.b,name="logits")
        self.prediction_probability = tf.nn.sigmoid(self.scores,name='positive_sentiment_probability')
        print (self.prediction_probability)
        self.predictions = tf.round(self.prediction_probability,name='final_prediction')

        self.losses = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.scores,labels=self.y)
        self.loss = tf.reduce_mean(self.losses) + self.lambda1*self.l2_loss
        tf.summary.scalar('loss', self.loss)

        self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.losses)

        self.correct_predictions = tf.equal(self.predictions,tf.round(self.y))
        print (self.correct_predictions)

        self.accuracy = tf.reduce_mean(tf.cast(self.correct_predictions, "float"),         name="accuracy")
        tf.summary.scalar('accuracy', self.accuracy)
```

# 训练模型

在本节中，我们将说明训练模型的 TensorFlow 代码。模型被训练为适度的`10 epochs`，以避免过度拟合。优化器使用的学习速率是`0.001`，而训练批次大小和验证批次大小分别设置在`250`和`50`。需要注意的是，我们正在使用`tf.train.write_graph`功能将模型图定义保存在`model.pbtxt`文件中。此外，一旦模型被训练，我们将使用`tf.train.Saver` 功能将模型权重保存在检查点文件`model_ckpt`中。将使用`model.pbtxt`和`model_ckpt`文件以 protobuf 格式创建 TensorFlow 模型的优化版本，该版本可与安卓应用程序集成:

```py
   def _train(self):

        self.num_batches = int(self.X_train.shape[0]//self.batch_size)
        self._build_model()
        self.saver = tf.train.Saver()

        with tf.Session() as sess:
            init = tf.global_variables_initializer()
            sess.run(init) 
            sess.run(self.assign_ops,feed_dict={self.emd_placeholder:self.embedding_matrix}) 
            tf.train.write_graph(sess.graph_def, self.path, 'model.pbtxt') 
            print (self.batch_size,self.batch_size_val)
            for epoch in range(self.epochs):
                gen_batch = self.batch_gen(self.X_train,self.y_train,self.batch_size)
                gen_batch_val = self.batch_gen(self.X_val,self.y_val,self.batch_size_val)

                for batch in range(self.num_batches):
                    X_batch,y_batch = next(gen_batch) 
                    X_batch_val,y_batch_val = next(gen_batch_val)
                    sess.run(self.optimizer,feed_dict={self.X:X_batch,self.y:y_batch})
                    c,a = sess.run([self.loss,self.accuracy],feed_dict={self.X:X_batch,self.y:y_batch})
                    print(" Epoch=",epoch," Batch=",batch," Training Loss: ","{:.9f}".format(c), " Training Accuracy=", "{:.9f}".format(a))
                    c1,a1 = sess.run([self.loss,self.accuracy],feed_dict={self.X:X_batch_val,self.y:y_batch_val})
                    print(" Epoch=",epoch," Validation Loss: ","{:.9f}".format(c1), " Validation Accuracy=", "{:.9f}".format(a1))
                results = sess.run(self.prediction_probability,feed_dict={self.X:X_batch_val})
                print(results)

                if epoch % self.checkpoint_step == 0:
                    self.saver.save(sess, os.path.join(self.path,'model'), global_step=epoch) 

            self.saver.save(sess,self.path + 'model_ckpt')
            results = sess.run(self.prediction_probability,feed_dict={self.X:X_batch_val})
            print(results)
```

# 批量生成器

在`train`功能中，我们将使用批次生成器，根据通过的批次大小，生成随机批次。生成器函数可以定义如下。请注意，这些功能使用`yield`代替`return`。通过调用带有所需参数的函数，将创建一个批处理迭代器对象。通过对迭代器对象应用`next`方法可以检索批次。我们将在每个纪元开始时调用生成器函数，这样批处理在每个纪元中将是随机的。

下面的代码片段说明了用于生成批处理迭代器对象的函数:

```py
def batch_gen(self,X,y,batch_size):

        index = list(range(X.shape[0]))
        np.random.shuffle(index)
        batches = int(X.shape[0]//batch_size)

        for b in range(batches):
            X_train,y_train = X[index[b*batch_size: (b+1)*batch_size],:],
                                      y[index[b*batch_size: (b+1)*batch_size]]
            yield X_train,y_train

```

模型培训活动的详细代码在脚本`**movie_review_model_train.py**`中。同样的训练可以如下调用:

```py
python movie_review_model_train.py process_main --path /home/santanu/Downloads/Mobile_App/ --epochs 10
```

培训的输出如下:

```py
Using TensorFlow backend.
(35000, 1000) (35000, 1)
(7500, 1000) (7500, 1)
(7500, 1000) (7500, 1)
no of positive class in train: 17497
no of positive class in test: 3735
Tensor("inputs/X:0", shape=(?, 1000), dtype=int32)
Tensor("embedding/embedding_lookup:0", shape=(?, 1000, 100), dtype=float32)
Tensor("positive_sentiment_probability:0", shape=(?, 1), dtype=float32)
.....
25.043 min: Model train 
```

# 将模型冻结为 protobuf 格式

保存的训练好的模型，以`model.pbtxt`和`model_ckpt`文件的形式，不能被安卓应用直接使用。我们需要将其转换为优化的 protobuf 格式(一个`.pb`扩展名文件)，可以与安卓应用程序集成。优化后的 protobuf 格式的文件大小将远小于`model.pbtxt`和`model_ckpt`文件的组合大小。

下面的代码(`freeze_code.py`)将从`model.pbtxt`和`model_ckpt`文件创建优化的原型 buf 模型:

```py
# -*- coding: utf-8 -*-

import sys
import tensorflow as tf
from tensorflow.python.tools import freeze_graph
from tensorflow.python.tools import optimize_for_inference_lib
import fire
from elapsedtimer import ElapsedTimer

#path = '/home/santanu/Downloads/Mobile_App/'
#MODEL_NAME = 'model'

def model_freeze(path,MODEL_NAME='model'):

    # Freeze the graph

    input_graph_path = path + MODEL_NAME+'.pbtxt'
    checkpoint_path = path + 'model_ckpt'
    input_saver_def_path = ""
    input_binary = False
    output_node_names = 'positive_sentiment_probability'
    restore_op_name = "save/restore_all"
    filename_tensor_name = "save/Const:0"
    output_frozen_graph_name = path + 'frozen_'+MODEL_NAME+'.pb'
    output_optimized_graph_name = path + 'optimized_'+MODEL_NAME+'.pb'
    clear_devices = True

    freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,
                            input_binary, checkpoint_path, output_node_names,
                            restore_op_name, filename_tensor_name,
    output_frozen_graph_name, clear_devices, "")

    input_graph_def = tf.GraphDef()

    with tf.gfile.Open(output_frozen_graph_name, "rb") as f:
        data = f.read()
        input_graph_def.ParseFromString(data)

    output_graph_def = optimize_for_inference_lib.optimize_for_inference(
            input_graph_def,
            ["inputs/X" ],#an array of the input node(s)
            ["positive_sentiment_probability"],
            tf.int32.as_datatype_enum # an array of output nodes
            )

    # Save the optimized graph

    f = tf.gfile.FastGFile(output_optimized_graph_name, "w")
    f.write(output_graph_def.SerializeToString())

if __name__ == '__main__':
    with ElapsedTimer('Model Freeze'):
        fire.Fire(model_freeze)

```

正如您在前面的代码中看到的，我们首先声明输入张量和输出张量，方法是在声明模型时引用它们的定义名称。使用输入和输出张量，以及`model.pbtxt`和`model_ckpt` 文件，利用`tensorflow.python.tools`的`freeze_graph` 功能冻结模型。下一步，冷冻模型进一步优化，使用`tensorflow.python.tools`中的`optimize_for_inference_lib`功能创建原型 buf 模型，命名为`optimized_model.pb`。这个优化后的 protobuf 模型`optimized_model.pb`将与安卓应用程序集成，用于推理。

可以调用`freeze_code.py`模型创建 protobuf 格式文件，如下所示:

```py
python freeze_code.py --path /home/santanu/Downloads/Mobile_App/ --MODEL_NAME model
```

执行上述命令的输出如下:

```py
39.623 s: Model Freeze
```

# 创建用于推理的单词到标记词典

在预处理过程中，我们训练了一个 Keras 标记器，用数字单词索引替换单词，这样处理后的电影评论就可以输入到 LSTM 模型中进行训练。我们还保留了词频最高的第一个`50000`单词，并将复习顺序设置为最大长度`1000`。虽然训练好的 Keras tokenizer 是为了推断而保存的，但它不能被安卓应用直接使用。我们可以恢复 Keras 标记器，并将第一个`50000`单词及其对应的单词索引保存在文本文件中。这个文本文件可以在安卓应用中使用，以便建立一个**单词到索引词典**将评论文本的单词转换成它们的单词索引。需要注意的是，通过参考`tokenizer.word_index.`可以从加载的 Keras 标记器对象中检索到单词到索引的映射。执行此活动`tokenizer_2_txt.py`的详细代码如下:

```py
import keras 
import pickle 
import fire
from elapsedtimer import ElapsedTimer

#path = '/home/santanu/Downloads/Mobile_App/aclImdb/tokenizer.pickle'
#path_out = '/home/santanu/Downloads/Mobile_App/word_ind.txt'
def tokenize(path,path_out):
    with open(path, 'rb') as handle:
        tokenizer = pickle.load(handle)

    dict_ = tokenizer.word_index

    keys = list(dict_.keys())[:50000] 
    values = list(dict_.values())[:50000]
    total_words = len(keys)
    f = open(path_out,'w')
    for i in range(total_words):
        line = str(keys[i]) + ',' + str(values[i]) + '\n'
        f.write(line)

    f.close()

if __name__ == '__main__':
    with ElapsedTimer('Tokeize'):
        fire.Fire(tokenize)
```

`tokenizer_2_txt.py`可以如下运行:

```py
python tokenizer_2_txt.py --path '/home/santanu/Downloads/Mobile_App/aclImdb/tokenizer.pickle' --path_out '/home/santanu/Downloads/Mobile_App/word_ind.txt'

```

前面命令的输出日志如下:

```py
Using TensorFlow backend.
165.235 ms: Tokenize
```

# App 界面页面设计

使用安卓工作室可以设计一个简单的手机应用界面，相关代码将生成一个 XML 文件。正如你在下面的截图中看到的那样(*图 7.3* )，这个应用程序由一个简单的电影评论文本框组成，用户可以在这里输入他们的电影评论，一旦完成，就按下 SUBMIT 按钮。一旦按下 SUBMIT 按钮，评论将被传递给核心 app 逻辑，核心 app 逻辑将处理电影评论文本，并将其传递给 TensorFlow 优化模型进行推理。

作为推断的一部分，将计算情感评分，该评分将显示在移动应用程序上，并显示为星级:

![](img/039d0647-9cac-44e2-a3d2-451570512ba1.png)

Figure 7.3: Mobile app user interface page format

生成前面提到的移动应用视图所需的 XML 文件如下所示:

```py
<?xml version="1.0" encoding="utf-8"?>
<android.support.constraint.ConstraintLayout xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:app="http://schemas.android.com/apk/res-auto"
    xmlns:tools="http://schemas.android.com/tools"
    android:layout_width="match_parent"
    android:layout_height="match_parent"
    tools:context=".MainActivity"
    tools:layout_editor_absoluteY="81dp">

    <TextView
        android:id="@+id/desc"
        android:layout_width="100dp"
        android:layout_height="26dp"
        android:layout_marginEnd="8dp"
        android:layout_marginLeft="44dp"
        android:layout_marginRight="8dp"
        android:layout_marginStart="44dp"
        android:layout_marginTop="36dp"
        android:text="Movie Review"
        app:layout_constraintEnd_toEndOf="parent"
        app:layout_constraintHorizontal_bias="0.254"
        app:layout_constraintStart_toStartOf="parent"
        app:layout_constraintTop_toTopOf="parent"
        tools:ignore="HardcodedText" />

    <EditText
        android:id="@+id/Review"
        android:layout_width="319dp"
        android:layout_height="191dp"
        android:layout_marginEnd="8dp"
        android:layout_marginLeft="8dp"
        android:layout_marginRight="8dp"
        android:layout_marginStart="8dp"
        android:layout_marginTop="24dp"
        app:layout_constraintEnd_toEndOf="parent"
        app:layout_constraintStart_toStartOf="parent"
        app:layout_constraintTop_toBottomOf="@+id/desc" />

    <RatingBar
        android:id="@+id/ratingBar"
        android:layout_width="240dp"
        android:layout_height="49dp"
        android:layout_marginEnd="8dp"
        android:layout_marginLeft="52dp"
        android:layout_marginRight="8dp"
        android:layout_marginStart="52dp"
        android:layout_marginTop="28dp"
        app:layout_constraintEnd_toEndOf="parent"
        app:layout_constraintHorizontal_bias="0.238"
        app:layout_constraintStart_toStartOf="parent"
        app:layout_constraintTop_toBottomOf="@+id/score"
        tools:ignore="MissingConstraints" />

    <TextView
        android:id="@+id/score"
        android:layout_width="125dp"
        android:layout_height="39dp"
        android:layout_marginEnd="8dp"
        android:layout_marginLeft="96dp"
        android:layout_marginRight="8dp"
        android:layout_marginStart="96dp"
        android:layout_marginTop="32dp"
        android:ems="10"
        android:inputType="numberDecimal"
        app:layout_constraintEnd_toEndOf="parent"
        app:layout_constraintHorizontal_bias="0.135"
        app:layout_constraintStart_toStartOf="parent"
        app:layout_constraintTop_toBottomOf="@+id/submit" />

    <Button
        android:id="@+id/submit"
        android:layout_width="wrap_content"
        android:layout_height="35dp"
        android:layout_marginEnd="8dp"
        android:layout_marginLeft="136dp"
        android:layout_marginRight="8dp"
        android:layout_marginStart="136dp"
        android:layout_marginTop="24dp"
        android:text="SUBMIT"
        app:layout_constraintEnd_toEndOf="parent"
        app:layout_constraintHorizontal_bias="0.0"
        app:layout_constraintStart_toStartOf="parent"
        app:layout_constraintTop_toBottomOf="@+id/Review" />

</android.support.constraint.ConstraintLayout>

```

需要注意的一点是，用户和移动应用核心逻辑交互的变量是在 XML 文件中声明的，在`android:id`选项中。例如，用户提供的电影评论将由`Review`变量处理，如这里所示的 XML 文件中所定义的:

```py
android:id="@+id/Review"
```

# 安卓应用的核心逻辑

安卓应用的核心逻辑是处理用户请求，以及传递的数据，然后将结果发送回用户。作为这个移动应用程序的一部分，核心逻辑将接受用户提供的电影评论，处理原始数据，并将其转换为训练有素的 LSTM 模型可以运行推理的格式。Java 中的`OnClickListener`功能用于监控用户是否提交了处理请求。所提供的电影评论中的每个词都需要被改变为它们的索引，然后输入可以被直接馈送到优化的训练 LSTM 模型用于推断。除了优化的 protobuf 模型之外，还为此目的存储了单词及其对应索引的字典。使用`TensorFlowInferenceInterface` 方法对训练好的模型进行推理。优化后的 protobuf 模型和单词字典及其对应的索引存储在`assets`文件夹中。综上所述，应用核心逻辑执行的任务如下:

1.  将索引词典中的单词加载到`WordToInd` `HashMap`中。在训练模型之前，单词到索引字典是在文本预处理期间从标记器中得到的。
2.  使用`OnClickListener`方法监控用户是否提交了电影评论进行推断。
3.  如果已经提交了电影评论，则该评论将从绑定到 XML 的`Review`变量中读取。通过删除标点符号等方式清理评论，然后将其拆分为单词。使用`HashMap`功能`WordToInd`，每个单词都被转换成相应的索引。这些指数构成了我们的张量流模型的`InputVec`输入，用于推断。输入向量长度为`1000`；所以，如果评论少于`1000`个字，向量在开头用零填充。

4.  在下一步中，使用`TensorFlowInferenceInterface`功能创建一个`mInferenceInterface`对象，将优化后的 protobuf 模型(扩展名为`.pb`)从`assets`文件夹加载到内存中。需要定义张量流模型的输入节点和输出节点，这些节点将被引用来进行推理，就像原始模型一样。对于我们的模型，它们被定义为`INPUT_NODE`和`OUTPUT_NODE`，它们分别包含 TensorFlow 输入占位符的名称和输出情感概率 ops。**`mInferenceInterface`**对象的`feed`方法用于将`InputVec`值分配给模型的`INPUT_NODE`，而`mInferenceInterface` 的`run`方法执行`OUTPUT_NODE`。最后，使用`mInferenceInterface` 的`fetch`方法将推理结果填充到浮动变量`value_`中。****
*****   情绪得分(情绪为正的概率)通过乘以 5 转换为评级。然后通过`ratingBar` 变量将此反馈到安卓 app 用户界面。****

 ****Java 中移动应用的核心逻辑如下:

```py
package com.example.santanu.abc;
import android.content.res.AssetManager;
import android.support.v7.app.AppCompatActivity;
import android.os.Bundle;
import android.view.View;
import android.widget.RatingBar;
import android.widget.TextView;
import android.widget.Button;
import android.widget.EditText;
import java.io.BufferedReader;
import java.io.FileReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.util.HashMap;
import java.util.Map;
import org.tensorflow.contrib.android.TensorFlowInferenceInterface;

public class MainActivity extends AppCompatActivity {

    private TensorFlowInferenceInterface mInferenceInterface;
    private static final String MODEL_FILE = "file:///android_asset/optimized_model.pb";
    private static final String INPUT_NODE = "inputs/X";
    private static final String OUTPUT_NODE = "positive_sentiment_probability";

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        // Create references to the widget variables

        final TextView desc = (TextView) findViewById(R.id.desc);
        final Button submit = (Button) findViewById(R.id.submit);
        final EditText Review = (EditText) findViewById(R.id.Review);
        final TextView score = (TextView) findViewById(R.id.score);
        final RatingBar ratingBar = (RatingBar) findViewById(R.id.ratingBar);

        //String filePath = "/home/santanu/Downloads/Mobile_App/word2ind.txt";
        final Map<String,Integer> WordToInd = new HashMap<String,Integer>();
        //String line;

        //reader = new BufferedReader(new InputStreamReader(getAssets().open("word2ind.txt")));

        BufferedReader reader = null;
        try {
            reader = new BufferedReader(
                    new InputStreamReader(getAssets().open("word_ind.txt")));

            // do reading, usually loop until end of file reading
            String line;
            while ((line = reader.readLine()) != null)
            {
                String[] parts = line.split("\n")[0].split(",",2);
                if (parts.length >= 2)
                {

                    String key = parts[0];
                    //System.out.println(key);
                    int value = Integer.parseInt(parts[1]);
                    //System.out.println(value);
                    WordToInd.put(key,value);
                } else

                {
                    //System.out.println("ignoring line: " + line);
                }
            }
        } catch (IOException e) {
            //log the exception
        } finally {
            if (reader != null) {
                try {
                    reader.close();
                } catch (IOException e) {
                    //log the exception
                }
            }
        }

        //line = reader.readLine();

        // Create Button Submit Listener

        submit.setOnClickListener(new View.OnClickListener() {

            @Override
            public void onClick(View v) {
                // Read Values
                String reviewInput = Review.getText().toString().trim();
                System.out.println(reviewInput);

                String[] WordVec = reviewInput.replaceAll("[^a-zA-z0-9 ]", "").toLowerCase().split("\\s+");
                System.out.println(WordVec.length);

                int[] InputVec = new int[1000];
                // Initialize the input
                for (int i = 0; i < 1000; i++) {
                    InputVec[i] = 0;
                }
                // Convert the words by their indices

                int i = 1000 - 1 ;
                for (int k = WordVec.length -1 ; k > -1 ; k--) {
                    try {
                        InputVec[i] = WordToInd.get(WordVec[k]);
                        System.out.println(WordVec[k]);
                        System.out.println(InputVec[i]);

                    }
                    catch (Exception e) {
                        InputVec[i] = 0;

                    }
                    i = i-1;
                }

                if (mInferenceInterface == null) {
                    AssetManager assetManager = getAssets();
                    mInferenceInterface = new TensorFlowInferenceInterface(assetManager,MODEL_FILE);
                }

                float[] value_ = new float[1];

                mInferenceInterface.feed(INPUT_NODE,InputVec,1,1000);
                mInferenceInterface.run(new String[] {OUTPUT_NODE}, false);
                System.out.println(Float.toString(value_[0]));
                mInferenceInterface.fetch(OUTPUT_NODE, value_);

                double scoreIn;
                scoreIn = value_[0]*5;
                double ratingIn = scoreIn;
                String stringDouble = Double.toString(scoreIn);
                score.setText(stringDouble);
                ratingBar.setRating((float) ratingIn);

            }

        });

    }
}
```

需要注意的一点是，我们可能需要编辑应用的`build.gradle`文件，以便将包添加到依赖项中:

```py
org.tensorflow:tensorflow-android:1.7.0
```

# 测试移动应用程序

我们将用两部电影的评论来测试手机应用:*阿凡达*和*星际*。*阿凡达*影评取自[https://www.rogerebert.com/reviews/avatar-2009](https://www.rogerebert.com/reviews/avatar-2009)，内容如下:

*“看《阿凡达》的时候，我感觉和 1977 年看《星球大战》的时候差不多。那是我带着不确定的期望走进的另一部电影。詹姆斯·卡梅隆的电影就像他的《泰坦尼克号》一样，一直是令人怀疑的热门话题。他又一次通过简单地发表一部非凡的电影让质疑者哑口无言。在好莱坞，至少还有一个人知道如何明智地花费 2.5 亿美元，或者是 3 亿美元。*

*《阿凡达》不仅仅是一部轰动一时的娱乐片，尽管它确实如此。这是技术上的突破。它有一个明确的绿色和反战信息。发动邪教是命中注定的。它包含这样的视觉细节，它将奖励重复观看。它发明了一种新的语言，纳威语，就像《指环王》一样，尽管幸运的是，我怀疑这种语言是否能被人类使用，即使是十几岁的人。它创造了新的电影明星。这是一个活动，是那些你觉得必须看才能跟上对话的电影之一。”*

评论者给电影的评分是 4/5，而手机应用给的评分是 4.8/5 左右，如下图截图所示(*图 7.4* ):

![](img/edef4e5f-45e7-40d0-8e72-9d9f44e37b38.png)

Figure 7.4\. Mobile app review rating of the movie Avatar

同样，我们将评估该应用为电影*《星际穿越》*提供的评级，评论来自[https://www.rottentomatoes.com/m/interstellar_2014/](https://www.rottentomatoes.com/m/interstellar_2014/)。审核如下:

*《星际穿越》代表了更多的惊心动魄、发人深省、视觉上光彩照人的电影制作，观众已经开始期待编剧兼导演克里斯托弗·诺兰的作品，尽管它的知识面有些超出了观众的理解范围*

电影在*烂番茄*上的平均评分是 7/10，当缩放到 5 时，评分是 3.5/5，而手机应用预测的评分是 3.37，如下图截图所示(*图 7.5* ):

![](img/e35227a8-c487-43ee-934b-08186678ae3a.png)

Figure 7.5\. Mobile app review rating of the movie Interstellar

正如您在前面两张插图中看到的，移动电影评论评级应用程序在为电影评论提供合理评级方面做得很好。

# 摘要

读完这一章，读者应该对如何利用 TensorFlow 的移动功能在安卓应用程序中部署深度学习模型有了一个大致的了解。本章中涉及的技术细节和实现细节应该对读者有益，帮助他们构建智能安卓移动应用程序，并以有趣的方式扩展它们。本项目的详细代码位于[https://github . com/PacktPublishing/Python-人工智能-项目/第 07 章](https://github.com/PacktPublishing/Python-Artificial-Intelligence-Projects/Chapter07) *。*

在下一章中，我们将为客户服务构建一个对话式 AI 聊天机器人。我们期待您的参与。****
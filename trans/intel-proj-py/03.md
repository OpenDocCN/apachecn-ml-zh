# 神经机器翻译

**机器翻译**，简单来说就是用电脑将文本从一种语言翻译成另一种语言。它是计算机语言学的一个分支，已经存在好几年了。目前，在美国，翻译是一个 400 亿美元的行业，在欧洲和亚洲也在快速增长。社会、政府、经济和商业对翻译有很大的需求，谷歌、脸书、易贝等公司在应用中广泛使用翻译。尤其是谷歌的神经翻译系统是目前最先进的翻译系统之一，只需一个模型就能完成多种语言的翻译。

早期的机器翻译系统始于将文本中的单词和短语翻译成所需目标语言的相关替代语言。然而，由于以下原因，通过这些简单技术实现的翻译质量受到限制:

*   从源语言到目标语言的词到词的映射并不总是可用的。
*   即使源语言和目标语言之间确实存在精确的单词到单词的映射，语言的句法结构通常也不会相互对应。机器翻译中的这个问题通常被称为*错位*。

然而，随着最近在**递归神经网络** ( **RNN** )架构中的进展，例如 LSTMs、GRU 等，机器翻译不仅提供了改进的翻译质量，而且这种系统的复杂性也远低于传统系统。

机器翻译系统可以大致分为三类:基于规则的机器翻译、统计机器翻译和神经机器翻译。

在本章中，我们将涵盖以下主题:

*   基于规则的机器翻译
*   统计机器学习系统
*   神经机器翻译
*   序列到序列的神经翻译
*   神经翻译的损失函数

# 技术要求

您将需要具备 Python 3、TensorFlow 和 Keras 的基本知识。

本章代码文件可在 GitHub:
[https://GitHub . com/PacktPublishing/Intelligent-Projects-use-Python/tree/master/chapter 03](https://github.com/PacktPublishing/Intelligent-Projects-using-Python/tree/master/Chapter03)上找到

查看以下视频，查看正在运行的代码:
[http://bit.ly/2sXYX8A](http://bit.ly/2sXYX8A)

# 基于规则的机器翻译

经典的基于规则的机器翻译系统严重依赖于将文本从源语言转换为目标语言的规则。这些规则通常由语言学家创建，通常在句法、语义和词汇层面起作用。典型的基于规则的机器翻译系统通常有三个阶段:

*   分析阶段
*   词汇迁移阶段
*   生成阶段

图 3.1 所示为典型的基于规则的机器翻译系统的流程图:

![](assets/87104398-8e42-45a6-bf08-3dbad0d1e745.png)

Figure 3.1: A flow diagram of a rule-based machine translation system

# 分析阶段

基于规则的机器翻译的第一阶段是分析阶段，对源语言文本进行分析，提取与词法、词性、命名实体识别以及词义消歧相关的信息。形态信息涉及单词的结构、词干的来源、词根的检测等等。词性标记器用可能的词性标记来标记文本中的每个单词，如名词、动词、副词、形容词等。接下来是一个**命名实体识别** ( **NER** )任务，该任务试图将命名实体分类到预定义的桶中，如人名、位置、组织名称等。NER 之后是词义消歧，它试图识别一个特定的词是如何在一个句子中使用的。

# 词汇迁移阶段

词汇迁移阶段跟在分析阶段之后，有两个阶段:

*   **单词翻译**:在单词翻译中，使用双语翻译词典将分析阶段推导出的源词根翻译成对应的目标词根。
*   **语法翻译**:在语法翻译阶段，进行句法修改，包括翻译后缀等。

# 生成程序段

在生成阶段，在最终的翻译文本作为输出提供之前，对翻译文本进行验证和纠正，以使其在词类、性别以及主语和宾语相对于动词的一致性方面是正确的。在每个步骤中，机器翻译系统使用预定义的字典。对于基于规则的机器翻译系统的最低限度实现，需要以下字典:

*   源语言形态分析词典
*   包含源语言单词与其目标语言对应词的映射的双语词典
*   包含用于目标词生成的目标语言形态信息的词典

# 统计机器学习系统

给定源文本，统计机器翻译系统通过最大化其条件概率来选择目标文本。例如，假设我们有一个源文本 *s* ，我们想要在目标语言中导出最佳的等价文本 *t* 。这可以推导如下:

![](assets/d5a5fe04-9f29-433c-a9bf-83303d4e5232.png)

*(1)* 中 *P(t/s)* 的公式可以用贝叶斯定理扩展如下:

![](assets/f9bcb9c3-e8e5-4d9b-bddc-cf07222a55ee.png)

对于给定的源句子， *P(s)* 将是固定的，因此，找到最佳的目标翻译结果如下:

![](assets/3e0fe8f4-e700-48f5-95a8-07ce870ed1c2.png)

你可能想知道为什么最大化 *P(s/t)P(t)* 而不是直接最大化 *P(t/s)* 会带来优势。一般来说，在 *P(t/s)* 下很可能出现的格式不良的句子是通过将问题分解成两部分来避免的，即 *P(s/t)* 和 *P(t)* ，如上式所示:

![](assets/f4f8506a-2b5f-4c49-a434-12012a2dcf97.png)

Figure 3.2: Statistical machine translation architecture

从上图中我们可以看到，统计机器翻译问题被分解成三个不同的子问题，如上所述:

*   为目标建立一个**语言模型**，让我们可以估计 *P(t)*
*   建立从目标语言到源语言的**翻译模型**，使我们能够估计 *P(s/t)*
*   对可能的目标翻译进行搜索，并选择最大化 *P(s/t)P(t)* 的翻译

我们将讨论这三个主题中的每一个，因为这些功能是任何机器翻译问题所固有的。

# 语言模型

在语言模型中，句子的概率被表示为各个单词或短语的条件概率的乘积。先说句子 *t* 由*t<sub>1</sub>t<sub>2</sub>t<sub>3</sub>组成。。t <sub>n</sub>* 。根据概率的链式法则，句子 *t* 的概率可以表示为:

![](assets/5b33f286-e730-48d1-83d1-f491731ad41f.png)

建立一个基于前面公式的语言模型需要我们估计几个顺序的条件概率，这实际上是不可能的。为了使这个问题在计算上可行，一个简单的假设是只基于前一个单词来限定一个单词，而不是基于它之前的所有单词。这个假设也被称为**马尔可夫假设**、**T3，这个模型被称为**二元模型**。根据二元模型，单词的条件概率可以表示如下:**

![](assets/fed81518-1cd1-4beb-a689-4f153de98fea.png)

为了进一步改进结果，我们可以使用一个**三元模型**，它将一个句子中的一个特定单词置于它前面的两个单词之上，如下所示:

![](assets/b00765b5-99f5-4dc3-a9cd-32f3ae13a51f.png)

对于二元模型，给定当前单词 *t <sub>1</sub>* ，下一个单词为*t<sub>2</sub>T3 的条件概率可以通过计算训练语料库中一对 *(t <sub>1</sub>* *、t <sub>2</sub> )* 的总出现次数并将其归一化为单词 *t <sub>1</sub>* 在*

![](assets/4011e558-b4fc-468a-89cc-3ae457494668.png)

对于三元模型，当前单词*t<sub>3</sub>T3】的条件概率给定它前面的两个单词 *t <sub>1</sub> ，t <sub>2</sub>* ，可以估计如下:*

![](assets/a4e37492-f2ae-4999-b8d1-53d9afac5fba.png)

超越三元模型通常会导致稀疏性。即使对于二元模型，我们也可能会有几个二元模型的条件概率缺失，因为它们不会出现在训练语料库中。然而，那些缺失的二元模型可能非常相关，估计它们的条件概率非常重要。不用说，n-gram 模型倾向于为训练数据中出现的单词对估计高条件概率，而忽略那些没有出现的单词对。

# 语言模型的困惑

困惑度量用于评估语言模型的有用性。假设我们已经在一个训练语料库上训练了一个语言模型，让学习到的句子或文本的概率模型为 *P(。)*。模型的困惑 *P(。)*在从与训练语料库相同的人群中抽取的测试集语料库上进行评估。如果我们用 *M* 字表示测试集语料库，那么说 *(w <sub>1</sub> ，w <sub>2</sub> ，w <sub>3</sub> ，。。。。。，w <sub>M</sub> )* ，则模型对测试集序列的困惑由下式表示:

![](assets/3ae0b20f-358d-46c3-a2df-addd87872199.png)

所示的 *H* 的表达式测量每个单词的不确定性:

![](assets/1628bf07-cbf5-4c9d-a63d-de3baa23d975.png)

根据语言模型，我们可以将测试语料库的概率表达式分解如下:

![](assets/f6cd48b3-1beb-41ae-aedb-3cc8382266ca.png)

如果我们将测试集中第*I*个单词以前面的单词为条件的概率表示为 *<sub>P</sub> (s <sub>i</sub> )* ，那么测试语料库的概率给出如下:

![](assets/9028a0b4-506c-49df-a783-869bb5c75426.png)

在这里，*T1】P(s<sub>I</sub>)= P(w<sub>I</sub>/w<sub>1</sub>w<sub>2</sub>。。。w <sub>i-1</sub> )* 。结合 *(1)* 和 *(4)* ，困惑可以写成:

![](assets/785a9853-f2d3-4c28-a718-aeb9e2fcb6de.png)

假设我们有一个语言模型 *P(。)*还有一个测试集*我爱机器学习*来评价。根据语言模型，测试集的概率如下:

![](assets/82e0b0cf-e3ee-43a0-962e-91bf737abd0a.png)

如果语言模型的训练语料也是*我爱机器学习，*测试集的概率会是 1，导致*的对数概率是 0*，而*的困惑度是 1*。这意味着模型可以完全确定地生成下一个单词。

另一方面，如果我们有一个大小为 *N* = 20，000 的词汇的更真实的训练语料库，并且训练后的模型在测试数据集上的困惑度为 100，那么平均来说，为了预测序列中的下一个单词，我们已经将搜索空间从 20，000 个单词缩小到 100 个单词。

让我们看看最坏的情况，在这种情况下，我们设法建立了一个模型，其中每个单词都独立于序列中的前几个单词:

![](assets/a231a609-f58f-4faa-a081-64addf74b643.png)

对于一组 *M* 单词，使用 *(5)* 的困惑如下:

![](assets/ba0cff31-c3c7-49ec-9967-d48fdcdb8ae4.png)

如果我们像以前一样有 *N* = 20，000，那么为了预测序列中的任何单词，需要考虑词汇表中的所有 *N* 单词，因为它们具有相同的概率。在这种情况下，我们无法减少单词上的平均搜索空间来预测序列中的单词。

# 翻译模式

**翻译模型**可以认为是机器翻译模型的心脏。在翻译模型中，我们需要估计概率 *P(s/t)* ，其中 *s* 为源语句子， *t* 为目标语句子。在这里，源句被给出，而目标是我们寻求发现的。因此，这个概率可以被称为给定目标句子的源句子的可能性。例如，让我们假设我们正在将一个源文本从法语翻译成英语。所以，在 *P(s/t)* 的语境中，我们的目的语是法语，我们的源语是英语，而在实际翻译的语境中，即 *P(s/t)P(t)* 中，我们的源语是法语，我们的目的语是英语。

翻译主要包括三个部分:

*   **生育率** *:* 并非源语言中的所有单词在目标语言中都有对应的单词。例如，英语句子 *Santanu 热爱数学*在法语中被翻译为 *Santanu 瞄准数学*。我们可以看到，英语中的 *m* *ath* 在法语中被翻译成了两个词，就像*les mathematics*一样。形式上，*生殖力*定义为源语词在目标语中生成的字数的概率分布，可以表示为*P**(n/w<sub>s</sub>)*，其中 *w <sub>s</sub>* 代表源词。使用概率分布代替硬编码数字 *n* ，因为相同的单词可能基于上下文产生不同长度的翻译。
*   **扭曲**:源句和目的句之间的词与词的对应对于任何机器翻译系统都很重要。然而，源语言句子中单词的位置可能不总是与其在目标语言句子中的对应位置完全同步。扭曲通过概率函数涵盖了对齐的概念， *P(p <sub>t</sub> /p <sub>s</sub> ，l)* ，其中 *p <sub>t</sub>* 和 *P <sub>s</sub>* 分别代表目标词和源词的位置，而 *l* 代表目标句的长度。如果源语言是英语，目标语言是法语，那么 *P(p <sub>t</sub> /p <sub>s</sub> ，l)* 表示在给定长度为 *l* 的法语句子中，位置*P<sub>s</sub>T27】的英语单词对应于位置*P<sub>s</sub>T31】的法语单词的概率。**
*   **词与词的翻译**:最后我们来看词与词的翻译，一般用目标语词给定源语词的概率分布来表示。对于给定的源语言单词,*w<sub>s</sub>T5】，概率可以表示为*P(w<sub>t</sub>/w<sub>s</sub>)*，其中*w<sub>t</sub>T15】代表目标语言单词。**

对于语言模型来说，在训练过程中需要估计生殖力概率、失真概率和单词到单词的翻译概率。

现在，让我们回到最初估计概率 *P(s/t)* 的问题。如果用 *E* 表示英语句子，用 *F* 表示法语句子，需要计算 *P(F/E)* 的概率。为了考虑单词的对齐，我们将概率修改为 *P(F，a/E)* ，其中 *a* 代表法语中目标句的对齐。这种比对将帮助我们注入与扭曲和生育力相关的信息。

让我们通过一个例子来计算概率 *P(F，a/E)* 。让一个具体的英语句子用一个五个字的句子来表示， *e = (e <sub>1</sub> ，e <sub>2</sub> ，e <sub>3</sub> ，e <sub>4</sub> ，e <sub>5</sub> )* ，这其实就是实际法语句子 *f = (f <sub>1</sub> ，f <sub>2</sub> ，f <sub>3</sub> 的正确翻译同样，让单词的对应对齐如下:*

*   *e<sub>1</sub>*→*f<sub>6</sub>*
*   *e* <sub>*2*</sub> → *在法语中不对应任何单词*
*   *e**→*【f】<sub>*、*【f】**</sub>**
***   *e*→**<sub>1</sub>****   *e<sub>5</sub>*→*f**<sub>2</sub>**   *f <sub>5</sub>* → *在英语*中没有对应的单词***

 ***由于这是一个概率模型，该算法将尝试不同对齐的不同英语句子，其中具有正确对齐的正确英语句子应该具有最高的概率，给定法语句子。

让我们将第一个英语单词视为*e<sub>1</sub>*—它与法语单词 *f <sub>6</sub>* 对齐，并且还发出一个法语单词，如下所示:

![](assets/688b2388-8434-4d98-8d00-66ea374148b9.png)

现在，让我们将对齐视为两个组件的组合:扭曲 *a <sub>d</sub>* 和生育力 *f <sub>d</sub>* 。 *(1)* 中的表达式可以改写如下:

![](assets/edaf41f6-4172-4397-b791-f714571e57ca.png) ![](assets/546bd7e5-37e3-44ba-a006-3378e4664053.png)

如果我们仔细观察， *P(f <sub>5</sub> /e <sub>1</sub> )* 为平移概率，*P(a<sub>f</sub>/e<sub>1</sub>)*为生育力，而 *P(a <sub>d</sub> /e <sub>1</sub> ，f <sub>5</sub> )* 为畸变概率。我们需要对英语句子中所有给定的英语单词和给定的法语句子进行此练习，以计算 *P(F，a/E)* 。最后我们需要取最好的英文句子![](assets/da614761-d0d0-4d7c-a1db-6666a7d68f5b.png)，对齐![](assets/10715372-f52d-4d7d-a131-032da0542465.png)，这样最大化概率 *P(F，a/E)P(E)* 。这看起来如下:

![](assets/396ee058-a561-4b7e-a60d-1a568bbb52b6.png)

这里需要注意的一点是，为了寻找最佳翻译而尝试不同的对齐方式和不同的可能单词翻译可能会变得难以计算，因此，需要部署聪明的算法来在最短的时间内找到最佳翻译。

# 神经机器翻译

**神经机器翻译** ( **NMT** )使用深度神经网络执行从源语言到目标语言的机器翻译。神经翻译机接收源语言的文本作为输入序列，并将其编码为隐藏的表示，然后将其解码以产生目标语言的翻译文本序列。这种 NMT 系统的一个关键优点是，整个机器翻译系统可以从端到端一起训练，不像基于规则和统计的机器翻译系统。一般来说，RNN 体系结构，如 **LSTMs** ( **长短期记忆**)和/或**门控递归单元** ( **GRUs** )用于神经翻译机体系结构。

NMT 相对于其他传统方法的一些优势如下:

*   NMT 模型的所有参数都是基于损失函数进行端到端训练的，因此降低了模型的复杂性
*   这些 NMT 模型使用了比传统方法大得多的上下文，因此产生了更准确的翻译
*   NMT 模型更好地利用了单词和短语的相似性
*   rnn 允许更高质量的文本生成，因此相对于翻译文本的语法，翻译更加准确

# 编码器-解码器模型

下图所示为神经翻译机的架构，该机器使用一个 LSTM 作为编码器，将输入源语言序列编码为最终隐藏状态 *h <sub>f</sub>* 和最终存储单元状态 *c <sub>f</sub>* 。最终的隐藏状态和单元格状态*【h<sub>f</sub>、c<sub>f</sub>*将捕捉整个输入序列的上下文。因此，*【h<sub>f</sub>，c<sub>f</sub>*成为解码器网络可以调节的良好候选。

该隐藏和单元状态信息*【h】<sub>f</sub>，c<sub>f</sub>*被馈送到解码器网络作为初始隐藏和单元状态，然后解码器在目标序列上被训练，输入目标序列相对于输出目标序列滞后 1。根据解码器，输入序列的第一个字是伪字`[START]`，而输出标签是字 *c'est* 。解码器网络只是被训练成一个生成语言模型，其中在任何时间步 *t* ，输出标签，只是相对于输入的下一个单词，即*y<sub>t</sub>= x<sub>t+1</sub>*。唯一新的是编码器的最终隐藏和单元状态(即*【h<sub>f</sub>、c<sub>f</sub>*)被馈送到解码器的初始隐藏和单元状态，为翻译提供内容。

这意味着训练过程可以被认为是为目标语言(由解码器表示)建立一个语言模型，条件是代表源语言的编码器的隐藏状态:

![](assets/6b5fdbd2-9d77-4305-b64c-3a62dadede35.png)

Figure 3.3: High level encoder-decoder architecture of a neural machine translation system 

如果 *T* 是源语言文本![](assets/39b615f1-11b1-4356-b3bb-e432b66d1e58.png)对应的目标语言文本，那么对于训练来说我们只是试图最大化 *P <sub> w </sub> (T <sub> t+1 </sub> /S，T)* 相对于 *W* 的对数概率，其中 *T <sub> s+1 </sub>* 代表偏移一个时间步长的目标语言文本， *W* 代表编码器-解码器

既然我们已经讨论了编码器-解码器 NMTs 的训练过程，现在我们将看看如何在推理过程中使用训练好的模型。

# 使用编码器-解码器模型进行推断

在 **NMT** ( **神经翻译机**)上运行推理的架构流程与训练 NMT 有点不同。以下是使用 NMT 进行推理的体系结构流程:

![](assets/c8e700f7-0973-4a7a-b1d8-1f00a2ef91e7.png)

Figure 3.4: Inference from an encoder/decoder-based neural machine translation

在推断过程中，源语言输入序列被馈送到编码器网络，最终产生的隐藏和单元状态,*【h】<sub>f</sub>、c<sub>f</sub>*被馈送到解码器隐藏和单元状态。解码器被转换成单个时间步长，馈送到解码器的第一个输入是伪`[START]`字。于是，基于*【h<sub>f</sub>、c<sub>f</sub>*和初始伪字`[START]`，解码器将输出一个字， *w* ，以及新的隐藏和单元状态，*【h<sub>d</sub>、c<sub>d</sub>*。这个单词 *w* 以新的隐藏和单元状态*【h<sub>d</sub>、c<sub>d</sub>*再次被馈送到解码器，以生成下一个单词。重复这个过程，直到我们遇到一个序列结束字符。

# 实现序列到序列的神经翻译机

我们要建立一个神经机器翻译系统，它将学习把英语短句翻译成法语。为此，我们将使用位于[http://www.manythings.org/anki/](http://www.manythings.org/anki/)的英语到法语文本语料库(`fra-eng/fra.txt`)。

# 处理输入数据

文本数据不能直接输入任何神经网络，因为神经网络只能理解数字。我们将把每个单词视为一个长度等于每个语料库中存在的单词数的热门编码向量。如果英语语料库包含 1000 个单词，则热门编码向量*v<sub>e</sub>T3】的维数为 1000，即*v<sub>e</sub>∈R<sup>1000 x 1</sup>*。*

我们将通读英语和法语语料库，并确定每个语料库中独特单词的数量。我们还将通过索引来表示单词，对于单词的一个热编码向量，对应于该单词的索引将被设置为 1，而其余的索引将被设置为零。举个例子，假设在英语语料库中，我们有四个词:*全球变暖是真实存在的*。我们可以将每个单词的索引定义如下:

| **字** | **指数** |
| 全球的 | Zero |
| 加温 | one |
| 是 | Two |
| 真实的 | three |

在这种情况下，我们可以将单词*全局*的一热编码向量定义为*【1，0，0】<sup>T</sup>*。同样的，*实数*的一热编码向量可以表示为*【1，0，0】<sup>T</sup>*。

现在，转向每个句子或记录的源语言输入，我们将有一个单词序列表示为一个热门编码向量序列。下一个明显的问题是如何管理序列长度，因为这可能会有所不同。最被接受的方法是具有固定的序列长度，或者等于语料库中句子的最大序列长度，或者是预定的合理长度。我们将使用目标句子两次:一次作为解码器的翻译输出序列，一次作为解码器的输入，唯一的区别是输出序列将比输入序列提前一个时间步长。因此，输入目标序列中的第一个单词将是虚拟单词`[START]`，而输出目标序列中的最后一个单词将是虚拟单词`[END]`，标志着句子序列的结束。

如果目标法语句子是`Je m'appelle Santanu`*，解码器中的输入目标和输出目标序列如下:*

 *```
[START],[Je],[m’appelle] [Santanu]
[Je],[m’appelle] [Santanu][END]
```

我们选择用制表符表示`[START]`，用下一行字符表示`[END]`。

我们将数据创建活动分为三个部分:

*   读取源(英语)和目标(法语)文本的输入文件
*   从源语言和目标语言文本中构建词汇
*   将输入的英语和法语语料库处理为它们的数字表示，以便它们可以用于神经机器翻译网络

这里说明的`read_input_file`功能可用于阅读源语言和目标语言文本:

```
    def read_input_file(self,path,num_samples=10e13):
        input_texts = []
        target_texts = []
        input_words = set()
        target_words = set()

        with codecs.open(path, 'r', encoding='utf-8') as f:
            lines = f.read().split('\n')

        for line in lines[: min(num_samples, len(lines) - 1)]:
            input_text, target_text = line.split('\t')
              # \t as the start of sequence 
            target_text = '\t ' + target_text + ' \n'
              # \n as the end of sequence
            input_texts.append(input_text)
            target_texts.append(target_text)
            for word in input_text.split(" "):
                if word not in input_words:
                    input_words.add(word)
            for word in target_text.split(" "):
                if word not in target_words:
                    target_words.add(word)

        return input_texts,target_texts,input_words,target_words
```

`vocab_generation`功能可用于建立源语言和目标语言的词汇集:

```
    def vocab_generation(self,path,num_samples,verbose=True):

        input_texts,target_texts,input_words,target_words =   
        self.read_input_file(path,num_samples)
        input_words = sorted(list(input_words))
        target_words = sorted(list(target_words))
        self.num_encoder_words = len(input_words)
        self.num_decoder_words = len(target_words)
        self.max_encoder_seq_length = 
        max([len(txt.split(" ")) for txt in input_texts])
        self.max_decoder_seq_length =
        max([len(txt.split(" ")) for txt in target_texts])

        if verbose == True:

            print('Number of samples:', len(input_texts))
            print('Number of unique input tokens:',
                  self.num_encoder_words)
            print('Number of unique output tokens:',
                   self.num_decoder_words)
            print('Max sequence length for inputs:',
                   self.max_encoder_seq_length)
            print('Max sequence length for outputs:',
                   self.max_decoder_seq_length)

        self.input_word_index =
        dict([(word, i) for i, word in enumerate(input_words)])
        self.target_word_index = 
        dict([(word, i) for i, word in enumerate(target_words)])
        self.reverse_input_word_dict = 
        dict((i, word) for word, i in self.input_word_index.items())
        self.reverse_target_word_dict = 
        dict((i, word) for word, i in self.target_word_index.items())
```

`process_input`函数利用前面函数中构建的输入和目标文本以及词汇表，将文本数据转换为神经翻译机体系结构可以使用的数字形式。`process_input`功能的代码如下:

```
        def process_input(self,input_texts,target_texts=None,verbose=True):

        encoder_input_data = 
        np.zeros((len(input_texts), self.max_encoder_seq_length,               
                 self.num_encoder_words), dtype='float32')

        decoder_input_data = 
         np.zeros((len(input_texts), self.max_decoder_seq_length, 
                  self.num_decoder_words), dtype='float32')

        decoder_target_data = 
        np.zeros((len(input_texts), self.max_decoder_seq_length, 
                 self.num_decoder_words), dtype='float32')

        if self.mode == 'train':
            for i, (input_text, target_text) in 
            enumerate(zip(input_texts,target_texts)):
                for t, word in enumerate(input_text.split(" ")):
                    try:
                        encoder_input_data[i, t, 
                                          self.input_word_index[word]] = 1.
                    except:
                        print(f'word {word} 
                             encoutered for the 1st time, skipped')
                for t, word in enumerate(target_text.split(" ")):
                # decoder_target_data is ahead of decoder_input_data
                  by one timestep
                    decoder_input_data[i, t, 
                    self.target_word_index[word]] = 1.
                    if t > 0:
                    # decoder_target_data will be ahead by one timestep
                    #and will not include the start character.
                        try:
                            decoder_target_data[i, t - 1, 
                            self.target_word_index[word]] = 1.
                        except:
                            print(f'word {word} 
                                  encoutered for the 1st time,skipped')

            return 
            encoder_input_data,decoder_input_data,decoder_target_data,
            np.array(input_texts),np.array(target_texts)

        else:
            for i, input_text in enumerate(input_texts):
                for t, word in enumerate(input_text.split(" ")):
                    try:
                        encoder_input_data[i, t, 
                                          self.input_word_index[word]] = 1.
                    except:
                        print(f'word {word} 
                        encoutered for the 1st time, skipped')

            return encoder_input_data,None,None,np.array(input_texts),None
```

`encoder_input_data` 变量将包含输入源数据，并且将是记录数量、时间步长数量和每个单向编码向量的维度的三维数组。类似地，`decoder_input_data` 将包含输入的目标数据，而`decoder_target_data` 将包含目标标签。在执行上述功能时，将生成训练机器翻译系统所需的所有相关输入和输出。以下代码块包含与使用`40000`样本执行`vocab_generation`功能相关的显示统计信息:

```

('Number of samples:', 40000)
('Number of unique input tokens:', 8658)
('Number of unique output tokens:', 16297)
('Max sequence length for inputs:', 7)
('Max sequence length for outputs:', 16)

```

从前面的统计中我们可以看到，`40000`语料库中输入的英语单词数，以及文本句子数为`8658`，而对应的法语单词数为`16297`。这表明一个事实，即每个英语单词平均发出大约两个法语单词。同样，我们看到英语句子中的最大单词数是`7`，而法语句子中的最大单词数是`14`，如果不包括我们为了训练目的添加到法语句子中的`[START]`和`[END]`字符。这也证实了这样一个事实，平均来说，每个被翻译的英语句子将产生两倍的单词。

让我们看看神经翻译机的输入和目标的形状:

```
('Shape of Source Input Tensor:',(40000, 7, 8658))
('Shape of Target Input Tensor:',(40000, 16, 16297))
(Shape of Target Output Tensor:',(40000, 16, 16297))
```

编码器数据的形状为`(40000, 7, 8658)`，其中第一维是源语言句子的数量，第二维是时间步长的数量，最终维度是一个热门编码向量的大小，即`8658`，对应于英语词汇中的`8658`源语言单词。类似地，我们看到对于目标输入和输出张量，一热编码向量的大小为`16297`，对应于法语词汇中的`16297`单词。法语句子的时间步数为`16`。

# 定义神经机器翻译模型

如前所述，编码器将通过 LSTM 处理源输入序列，并将源文本编码成有意义的摘要。有意义的摘要将存储在最终的序列步骤隐藏和单元状态*h<sub>f</sub>T3】和*c<sub>f</sub>T7】中。这些向量在一起(即*【h<sub>f</sub>；c<sub>f</sub>】*)提供关于源文本的有意义的上下文，并且解码器被训练以产生其自己的目标序列，该目标序列以隐藏和单元状态向量*【h<sub>f</sub>为条件；c<sub>f</sub>】*。**

如下图所示，*图 3.5，*是一个英法翻译的训练过程的详细示意图。英语句子*这是美好的一天*通过一个 LSTM 转换成一个意义总结，然后存储在隐藏和细胞状态向量*h<sub>f</sub>中；c<sub>f</sub>】*。然后解码器通过嵌入在*【h<sub>f</sub>中的信息，以输入的源语句为条件，生成自己的目标序列；c<sub>f</sub>】*。时间步 *t* 的解码器预测下一个目标词，即给定源句的时间步 *t + 1* 的词。这就是为什么目标输入单词和目标输出单词之间有一个时间步长的滞后。对于第一时间步，解码器在目标文本序列中没有任何在先单词，因此它唯一可用于预测目标单词的信息是编码在*【h】<sub>f</sub>中的信息；c<sub>f</sub>*作为初始隐藏向量和细胞状态向量。像编码器一样，解码器也使用 LSTM，并且如所讨论的，输出目标序列比输入目标序列领先一个时间步长:

![](assets/421b234c-10f6-4cbe-9233-97a33233b2ca.png)

Figure 3.5: Illustration of the machine translation network flow while training

我们基于*图 3.5* 所示的架构，在函数`model_enc_dec`中定义了用于训练的编码器解码器端到端模型。这里，**编码器(LSTM 1)** 顺序接收源语言文本单词，并在**编码器(LSTM 1)** 的最后顺序步骤中捕获源语言句子或文本的整个上下文。来自编码器的该上下文作为初始状态被馈送给**解码器(****【LSTM 2】)**，该解码器学习基于当前单词来预测下一个单词，因为在训练期间，我们有目标语言的句子/文本，因此解码器可以仅将其输入移动一个时间步长来形成目标:

```
    def model_enc_dec(self):
        #Encoder Model
        encoder_inp = 
        Input(shape=(None,self.num_encoder_words),name='encoder_inp')
        encoder = LSTM(self.latent_dim, return_state=True,name='encoder')
        encoder_out,state_h, state_c = encoder(encoder_inp)
        encoder_states = [state_h, state_c]

        #Decoder Model
        decoder_inp = 
        Input(shape=(None,self.num_decoder_words),name='decoder_inp')
        decoder_lstm = 
        LSTM(self.latent_dim, return_sequences=True,   
        return_state=True,name='decoder_lstm')
        decoder_out, _, _ = 
        decoder_lstm(decoder_inp, initial_state=encoder_states)
        decoder_dense = 
        Dense(self.num_decoder_words, 
        activation='softmax',name='decoder_dense')
        decoder_out = decoder_dense(decoder_out)
        print(np.shape(decoder_out))
        #Combined Encoder Decoder Model
        model = Model([encoder_inp, decoder_inp], decoder_out)
        #Encoder Model 
        encoder_model = Model(encoder_inp,encoder_states)
        #Decoder Model
        decoder_inp_h = Input(shape=(self.latent_dim,))
        decoder_inp_c = Input(shape=(self.latent_dim,))
        decoder_input = Input(shape=(None,self.num_decoder_words,))
        decoder_inp_state = [decoder_inp_h,decoder_inp_c]
        decoder_out,decoder_out_h,decoder_out_c =   
        decoder_lstm(decoder_input,initial_state=decoder_inp_state)
        decoder_out = decoder_dense(decoder_out)
        decoder_out_state = [decoder_out_h,decoder_out_c]
        decoder_model = Model(inputs = 
        [decoder_input] + decoder_inp_state,output=
        [decoder_out]+ decoder_out_state)
        plot_model(model,show_shapes=True, to_file=self.outdir + 
                   'encoder_decoder_training_model.png')
        plot_model(encoder_model,show_shapes=True, to_file=self.outdir + 
                   'encoder_model.png')
        plot_model(decoder_model,show_shapes=True, to_file=self.outdir + 
                   'decoder_model.png')

        return model,encoder_model,decoder_model

```

虽然用于训练的模型是直接的端到端模型，但推理模型并不那么直接，因为我们不知道解码器在每个时间步长的先验输入。我们将在*构建推理模型*部分更详细地讨论推理模型。

# 神经翻译机的损失函数

神经翻译机的损失函数是预测模型序列中每个目标词的平均交叉熵损失。实际目标词和预测目标词可以是我们所取的法语语料库中的 *16，297* 个词中的任意一个。时间步长 *t* 处的目标标签将是一个单热编码向量*y<sub>t</sub>∑{ 0，1} <sup>16297</sup>* ，而预测输出将是法语词汇中 *16，297* 个单词中每个单词的概率形式。如果我们将预测的输出概率向量表示为*p<sub>t</sub>∑(0，1) <sup>16297</sup>* ，那么特定句子 *s* 每个时间步长的平均分类损失由下式给出:

![](assets/be4d5566-e340-4986-8364-96b61806475a.png)

我们通过对所有序列时间步长的损失进行求和，得到整个句子的损失，如下所示:

![](assets/b7bc5575-d588-40d6-926a-4178a812cd58.png)

由于我们使用的是小批量随机梯度下降，小批量的平均成本可以通过平均小批量中所有句子的损失来获得。如果我们取尺寸为 *m* 的小批量，每个小批量的平均损失如下:

![](assets/c36a2af9-5786-4cb3-baf8-29dbd0b17918.png)

小批量成本用于计算随机梯度下降的梯度。

# 训练模型

我们首先执行`model_enc_dec` 函数定义模型进行训练，定义`encoder_model`和`decoder_model`进行推理，然后用`categorical_crossentropy`损失和`rmsprop`优化器进行编译。我们可以尝试其他的优化器，比如 Adam，有动量的 SDG 等等，但是，目前我们还是坚持`rmsprop` *。*功能可定义如下:

```
# Run training

    def train(self,encoder_input_data,decoder_input_data,
              decoder_target_data):
        print("Training...")

        model,encoder_model,decoder_model = self.model_enc_dec()

        model.compile(optimizer='rmsprop', loss='categorical_crossentropy')

        model.fit([encoder_input_data, decoder_input_data],
                  decoder_target_data,
                  batch_size=self.batch_size,
                  epochs=self.epochs,
                  validation_split=0.2)
        # Save model
        model.save(self.outdir + 'eng_2_french_dumm.h5')
        return model,encoder_model,decoder_model

```

我们在 80%的数据上训练模型，并使用剩余的 20%进行验证。列车/测试分离由如下定义的功能执行:

```
def train_test_split(self,num_recs,train_frac=0.8):
        rec_indices = np.arange(num_recs)
        np.random.shuffle(rec_indices)
        train_count = int(num_recs*0.8)
        train_indices = rec_indices[:train_count]
        test_indices = rec_indices[train_count:]
        return train_indices,test_indices
```

# 构建推理模型

让我们试着回忆一下推理模型的工作机制，看看我们如何使用已经训练好的模型的组件来构建它。模型的编码器部分应该以源语言中的文本句子为输入进行工作，并提供最终的隐藏和细胞状态向量，*【h】<sub>f；</sub>c<sub>f</sub>*，作为输出。我们不能像现在这样使用解码器网络，因为目标语言输入单词不能再被馈送到解码器。相反，我们将解码器网络折叠成由单个步骤组成，并将该步骤的输出作为下一步的输入。我们以伪字`[START]`作为解码器的第一个输入字开始，加上*【h】<sub>f；</sub>c<sub>f</sub>*，作为其初始隐藏和单元状态。目标输出字 *w <sub>1</sub>* 和隐藏和单元格状态*【h<sub>1；</sub>c<sub>1</sub>*由解码器用`[START]`和*h<sub>f 生成；作为输入的</sub>c<sub>f</sub>*再次被馈送到解码器以生成下一个字，并且该过程重复直到解码器输出伪字`[END]`。下图说明了推理过程的分步表示，以便于解释:

![](assets/32c9e729-5872-4e25-bf42-0f87c5ba9d4d.png)

Figure 3.6: Step-wise illustration of the inference process

从上图可以看出，解码器第一步的输出是`C'est`，而隐藏和单元状态是![](assets/8f9d7576-9524-451d-9733-333ec39cf99a.png)。如虚线所示，这再次被馈送到解码器，以生成下一个字以及下一组隐藏和单元状态。重复该过程，因为解码器输出伪结束字符`[END]`。

为了进行推断，我们可以将网络的编码器部分保持原样，并进行一些修改来折叠解码器，使其由一个时间步骤组成。概括地说，无论 RNN 是由一个时间步长还是几个时间步长组成，与 RNN 相关的权重都不会改变，因为 RNN 的所有时间步长都具有相同的权重。

对于推断，我们可以看到训练模型的编码器部分被用作函数`model_enc_dec`中的`encoder_model`。类似地，使用相同的解码器 LSTM 定义单独的`decoder_model`，该解码器将输入作为隐藏状态、单元状态和输入字，并输出目标字和更新的隐藏和单元状态。为了清楚起见，再次重复我们定义推理模型的功能`model_enc_dec`，即`encoder_model`和`decoder_model`:

```
def model_enc_dec(self):
        #Encoder Model
        encoder_inp = 
        Input(shape=(None,self.num_encoder_words),name='encoder_inp')
        encoder = LSTM(self.latent_dim, return_state=True,name='encoder')
        encoder_out,state_h, state_c = encoder(encoder_inp)
        encoder_states = [state_h, state_c]

        #Decoder Model
        decoder_inp = 
        Input(shape=(None,self.num_decoder_words),name='decoder_inp')
        decoder_lstm = 
        LSTM(self.latent_dim, return_sequences=True, 
        return_state=True,name='decoder_lstm')
        decoder_out, _, _ = 
        decoder_lstm(decoder_inp, initial_state=encoder_states)
        decoder_dense =
        Dense(self.num_decoder_words, 
        activation='softmax',name='decoder_dense')
        decoder_out = decoder_dense(decoder_out)
        print(np.shape(decoder_out))
        #Combined Encoder Decoder Model
        model  = Model([encoder_inp, decoder_inp], decoder_out)
        #Encoder Model 
        encoder_model = Model(encoder_inp,encoder_states)
        #Decoder Model
        decoder_inp_h = Input(shape=(self.latent_dim,))
        decoder_inp_c = Input(shape=(self.latent_dim,))
        decoder_input = Input(shape=(None,self.num_decoder_words,))
        decoder_inp_state = [decoder_inp_h,decoder_inp_c]
        decoder_out,decoder_out_h,decoder_out_c =   
        decoder_lstm(decoder_input,initial_state=decoder_inp_state)
        decoder_out = decoder_dense(decoder_out)
        decoder_out_state = [decoder_out_h,decoder_out_c]
        decoder_model = Model(inputs = 
        [decoder_input] + decoder_inp_state,output=
        [decoder_out]+ decoder_out_state)
        plot_model(model,to_file=self.outdir + 
                   'encoder_decoder_training_model.png')
        plot_model(encoder_model,to_file=self.outdir + 'encoder_model.png')
        plot_model(decoder_model,to_file=self.outdir + 'decoder_model.png')

        return model,encoder_model,decoder_model
```

解码器将一次运行一个时间步长。在第一种情况下，它将从编码器获取隐藏和单元状态，并基于虚拟单词`[START]`猜测翻译的第一个单词。在第一步中预测的单词连同生成的隐藏和单元状态一起再次被馈送到解码器以预测第二个单词，并且该过程继续直到由虚拟单词`[END]`表示的句子结束被预测。

现在，我们已经定义了将源语句/文本翻译成目标语言所需的所有函数，我们将它们结合起来构建一个函数，该函数将生成翻译后的序列，给定源语言输入序列或句子:

```
    def decode_sequence(self,input_seq,encoder_model,decoder_model):
        # Encode the input as state vectors.
        states_value = encoder_model.predict(input_seq)

        # Generate empty target sequence of length 1.
        target_seq = np.zeros((1, 1, self.num_decoder_words))
        # Populate the first character of target sequence 
          with the start character.
        target_seq[0, 0, self.target_word_index['\t']] = 1.

        # Sampling loop for a batch of sequences
        stop_condition = False
        decoded_sentence = ''

        while not stop_condition:
            output_word, h, c = decoder_model.predict(
                [target_seq] + states_value)

            # Sample a token
            sampled_word_index = np.argmax(output_word[0, -1, :])
            sampled_char = 
            self.reverse_target_word_dict[sampled_word_index]
            decoded_sentence = decoded_sentence + ' ' + sampled_char

            # Exit condition: either hit max length
            # or find stop character.
            if (sampled_char == '\n' or
            len(decoded_sentence) > self.max_decoder_seq_length):
                stop_condition = True

            # Update the target sequence (of length 1).
            target_seq = np.zeros((1, 1, self.num_decoder_words))
            target_seq[0, 0, sampled_word_index] = 1.

            # Update states
            states_value = [h, c]

        return decoded_sentence
```

一旦我们训练了模型，我们就在保持数据集上运行推理并检查翻译质量。`inference`功能可以编码如下:

```
    def inference(self,model,data,encoder_model,decoder_model,in_text):
        in_list,out_list = [],[]
        for seq_index in range(data.shape[0]):

            input_seq = data[seq_index: seq_index + 1]
            decoded_sentence =  
            self.decode_sequence(input_seq,encoder_model,decoder_model)
            print('-')
            print('Input sentence:', in_text[seq_index])
            print('Decoded sentence:',decoded_sentence)
            in_list.append(in_text[seq_index])
            out_list.append(decoded_sentence)
        return in_list,out_list

```

机器翻译模型可以通过调用 Python 脚本`MachineTranslation.py`在保持数据集上进行训练和验证，如下所示:

```
python MachineTranslation.py --path '/home/santanu/ML_DS_Catalog/Machine Translation/fra-eng/fra.txt' --epochs 20 --batch_size 32 -latent_dim 128 --num_samples 40000 --outdir '/home/santanu/ML_DS_Catalog/Machine Translation/' --verbose 1 --mode train
```

从机器翻译模型表现良好的保持数据集翻译几个英语句子的结果说明如下，以供参考:

```
('Input sentence:', u'Go.')
('Decoded sentence:', u' Va ! \n')
('Input sentence:', u'Wait!')
('Decoded sentence:', u' Attendez ! \n')
('Input sentence:', u'Call me.')
('Decoded sentence:', u' Appelle-moi ! \n')
('Input sentence:', u'Drop it!')
('Decoded sentence:', u' Laisse tomber ! \n')
('Input sentence:', u'Be nice.')
('Decoded sentence:', u' Soyez gentil ! \n')
('Input sentence:', u'Be fair.')
('Decoded sentence:', u' Soyez juste ! \n')
('Input sentence:', u"I'm OK.")
('Decoded sentence:', u' Je vais bien. \n')
('Input sentence:', u'I try.')
('Decoded sentence:', u' Je vais essayer.')
```

然而，也有机器翻译表现不佳的情况，如下所示:

```
('Input sentence:', u'Attack!')
('Decoded sentence:', u' ma ! \n')

('Input sentence:', u'Get up.')
('Decoded sentence:', u' un ! \n')
```

总之，前面说明的神经机器翻译实现在将相对较短的英语句子翻译成法语方面做得很好。我想强调的一点是使用热门编码向量来表示每种语言中的输入单词。当我们使用一个相对较小的 40，000 个单词的语料库时，词汇是合理的，因此，我们能够使用英语和法语词汇的大小分别为 8，658 和 16，297 的单向编码向量。使用更大的语料库，热门编码词向量的大小将进一步增加。这种稀疏的高维向量在比较两个词时没有任何相似性的概念，因为它们的余弦乘积将是*零*，即使两个词有几乎相同的含义。在下一节中，我们将看到如何使用在低得多的维度上工作的单词向量嵌入来解决这个问题。

# 单词向量嵌入

词向量嵌入可以用来表示比单热编码向量低得多的密集维度空间中的词，而不是单热编码向量。一个词的词向量嵌入 *w* 可以用*v<sub>w</sub>∈R<sup>m</sup>T7】来表示，其中 *m* 是词向量嵌入的维数。正如我们所看到的，虽然一个热编码向量的每个分量只能占用{0，1}的二进制值，但是单词向量嵌入的一个分量可以占用任何实数，因此具有更密集的表示。相似和类比的概念也与词向量嵌入有关。*

单词向量嵌入通常是通过诸如连续单词包方法、skip-gram、GloVe 等技术来训练的。我们不打算过多讨论它们的实现，但中心思想是以这样一种方式定义单词向量嵌入，即相似的单词被紧密地放置在 m 维欧几里德空间中:

![](assets/9f7522e1-949b-4004-b21d-4f95010db169.png)

Figure 3.7: Similarity and analogy illustration of GloVe embeddings

在上图中，我们绘制了**男子**、**女子**、**国王**和**王后**的手套单词向量嵌入的 2D·TSNE 视图。我们可以看到，**男**和**女**有着内在的相似性，就像**王**和**皇后**一样。此外，我们看到**国王**和**男人**的矢量差几乎与**女王**和**女人**的矢量差相同，这可能代表某种王权的概念。我们可以看到*男:王女:皇后*这样的类比除了表达词与词之间的相似性外，还可以通过词向量嵌入来表达。在下一节中，我们将讨论使用 RNN 中的嵌入层将输入单词表示为单词向量嵌入，而不是一个热门的编码向量。

# 嵌入层

嵌入层将输入单词的索引作为输入，并将单词的单词向量嵌入作为输出。嵌入层的维度是 *R <sup>d x V</sup>* ，其中 *d* 是词向量嵌入的维度， *V* 是词汇的大小。嵌入层可以根据问题学习嵌入本身，或者你可以提供一个预包含的嵌入层。在我们的例子中，我们将让神经机器翻译找出源语言和目标语言的嵌入向量，以实现良好的翻译。因此，我们定义的每个功能都应该改变，以适应嵌入层。

# 实施基于嵌入的 NMT

我们需要对现有的功能做一些修改，以适应嵌入层。首先，`process_input`将处理输入，以在不同的时间步骤中具有单词索引，而不是一个热编码向量，如下所示:

```
      def process_input(self,input_texts,target_texts=None,verbose=True):

        encoder_input_data = np.zeros(
            (len(input_texts), self.max_encoder_seq_length),
            dtype='float32')

        decoder_input_data = np.zeros(
            (len(input_texts), self.max_decoder_seq_length),
            dtype='float32')

        decoder_target_data = np.zeros(
            (len(input_texts), self.max_decoder_seq_length,1),
            dtype='float32')

        if self.mode == 'train':
            for i, (input_text, target_text) in 
                    enumerate(zip(input_texts,target_texts)):
                for t, word in enumerate(input_text.split(" ")):
                    try:
                        encoder_input_data[i, t] = 
                        self.input_word_index[word]
                    except:
                        encoder_input_data[i, t] = 
                        self.num_encoder_words

                for t, word in enumerate(target_text.split(" ")):
                # decoder_target_data is ahead of decoder_input_data
                  by one timestep
                    try:
                        decoder_input_data[i, t] = 
                        self.target_word_index[word]
                    except:
                        decoder_input_data[i, t] = 
                        self.num_decoder_words 
                    if t > 0:
                    # decoder_target_data will be ahead by one timestep
                    #and will not include the start character.
                        try:
                            decoder_target_data[i, t - 1] = 
                            self.target_word_index[word]
                        except:
                            decoder_target_data[i, t - 1] = 
                            self.num_decoder_words 
            print(self.num_encoder_words)
            print(self.num_decoder_words)
            print(self.embedding_dim)
            self.english_emb = np.zeros((self.num_encoder_words + 1,
                                        self.embedding_dim))
            self.french_emb = np.zeros((self.num_decoder_words + 1,
                                        self.embedding_dim))
            return encoder_input_data,decoder_input_data,decoder_target_data,np.array(input_texts),
np.array(target_texts)
        else:
            for i, input_text in enumerate(input_texts):
                for t, word in enumerate(input_text.split(" ")):
                    try:
                        encoder_input_data[i, t] = self.input_word_index[word]

```

与早期的`process_input`函数相比，唯一的变化是我们不再用单一的编码向量来表示单词，而是用单词的索引来表示。另外，你有没有注意到我们正在为词汇表中没有的单词增加一个额外的单词索引？对于训练数据来说，这种情况不应该发生，但是在测试过程中，可能会出现一个词汇中没有的全新单词。

以下是输入处理的统计数据:

```
Number of samples: 40000
Number of unique input tokens: 8658
Number of unique output tokens: 16297
Max sequence length for inputs: 7
Max sequence length for outputs: 16
('Shape of Source Input Tensor:', (40000, 7))
('Shape of Target Input Tensor:', (40000, 16))
('Shape of Target Output Tensor:', (40000, 16, 1))
```

如我们所见，源和目标输入张量现在具有`7`和`16`时间步长，但是没有单热编码向量的维度。每个时间步长都包含单词的索引。

下一个变化是关于编码器和解码器网络，以适应 LSTM 层之前的嵌入层:

```
    def model_enc_dec(self):
        #Encoder Model
        encoder_inp = Input(shape=(None,),name='encoder_inp')
        encoder_inp1 = 
        Embedding(self.num_encoder_words + 1,
                  self.embedding_dim,weights=[self.english_emb])
                  (encoder_inp)
        encoder = LSTM(self.latent_dim, return_state=True,name='encoder')
        encoder_out,state_h, state_c = encoder(encoder_inp1)
        encoder_states = [state_h, state_c]

        #Decoder Model
        decoder_inp = Input(shape=(None,),name='decoder_inp')
        decoder_inp1 = 
        Embedding(self.num_decoder_words+1,self.embedding_dim,weights=   
                  [self.french_emb])(decoder_inp)
        decoder_lstm = 
        LSTM(self.latent_dim, return_sequences=True, 
              return_state=True,name='decoder_lstm')
        decoder_out, _, _ = 
        decoder_lstm(decoder_inp1,initial_state=encoder_states)
        decoder_dense = Dense(self.num_decoder_words+1, 
                        activation='softmax',name='decoder_dense')
        decoder_out = decoder_dense(decoder_out)
        print(np.shape(decoder_out))
        #Combined Encoder Decoder Model
        model = Model([encoder_inp, decoder_inp], decoder_out)
        #Encoder Model 
        encoder_model = Model(encoder_inp,encoder_states)
        #Decoder Model
        decoder_inp_h = Input(shape=(self.latent_dim,))
        decoder_inp_c = Input(shape=(self.latent_dim,))
        decoder_inp_state = [decoder_inp_h,decoder_inp_c]
        decoder_out,decoder_out_h,decoder_out_c = 
        decoder_lstm(decoder_inp1,initial_state=decoder_inp_state)
        decoder_out = decoder_dense(decoder_out)
        decoder_out_state = [decoder_out_h,decoder_out_c]
        decoder_model = Model(inputs = 
                        [decoder_inp] + decoder_inp_state,output=
                        [decoder_out]+ decoder_out_state)

        return model,encoder_model,decoder_model
```

训练模型需要用`sparse_categorical_crossentropy`编译，因为输出目标标签被表示为索引，而不是一个热门的编码单词向量:

```
    def train(self,encoder_input_data,decoder_input_data,
              decoder_target_data):
        print("Training...")

        model,encoder_model,decoder_model = self.model_enc_dec()

        model.compile(optimizer='rmsprop', 
                      loss='sparse_categorical_crossentropy')
        model.fit([encoder_input_data, decoder_input_data],
                  decoder_target_data,
                batch_size=self.batch_size,
                epochs=self.epochs,
                validation_split=0.2)
        # Save model
        model.save(self.outdir + 'eng_2_french_dumm.h5')
        return model,encoder_model,decoder_model
```

接下来，我们需要对推理相关的函数进行修改，以适应嵌入相关的变化。用于推理的`encoder_model`和`decoder_model`现在分别使用英语和法语词汇的嵌入层。

最后，我们可以使用`decoder_model`和`encoder_model`如下创建序列生成器函数:

```
    def decode_sequence(self,input_seq,encoder_model,decoder_model):
        # Encode the input as state vectors.
        states_value = encoder_model.predict(input_seq)

        # Generate empty target sequence of length 1.
        target_seq = np.zeros((1, 1))
        # Populate the first character of target sequence
          with the start character.
        target_seq[0, 0] = self.target_word_index['\t']

        # Sampling loop for a batch of sequences
        stop_condition = False
        decoded_sentence = ''

        while not stop_condition:
            output_word, h, c = decoder_model.predict(
                [target_seq] + states_value)

            # Sample a token
            sampled_word_index = np.argmax(output_word[0, -1, :])
            try:
                sampled_char = 
                self.reverse_target_word_dict[sampled_word_index]
            except:
                sampled_char = '<unknown>'
            decoded_sentence = decoded_sentence + ' ' + sampled_char

            # Exit condition: either hit max length
            # or find stop character.
            if (sampled_char == '\n' or
            len(decoded_sentence) > self.max_decoder_seq_length):
                stop_condition = True

            # Update the target sequence (of length 1).
            target_seq = np.zeros((1, 1))
            target_seq[0, 0] = sampled_word_index

            # Update states
            states_value = [h, c]

        return decoded_sentence
```

模型的训练可以通过如下运行脚本来调用:

```
python MachineTranslation_word2vec.py --path '/home/santanu/ML_DS_Catalog-/Machine Translation/fra-eng/fra.txt' --epochs 20 --batch_size 32 --latent_dim 128 --num_samples 40000 --outdir '/home/santanu/ML_DS_Catalog-/Machine Translation/' --verbose 1 --mode train --embedding_dim 128 
```

The model is trained on GeForce GTX 1070 GPU, and it approximately takes around 9.434 minutes to train on 32,000 records and run inference on 8,000 records. Users are highly recommended to use a GPU, since RNNs are computation heavy and might take hours to train the same model on CPU.

我们可以运行机器翻译模型的训练，并通过运行 python 脚本`MachineTranslation.py`在保持数据集上执行验证，如下所示:

```
python MachineTranslation.py --path '/home/santanu/ML_DS_Catalog/Machine Translation/fra-eng/fra.txt' --epochs 20 --batch_size 32 -latent_dim 128 --num_samples 40000 --outdir '/home/santanu/ML_DS_Catalog/Machine Translation/' --verbose 1 --mode train
```

从嵌入向量方法获得的结果类似于一个热门编码词向量的结果。这里提供了一些来自维持数据集推理的翻译:

```
Input sentence: Where is my book?
Decoded sentence:  Où est mon Tom ?
-
Input sentence: He's a southpaw.
Decoded sentence:  Il est en train de
-
Input sentence: He's a very nice boy.
Decoded sentence:  C'est un très bon
-
Input sentence: We'll be working.
Decoded sentence:  Nous pouvons faire
-
Input sentence: May I have a program?
Decoded sentence:  Puis-je une ? 

-
Input sentence: Can you make it safe?
Decoded sentence:  Peux-tu le faire
-
Input sentence: We walked to my room.
Decoded sentence:  Nous avons devons
-
Input sentence: Don't stand too close.
Decoded sentence:  Ne vous en prie.
-
Input sentence: Where's the dog?
Decoded sentence:  Où est le chien ?
-
Input sentence: He's a hopeless case.
Decoded sentence:  Il est un fait de
-
Input sentence: Where were we?
Decoded sentence:  Où fut ? 

```

# 摘要

读者现在应该很好地理解几种机器翻译方法，以及神经翻译机器与传统机器有什么不同。我们现在应该已经深入了解了如何从头开始构建神经机器翻译系统，以及如何以有趣的方式扩展该系统。根据所提供的信息和实现演示，建议读者探索其他平行语料库数据集。

在这一章中，我们定义了嵌入层，但是没有加载预包含的嵌入，比如 GloVe、FastText 等等。建议读者在嵌入层加载预训练的单词向量嵌入，看看这样是否会产生更好的结果。在[第 4 章](04.html)、*时尚产业中的风格转移使用 GANs* 中，我们将通过一个与时尚产业中的风格转移相关的项目，使用生成对抗网络，这是人工智能领域的一场现代革命。****
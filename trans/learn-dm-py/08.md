# 用神经网络击败验证码

图像给数据挖掘者带来了有趣而困难的挑战。直到最近，在分析图像以提取信息方面只有少量进展。然而最近，随着自动驾驶汽车的进步，在很短的时间内取得了重大进展。最新的研究提供了能够理解图像的算法，用于商业监控、自动驾驶车辆和人员识别。

图像中有大量的原始数据，而对图像进行编码的标准方法——像素——本身并不能提供足够的信息。图像和照片可能会模糊不清、离目标太近、太暗、太亮、缩放、裁剪、倾斜或其他各种问题，这些问题会对试图提取有用信息的计算机系统造成严重破坏。神经网络可以将这些较低级别的特征组合成更高级别的模式，这些模式更能概括和处理这些问题。

在这一章中，我们将通过使用神经网络来预测验证码中的每个字母，从而从图像中提取文本数据。验证码是人类容易解决而计算机难以解决的图像，根据首字母缩略词:**完全自动化的公共图灵测试来区分计算机和人类**。许多网站将它们用于注册和评论系统，以阻止自动程序用虚假账户和垃圾评论淹没他们的网站。

这些测试有助于阻止程序(机器人)使用网站，例如一个机器人意图自动注册新的人到一个网站。我们扮演了这样一个垃圾邮件制造者的角色，试图绕过一个验证码保护的系统，向一个在线论坛发布消息。该网站由验证码保护，这意味着我们不能发布，除非我们通过测试。

本章涵盖的主题包括:

*   神经网络
*   创建我们自己的验证码和字母数据集
*   用于处理图像数据的 scikit 图像库
*   从图像中提取基本特征
*   将神经网络用于大规模分类任务
*   使用后处理提高性能
*   人工神经网络

# 人工神经网络

神经网络是最初基于人脑工作方式设计的一类算法。然而，现代的进步通常是基于数学而不是生物学的见解。神经网络是连接在一起的神经元的集合。每个神经元都是其输入的简单函数，这些输入通过某种函数组合起来生成输出:

![](images/B06162_08_01.jpg)

定义神经元处理的函数可以是任何标准函数，例如输入的线性组合，被称为**激活函数**。为了让常用的学习算法发挥作用，我们需要激活函数为*可导*和*平滑*。一个常用的激活函数是**逻辑函数**，它由下面的等式定义( *k* 通常简单地为 1， *x* 是神经元的输入，L 通常为 1，即函数的最大值):

![](images/B06162_08_02.png)

该图的值从-6 到+6 如下所示。红线表示 *x* 为零时数值为 0.5，但随着 x 的增大，函数迅速攀升至 1.0，x 减小时迅速下降至-1.0。

![](images/B06162_08_03.png)

每个神经元接收其输入，然后根据这些值计算输出。神经网络可以被认为是这些连接在一起的神经元的集合，它们对于数据挖掘应用来说非常强大。这些神经元的组合，它们如何组合在一起，以及它们如何组合来学习模型，是机器学习中最强大的概念之一。

# 神经网络导论

对于数据挖掘应用，神经元的排列通常在**层**中。第一层称为**输入层**，从数据样本中获取输入。每一个神经元的输出都被计算出来，然后传递给下一层的神经元。这就是所谓的**前馈神经网络**。在本章中，我们将这些简称为**神经网络**，因为它们是本章中使用的最常见的类型，也是唯一使用的类型。还有其他类型的神经网络，用于不同的应用。我们将在[第 11 章](10.html) *中看到另一种类型的网络，使用深度神经网络的图像中的目标检测*。

一层的输出成为下一层的输入，一直持续到我们到达最后一层:**输出层**。这些输出代表神经网络作为分类的预测。输入层和输出层之间的任何神经元层都被称为**隐藏层**，因为它们学习人类无法直观解释的数据表示。大多数神经网络至少有三层，尽管大多数现代应用使用的网络层比这多得多。

![](images/B06162_08_04.jpg)

通常，我们考虑完全连接的层。一个层中每个神经元的输出到达下一层中的所有神经元。虽然我们确实定义了一个完全连接的网络，但在训练过程中，许多权重将被设置为零，从而有效地消除了这些链接。此外，这些权重中的许多可能保留非常小的值，即使在训练之后。

除了是神经网络概念上更简单的形式之一之外，全连接神经网络的编程也比其他连接模式更简单、更有效。

See [Chapter 11](10.html), *Object Detection in images using Deep Neural Networks*,  for an investigation into different types of neural networks, including layers built specifically for image processing.

由于神经元的功能通常是逻辑函数，并且神经元完全连接到下一层，因此构建和训练神经网络的参数必须是其他因素。

*   神经网络的第一个因素是在构建阶段:神经网络的大小和形状。这包括神经网络有多少层，每个隐藏层中有多少神经元(输入和输出层的大小通常由数据集决定)。
*   神经网络的第二个参数是在训练阶段确定的:神经元之间连接的权重。当一个神经元连接到另一个神经元时，这个连接有一个相关的权重，该权重乘以信号(第一个神经元的输出)。如果连接权重为 0.8，则神经元被激活，并输出值 1，下一个神经元的最终输入为 0.8。如果第一个神经元没有被激活，并且值为 0，则该值保持为 0。

适当大小的网络和训练有素的权重的组合决定了神经网络在进行分类时的准确性。前一句中的*一词适当的*也不一定意味着更大，因为太大的神经网络可能需要很长时间的训练，更容易对训练数据进行过拟合。

Weights can be set randomly to start with but are then updated during the training phase. Setting weights to zero is normally not a good idea, as all neurons in the network act similarly to begin with! Having randomly set weights gives each neuron a different *role* in the learning process that can be improved with training.

这种配置的神经网络是一个分类器，然后可以用来根据输入预测数据样本的目标，很像我们在前面几章中使用的分类算法。但是首先，我们需要一个数据集来训练和测试。

Neural networks are, by a margin, the biggest area of advancement in data mining in recent years. This might make you think: *Why bother learning any other type of classification algorithm?* While neural networks are state of the art in pretty much every domain (at least, right now), the reason to learn other classifiers is that neural networks often require larger amounts of data to work well, and they take a long time to learn. If you don't have **big data**, you will probably get better results from another algorithm.

# 创建数据集

在这一章中，为了给事情增加一点趣味，让我们来扮演坏人的角色。我们想创建一个可以击败验证码的程序，允许我们的垃圾评论程序在某人的网站上做广告。需要注意的是，我们的验证码会比现在网络上使用的验证码简单一点，垃圾邮件不是一件很好的事情。

We play the bad guy today, but please *don't* use this against real world sites. One reason to "play the bad guy" is to help improve the security of our website, by looking for issues with it.

我们的实验将验证码简化为只有四个字母的单个英语单词，如下图所示:

![](images/B06162_08_05.png)

我们的目标是创建一个程序，可以从这样的图像中恢复单词。为此，我们将使用四个步骤:

1.  将图像分成单个字母。
2.  对每个字母进行分类。
3.  把字母重新组合成一个单词。
4.  用字典对单词进行排序，试图纠正错误。

Our CAPTCHA-busting algorithm will make the following assumptions. First, the word will be a whole and valid four-character English word (in fact, we use the same dictionary for creating and busting CAPTCHAs). Second, the word will only contain uppercase letters. No symbols, numbers, or spaces will be used.

我们将通过对文本执行剪切变换，以及不同的剪切和缩放速率，使问题比简单地识别字母稍微困难一些。

# 绘制基本验证码

在我们开始对验证码进行分类之前，我们首先需要一个数据集来学习。在本节中，我们将生成自己的数据来执行数据挖掘。

In more real-world applications, you'll be wanting to use an existing CAPTCHA service to generate the data, but for our purposes in this chapter, our own data will be sufficient. One of the issues that can arise is that we code in our assumptions around how the data works when we create the dataset ourselves, and then carry those same assumptions over to our data mining training.

我们在这里的目标是绘制一个上面有一个单词的图像，以及一个剪切变换。我们将使用 PIL 库来绘制我们的验证码，使用`scikit-image`库来执行剪切变换。`scikit-image`库可以读取 PIL 可以导出到的 NumPy 数组格式的图像，允许我们使用这两个库。

Both PIL and scikit-image can be installed via Anaconda. However, I recommend getting PIL through its replacement called **pillow**:
conda install pillow scikit-image

首先，我们导入必要的库和模块。我们导入 NumPy 和图像绘制功能如下:

```
import numpy as np 
from PIL import Image, ImageDraw, ImageFont 
from skimage import transform as tf

```

然后我们创建生成验证码的基础函数。这个函数接受一个单词和一个剪切值(通常在 0 到 0.5 之间)来返回一个 NumPy 数组格式的图像。我们允许用户设置结果图像的大小，因为我们也将此功能用于单字母训练样本:

```
def create_captcha(text, shear=0, size=(100, 30), scale=1):
    im = Image.new("L", size, "black")
    draw = ImageDraw.Draw(im)
    font = ImageFont.truetype(r"bretan/Coval-Black.otf", 22) 
    draw.text((0, 0), text, fill=1, font=font)
    image = np.array(im)
    affine_tf = tf.AffineTransform(shear=shear)
    image = tf.warp(image, affine_tf)
    image = image / image.max()
    # Apply scale
    shape = image.shape
    shapex, shapey = (int(shape[0] * scale), int(shape[1] * scale))
    image = tf.resize(image, (shapex, shapey))
    return image

```

在这个函数中，我们使用 L 为格式创建一个新的图像，这意味着只有黑白像素，并创建一个`ImageDraw`类的实例。这允许我们使用 PIL 在这张图片上进行绘制。然后我们加载字体，绘制文本，并对其执行`scikit-image`剪切变换。

You can get the Coval font I used from the Open Font Library at:
[http://openfontlibrary.org/en/font/bretan](http://openfontlibrary.org/en/font/bretan)
Download the `.zip` file and extract the `Coval-Black.otf` file into the same directory as your Notebook.

从这里，我们现在可以非常容易地生成图像，并使用`pyplot`来显示它们。首先，我们使用 matplotlib 图形的内联显示并导入`pyplot`。代码如下:

```
%matplotlib inline
from matplotlib import pyplot as plt
image = create_captcha("GENE", shear=0.5, scale=0.6)
plt.imshow(image, cmap='Greys')

```

结果是在这个部分的开始显示的图像:我们的验证码。以下是一些具有不同剪切和缩放值的其他示例:

```
image = create_captcha("SEND", shear=0.1, scale=1.0)
plt.imshow(image, cmap='Greys')

```

![](images/B06162_08_12-2-e1493021528419.png)

```
image = create_captcha("BARK", shear=0.8, scale=1.0)
plt.imshow(image, cmap='Greys')

```

![](images/B06162_08_13-e1493021566785.png)

这是缩放到`1.5`大小的变体。虽然它看起来类似于上面的骨骼图像，但请注意 *x* 轴和 *y* 轴的值更大:

```
image = create_captcha("WOOF", shear=0.25, scale=1.5)
plt.imshow(image, cmap='Greys')

```

![](images/B06162_08_14-e1493021653291.png)

# 将图像拆分成单个字母

我们的验证码是文字。我们将把这个问题分解成一个更小的问题:预测字母，而不是建立一个能够识别成千上万个可能单词的分类器。

Our experiment is in English, and all uppercase, meaning we have 26 classes to predict from for each letter. If you try these experiments in other languages, keep in mind the number of output classes will have to change.

我们战胜这些验证码的算法的第一步包括对单词进行分段，以发现其中的每个字母。为此，我们将创建一个函数，在图像中找到连续的黑色像素部分，并将其提取为子图像。这些是(或至少应该是)我们的信。`scikit-image`功能有执行这些操作的工具。

我们的函数将获取一个图像，并返回一个子图像列表，其中每个子图像都是图像中原始单词的一个字母。我们需要做的第一件事是检测每个字母在哪里。为此，我们将使用`scikit-image`中的标签函数，该函数查找具有相同值的像素的连接集。这类似于我们在[第 7 章](06.html) *【使用图挖掘遵循建议】*中的关联组件发现。

```
from skimage.measure import label, regionprops

def segment_image(image):
    # label will find subimages of connected non-black pixels
    labeled_image = label(image>0.2, connectivity=1, background=0)
    subimages = []
    # regionprops splits up the subimages
    for region in regionprops(labeled_image):
        # Extract the subimage
        start_x, start_y, end_x, end_y = region.bbox
        subimages.append(image[start_x:end_x,start_y:end_y])
        if len(subimages) == 0:
            # No subimages found, so return the entire image
            return [image,]
    return subimages

```

然后，我们可以使用这个函数从示例验证码中获取子图像:

```
subimages = segment_image(image)

```

我们还可以查看每个子图像:

```
f, axes = plt.subplots(1, len(subimages), figsize=(10, 3)) 
for i in range(len(subimages)): 
    axes[i].imshow(subimages[i], cmap="gray")

```

结果将如下所示:

![](images/B06162_08_11.jpg)

如您所见，我们的图像分割做得很合理，但结果仍然相当混乱，显示了以前的一些字母。这很好，而且几乎更可取。在有规则噪声的数据上训练会使我们的训练变得更差，而在有随机噪声的数据上训练实际上可以使它变得更好。一个原因是底层数据挖掘模型学习重要的方面，即非噪声部分，而不是训练数据集中固有的特定噪声。这是过多和过少噪音之间的细微差别，这可能很难正确建模。对验证集进行测试是确保您的培训得到改进的好方法。

一个重要的注意事项是，该代码在查找字母时不一致。较低的剪切值通常会产生精确分割的图像。例如，下面是从上面分割 WOOF 示例的代码:

```
image = create_captcha("WOOF", shear=0.25, scale=1.5)
subimages = segment_image(image)
f, axes = plt.subplots(1, len(subimages), figsize=(10, 3), sharey=True) 
for i in range(len(subimages)): 
    axes[i].imshow(subimages[i], cmap="gray")

```

![](images/B06162_08_15-e1493021829708.png)

相比之下，较高的剪切值没有正确分割。例如，下面是以前的 BARK 示例:

![](images/B06162_08_16.png)

请注意正方形分割导致的大重叠。对本章代码进行改进的一个建议是通过寻找非正方形的线段来改进我们的分割。

# 创建训练数据集

使用我们已经定义的函数，我们现在可以创建一个字母数据集，每个字母都有不同的剪切值。由此，我们将训练一个神经网络来识别图像中的每个字母。

我们首先设置我们的随机状态和一个数组，该数组保存字母、剪切值和缩放值的选项，我们将从这些选项中随机选择。这里没有太多的惊喜，但是如果你以前没有使用过 NumPy 的`arange`函数，它类似于 Python 的`range`函数——除了这一个与 NumPy 数组一起工作，并允许步骤是一个浮点。代码如下:

```
from sklearn.utils import check_random_state
random_state = check_random_state(14) 
letters = list("ABCDEFGHIJKLMNOPQRSTUVWXYZ") 
shear_values = np.arange(0, 0.5, 0.05)
scale_values = np.arange(0.5, 1.5, 0.1)

```

然后，我们创建一个函数(用于在训练数据集中生成单个样本)，该函数从可用选项中随机选择一个字母、一个剪切值和一个比例值。

```
def generate_sample(random_state=None): 
    random_state = check_random_state(random_state) 
    letter = random_state.choice(letters) 
    shear = random_state.choice(shear_values)
    scale = random_state.choice(scale_values)
    # We use 30,30 as the image size to ensure we get all the text in the image
    return create_captcha(letter, shear=shear, size=(30, 30), scale=scale), letters.index(letter)

```

我们返回字母的图像，以及代表图像中字母的目标值。我们的班级将是 0 代表 A，1 代表 B，2 代表 C，以此类推。

在功能块之外，我们现在可以调用这个代码来生成一个新的示例，然后使用`pyplot`显示它:

```
image, target = generate_sample(random_state) 
plt.imshow(image, cmap="Greys") 
print("The target for this image is: {0}".format(target))

```

生成的图像只有一个字母，带有随机剪切和随机比例值。

![](images/B06162_08_17-e1493023909718.png)

我们现在可以通过调用这个函数几千次来生成所有的数据。然后我们将数据放入 NumPy 数组，因为它们比列表更容易处理。代码如下:

```
dataset, targets = zip(*(generate_sample(random_state) for i in range(1000))) 
dataset = np.array([tf.resize(segment_image(sample)[0], (20, 20)) for sample in dataset])
dataset = np.array(dataset, dtype='float') 
targets = np.array(targets)

```

我们的目标是 0 到 26 之间的整数值，每个值代表字母表中的一个字母。神经网络通常不支持单个神经元的多个值，而是更喜欢有多个输出，每个输出值为 0 或 1。我们对目标执行一次热编码，得到一个每个样本有 26 个输出的目标数组，如果该字母很可能，则使用接近 1 的值，否则使用接近 0 的值。代码如下:

```
from sklearn.preprocessing import OneHotEncoder 
onehot = OneHotEncoder() 
y = onehot.fit_transform(targets.reshape(targets.shape[0],1))

```

从这个输出，我们知道我们神经网络的输出层将有 26 个神经元。神经网络的目标是根据给定的输入——构成图像的像素——来确定这些神经元中的哪一个要激发。

我们要用的库不支持稀疏数组，所以需要把我们的稀疏矩阵变成密集的 NumPy 数组。代码如下:

```
y = y.todense()
X = dataset.reshape((dataset.shape[0], dataset.shape[1] * dataset.shape[2]))

```

最后，我们执行一次训练/测试分割，以便以后评估我们的数据:

```
from sklearn.cross_validation import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9)

```

# 培训和分类

我们现在要建立一个神经网络，它将把一幅图像作为输入，并试图预测图像中有哪个(单个)字母。

我们将使用之前创建的单字母训练集。数据集本身非常简单。我们有一个 20×20 像素的图像，每个像素 1(黑色)或 0(白色)。这些代表了我们将用作神经网络输入的 400 个特征。输出将是 0 到 1 之间的 26 个值，其中较高的值表示相关字母(第一个神经元是 A，第二个神经元是 B，以此类推)是输入图像所代表的字母的可能性较高。

在本章中，我们将使用 scikit-learn 的`MLPClassifier`作为我们的神经网络。

You will need a recent version of `scikit-learn` to use MLPClassifier. If the below import statement fails, try again after updating scikit-learn. You can do this using the following Anaconda command:
 `conda update scikit-learn`

至于其他`scikit-learn`分类器，我们导入模型类型，新建一个。下面的构造函数指定我们创建一个包含 100 个节点的隐藏层。输入和输出层的大小在训练时确定:

```
from sklearn.neural_network import MLPClassifier
clf = MLPClassifier(hidden_layer_sizes=(100,), random_state=14)

```

要查看神经网络的内部参数，我们可以使用`get_params()`函数。该功能存在于所有`scikit-learn`车型上。这是上述模型的输出。这些参数中的许多可以提高训练或训练速度。例如，提高学习速率将更快地训练模型，但有可能会丢失最佳值:

```
{'activation': 'relu',
 'alpha': 0.0001,
 'batch_size': 'auto',
 'beta_1': 0.9,
 'beta_2': 0.999,
 'early_stopping': False,
 'epsilon': 1e-08,
 'hidden_layer_sizes': (100,),
 'learning_rate': 'constant',
 'learning_rate_init': 0.001,
 'max_iter': 200,
 'momentum': 0.9,
 'nesterovs_momentum': True,
 'power_t': 0.5,
 'random_state': 14,
 'shuffle': True,
 'solver': 'adam',
 'tol': 0.0001,
 'validation_fraction': 0.1,
 'verbose': False,
 'warm_start': False}

```

接下来，我们使用标准 scikit-learn 界面来调整我们的模型:

```
clf.fit(X_train, y_train)

```

我们的模型现在已经学习了每个层之间的权重。我们可以通过检查`clf.coefs_`来查看这些权重，T0 是连接每个层的 NumPy 数组的列表。例如，具有 400 个神经元的输入层(从我们的每个像素)到具有 100 个神经元的隐藏层(我们设置的参数)之间的权重，可以使用`clf.coefs_[0]`获得。此外，隐藏层和输出层(有 26 个神经元)之间的权重可以使用`clf.coefs_[1]`获得。这些权重和上面的参数一起完整地定义了我们的训练网络。

我们现在可以使用这个训练好的网络来预测我们的测试数据集:

```
y_pred = clf.predict(X_test)

```

最后，我们评估结果:

```
from sklearn.metrics import f1_score
f1_score(y_pred=y_pred, y_true=y_test, average='macro')

```

结果是 0.96，相当令人印象深刻。这个版本的 F1 成绩是基于宏观平均的，它计算每个班级的个人 F1 成绩，然后在不考虑每个班级规模的情况下对其进行平均。

为了检查这些单独的类结果，我们可以查看分类报告:

```
from sklearn.metrics import classification_report
print(classification_report(y_pred=y_pred, y_true=y_test))

```

我的实验结果如下所示:

```
             precision    recall  f1-score   support

          0       1.00      1.00      1.00         5
          1       1.00      1.00      1.00         3
          2       1.00      1.00      1.00         3
          3       1.00      1.00      1.00         8
          4       1.00      1.00      1.00         2
          5       1.00      1.00      1.00         4
          6       1.00      1.00      1.00         2
          7       1.00      1.00      1.00         2
          8       1.00      1.00      1.00         7
          9       1.00      1.00      1.00         1
         10       1.00      1.00      1.00         3
         11       1.00      1.00      1.00         4
         12       1.00      0.75      0.86         4
         13       1.00      1.00      1.00         5
         14       1.00      1.00      1.00         4
         15       1.00      1.00      1.00         3
         16       1.00      1.00      1.00         3
         17       1.00      1.00      1.00         7
         18       1.00      1.00      1.00         5
         19       1.00      1.00      1.00         5
         20       1.00      1.00      1.00         3
         21       1.00      1.00      1.00         5
         22       1.00      1.00      1.00         2
         23       1.00      1.00      1.00         4
         24       1.00      1.00      1.00         2
         25       1.00      1.00      1.00         4

avg / total       1.00      0.99      0.99       100

```

本报告的最终`f1-score`显示在右下角，倒数第二个数字- 0.99。这是微平均值，其中为每个样本计算`f1-score`，然后计算平均值。这种形式对于相对相似的班级规模更有意义，而宏观平均值对于不平衡的班级更有意义。

从应用编程接口的角度来看非常简单，因为`scikit-learn`隐藏了所有的复杂性。然而在后端到底发生了什么？我们如何训练神经网络？

# 反向传播

训练神经网络主要集中在以下几个方面。

*   首先是网络的大小和形状——有多少层，什么大小的层以及它们使用什么样的误差函数。虽然存在可以改变其大小和形状的神经网络类型，但最常见的类型，前馈神经网络，很少具有这种能力。相反，它的大小在初始化时是固定的，在本章中，第一层是 400 个神经元，隐藏层是 100 个，最终层是 26 个。形状的训练通常是元算法的工作，它训练一组神经网络，并确定除了训练网络本身之外，哪一个是最有效的。
*   训练神经网络的第二部分是改变神经元之间的权重。在标准神经网络中，一层的节点通过具有特定权重的边连接到下一层的节点。这些可以随机初始化(虽然确实存在一些更智能的方法，如自动编码器)，但需要进行调整，以允许网络*学习*训练样本和训练类之间的关系。

在一种叫做**反向传播**的算法被开发出来解决这个问题之前，这种权重的调整是阻碍非常早期的神经网络的关键问题之一。

**反向传播** ( **反向传播**)算法是一种将错误预测归咎于每个神经元的方法。首先，我们考虑神经网络的使用，在神经网络中，我们将样本输入到输入层，并查看输出层的哪个神经元发出信号，如*正向传播*。反向传播从输出层返回到输入层，将责任分配给网络中的每个权重，与权重对网络产生的任何错误的影响成比例。

变化量基于两个方面:

*   神经元激活
*   激活函数的梯度

首先是神经元被*激活的程度*。以高(绝对)值激发的神经元被认为对结果有很大的影响，而以小(绝对)值激发的神经元对结果的影响很小。因此，高值神经元周围的权重比小值神经元周围的权重变化更大。

权重变化量的第二个方面与激活函数的*梯度成比例。您使用的许多神经网络将对所有神经元具有相同的激活功能，但是有许多情况下，对不同层的神经元具有不同的激活功能是有意义的(或者更少的情况下，同一层中具有不同的激活功能)。激活函数的梯度，结合神经元的激活，以及分配给该神经元的误差，一起形成权重改变的量。*

I've skipped over the maths involved in back propagation, as the focus of this book is on practical usage. As you increase your usage of neural networks, it pays to know more about what goes on inside the algorithm. I recommend looking into the details of the back-prop algorithm, which can be understood with some basic knowledge of gradients and derivatives.

# 预测单词

现在我们有了一个预测单个字母的分类器，我们现在进入计划的下一步——预测单词。为了做到这一点，我们希望预测这些片段中的每个字母，并将这些预测放在一起，形成来自给定验证码的预测单词。

我们的函数将接受验证码和训练好的神经网络，并返回预测的单词:

```
def predict_captcha(captcha_image, neural_network):
    subimages = segment_image(captcha_image)
    # Perform the same transformations we did for our training data
    dataset = np.array([np.resize(subimage, (20, 20)) for subimage in subimages])
    X_test = dataset.reshape((dataset.shape[0], dataset.shape[1] * dataset.shape[2]))
    # Use predict_proba and argmax to get the most likely prediction
    y_pred = neural_network.predict_proba(X_test)
    predictions = np.argmax(y_pred, axis=1)

    # Convert predictions to letters
    predicted_word = str.join("", [letters[prediction] for prediction in predictions])
    return predicted_word

```

我们现在可以使用下面的代码来测试一个单词。尝试不同的单词，看看你会得到什么样的错误，但请记住，我们的神经网络只知道大写字母:

```
word = "GENE"
captcha = create_captcha(word, shear=0.2) 
print(predict_captcha(captcha, clf))
plt.imshow(captcha, cmap="Greys") 

```

我们可以将其编码成一个函数，让我们更容易地进行预测:

```
def test_prediction(word, net, shear=0.2, scale=1):
    captcha = create_captcha(word, shear=shear, scale=scale, size=(len(word) * 25, 30))
    prediction = predict_captcha(captcha, net) 
    return word == prediction, word, prediction

```

返回的结果指定预测是否正确、原始单词和预测单词。这段代码正确地预测了 GENE 这个词，但是在其他词上出错了。有多准确？为了测试，我们将创建一个数据集，其中包含一大堆来自 NLTK 的四个字母的英语单词。代码如下:

```
from nltk.corpus import words

```

Install NLTK using Anaconda: conda install nltk
After installation, and before using it in code, you will need to download the corpus using:
python -c "import nltk; nltk.download('words')"

这里的单词实例实际上是一个语料库对象，所以我们需要在上面调用`words()`来从这个语料库中提取单个单词。我们还进行过滤，以便从该列表中仅获得四个字母的单词:

```
valid_words = set([word.upper() for word in words.words() if len(word) == 4])

```

然后，我们可以通过简单地计算正确和不正确的预测来迭代所有的单词，看看我们得到了多少正确的单词:

```
num_correct = 0 
num_incorrect = 0 
for word in valid_words:
    shear = random_state.choice(shear_values)
    scale = random_state.choice(scale_values) 
    correct, word, prediction = test_prediction(word, clf, shear=shear, scale=scale) 
    if correct: 
        num_correct += 1 
    else: 
        num_incorrect += 1
print("Number correct is {0}".format(num_correct)) 
print("Number incorrect is {0}".format(num_incorrect))

```

我得到的结果是 3342 个正确，2170 个不正确，准确率略高于 62%。从我们最初的每封信 99%的准确率来看，这是一个很大的下降。发生了什么事？

下降的原因如下:

*   影响的第一个因素是我们的准确性。在所有其他条件相同的情况下，如果我们有四个字母，并且每个字母的准确率为 99%，那么我们可以预期连续获得四个字母的成功率约为 96%(0.99<sup>4</sup>&AP；0.96).单个字母预测中的一个错误会导致预测错误的单词。
*   第二个影响是剪切值。我们的数据集在剪切值 0 到 0.5 之间随机选择。之前的测试使用了 0.2 的剪切力。对于 0 值，我得到 75%的准确率；对于 0.5 的剪切，结果要差得多，只有 2.5%。剪切力越高，性能越低。
*   第三个影响是单词经常被错误地分割。另一个问题是，一些元音通常是错误的，导致比上述错误率预期的更多的错误。

让我们研究第二个问题，并描绘剪切和性能之间的关系。首先，我们将评估代码转换为依赖于给定剪切值的函数:

```
def evaluation_versus_shear(shear_value):
    num_correct = 0 
    num_incorrect = 0 
    for word in valid_words: 
        scale = random_state.choice(scale_values)
        correct, word, prediction = test_prediction(word, clf, shear=shear_value, scale=scale)
        if correct: 
            num_correct += 1 
        else: 
            num_incorrect += 1
    return num_correct/(num_correct+num_incorrect)

```

然后，我们获取一个剪切值列表，然后使用这个函数来评估每个值的准确性。请注意，运行这段代码需要一段时间，大约 30 分钟，具体取决于您的硬件。

```
scores = [evaluation_versus_shear(shear) for shear in shear_values]

```

最后，使用 matplotlib 绘制结果:

```
plt.plot(shear_values, scores)

```

![](images/B06162_08_18-1.png)

您可以看到，当剪切值超过 0.4 时，性能会严重下降。规范化输入会有所帮助，例如图像旋转和取消输入。

Another surprising option to address issues with shear is to increase the amount of training data with high shear values, which can lead to the model learning a more generalized output.

在下一节中，我们将研究如何使用后处理来提高精确度。

# 使用字典提高准确性

我们可以检查这个词是否真的存在于我们的字典中，而不仅仅是返回给定的预测。如果是的话，那就是我们的预测。如果它不在字典里，我们可以试着找到一个和它相似的单词，并预测它。请注意，该策略依赖于我们的假设，即所有验证码单词都是有效的英语单词，因此该策略不适用于随机的字符序列。这是一些验证码不使用单词的原因之一。

这里有一个问题——我们如何确定最接近的单词？有很多方法可以做到这一点。例如，我们可以比较单词的长度。长度相似的两个词可以认为更相似。然而，如果单词在相同的位置有相同的字母，我们通常认为它们是相似的。这就是**编辑距离**的来源。

# 单词相似度的排序机制

**Levenshtein 编辑距离**是一种常用的方法，用于比较两个短字符串，看看它们有多相似。它的可伸缩性不是很高，因此不常用于很长的字符串。编辑距离计算从一个单词到另一个单词所需的步数。这些步骤可以是以下三种操作之一:

*   在单词的任何位置插入一个新字母
*   删除单词中的任何字母
*   用一个字母代替另一个字母

将第一个单词转换成第二个单词所需的最小动作数被给出为距离。较高的值表示单词不太相似。

该距离在 NLTK 中可作为`nltk.metrics.edit_distance`获得。我们可以只使用两个字符串来调用它，它返回编辑距离:

```
from nltk.metrics import edit_distance 
steps = edit_distance("STEP", "STOP") 
print("The number of steps needed is: {0}".format(steps))

```

当与不同的单词一起使用时，编辑距离非常接近许多人直观感觉到的相似单词。编辑距离非常适合测试拼写错误、听写错误和姓名匹配(在这里，您可以很容易地将您的马克和马克拼写混淆)。

然而，这对我们的情况不是很好。我们并不真的期望字母被移动，只是单个字母的比较是错误的。为此，我们将创建一个不同的距离度量，它只是相同位置中不正确的字母数量。代码如下:

```
def compute_distance(prediction, word):
    len_word = min(len(prediction), len(word))
    return len_word - sum([prediction[i] == word[i] for i in range(len_word)])

```

我们从预测单词的长度中减去该值(四)，使其成为距离度量，其中较低的值表示单词之间更相似。

# 把它们放在一起

我们现在可以使用与之前类似的代码来测试我们改进的预测函数。首先，我们定义一个预测函数，它也采用我们的有效单词列表:

```
from operator import itemgetter 

def improved_prediction(word, net, dictionary, shear=0.2, scale=1.0): 
    captcha = create_captcha(word, shear=shear, scale=scale) 
    prediction = predict_captcha(captcha, net) 

    if prediction not in dictionary:
        distances = sorted([(word, compute_distance(prediction, word)) for word in dictionary],
                           key=itemgetter(1))
        best_word = distances[0] 
        prediction = best_word[0]
    return word == prediction, word, prediction

```

我们计算我们预测的单词和字典中每个其他单词之间的距离，并按距离排序(最低优先)。我们测试代码中的更改如下:

```
num_correct = 0 
num_incorrect = 0 
for word in valid_words: 
    shear = random_state.choice(shear_values)
    scale = random_state.choice(scale_values)
    correct, word, prediction = improved_prediction(word, clf, valid_words, shear=shear, scale=scale)
    if correct: 
        num_correct += 1 
    else: 
        num_incorrect += 1
print("Number correct is {0}".format(num_correct)) 
print("Number incorrect is {0}".format(num_incorrect))

```

前面的代码需要一段时间才能运行(计算所有距离需要一些时间)，但最终结果是 3，037 个样本正确，2，476 个样本不正确。这是 71.5%的准确率，提升了近 10 个百分点！

Looking for a challenge? Update the `predict_captcha` function to return the probabilities assigned to each letter. By default, the letter with the highest probability is chosen for each letter in a word. If that doesn't work, choose the next most probable word, by multiplying the per-letter probabilities together.

# 摘要

在本章中，我们使用图像来使用简单的像素值来预测验证码中描绘的字母。我们的验证码有点简化；我们只用了完整的四个字母的英语单词。实际上，这个问题要困难得多——这是应该的！通过一些改进，用神经网络和类似于我们讨论的方法来解决更难的验证码是可能的。`scikit-image`库包含许多有用的功能，用于从图像中提取形状，用于提高对比度的功能，以及其他有帮助的图像工具。

我们把我们更大的预测单词的问题，创造了一个更小更简单的预测字母的问题。从这里，我们能够创建一个前馈神经网络来准确预测图像中的哪个字母。在这个阶段，我们的结果非常好，准确率为 97%。

神经网络是简单连接的神经元集合，是由单个函数组成的基本计算设备。然而，当你把这些联系在一起时，它们可以解决难以置信的复杂问题。神经网络是深度学习的基础，是目前数据挖掘最有效的领域之一。

尽管我们的每个字母的准确率很高，但当我们试图预测一个完整的单词时，预测一个单词的性能下降到略高于 60%。我们使用字典来搜索最匹配的单词，从而提高了准确率。为此，我们考虑了常用的编辑距离；然而，我们简化了它，因为我们只关心字母上的个别错误，而不是插入或删除。这一改进带来了一些好处，但仍有许多改进可以尝试进一步提高准确性。

为了进一步理解本章中的概念，研究通过添加更多隐藏层或改变这些层的形状来改变神经网络结构。调查这对结果的影响。此外，尝试创建一个更难的验证码-这会降低准确性吗？你能建立一个更复杂的网络来学习它吗？

像验证码例子这样的数据挖掘问题表明，一个初始的问题陈述，比如*猜测这个单词*，可以被分解成单独的子任务，这些子任务可以使用数据挖掘来执行。此外，这些子任务可以以几种不同的方式组合，例如使用外部信息。在这一章中，我们将我们的字母预测与有效单词词典相结合，以提供最终的响应，比单独的字母预测给出更好的准确性。

在下一章中，我们将继续字符串比较。我们将尝试确定哪个作者(在一组作者中)写了一个特定的文档——只使用内容，不使用其他信息！
# 用决策树预测体育赢家

在这一章中，我们将着眼于使用与我们目前所见不同类型的分类算法来预测体育比赛的获胜者:**决策树**。这些算法比其他算法有许多优点。其中一个主要优点是它们是人类可读的，允许它们用于人类驱动的决策。通过这种方式，决策树可以用来学习一个程序，如果需要的话，可以交给人类去执行。另一个优点是它们与各种特性一起工作，包括我们将在本章中看到的分类特性。

我们将在本章中讨论以下主题:

*   使用熊猫库加载和操作数据
*   分类决策树
*   改进决策树的随机森林
*   在数据挖掘中使用真实数据集
*   创建新特性并在健壮的框架中测试它们

# 正在加载数据集

在本章中，我们将着眼于预测**国家篮球协会** ( **NBA** )的比赛获胜者。NBA 的比赛往往势均力敌，可以在最后一刻决定胜负，这使得预测胜者变得相当困难。许多体育项目都有这样的特点，即(一般来说)更好的球队可能在合适的日子被另一个球队击败。

对预测获胜者的各种研究表明，运动结果预测的准确性可能有一个上限，根据运动的不同，该上限在 70%到 80%之间。有大量的研究正在进行体育预测，通常是通过数据挖掘或基于统计的方法。

在本章中，我们将了解一种入门级篮球比赛预测算法，使用决策树来确定一个球队是否会赢得给定的比赛。不幸的是，它并不像体育博彩机构使用的模型那样赚钱，后者通常更先进、更复杂，最终也更准确。

# 收集数据

我们将使用的数据是 2015-2016 赛季 NBA 的比赛历史数据。网站[http://basketball-reference.com](http://basketball-reference.com/)包含大量从 NBA 和其他联盟收集的资源和统计数据。要下载数据集，请执行以下步骤:

1.  在你的网页浏览器中导航到[http://www . basketball-reference . com/league/NBA _ 2016 _ games . html](http://www.basketball-reference.com/leagues/NBA_2016_games.html)。
2.  单击共享和更多。
3.  单击以 CSV 格式获取表格(对于 Excel)。
4.  将包括标题在内的数据复制到名为`basketball.csv`的文本文件中。
5.  在其他月份重复这个过程，除了不要复制标题。

这将会给你一个 CSV 文件，包含 NBA 本赛季每场比赛的结果。您的文件应该包含 1316 个游戏，文件中总共有 1317 行，包括标题行。

CSV 文件是文本文件，其中每行包含一个新行，每个值由逗号分隔(因此得名)。CSV 文件可以通过在文本编辑器中键入并以`.csv`扩展名保存来手动创建。它们可以在任何可以读取文本文件的程序中打开，但也可以作为电子表格在 Excel 中打开。Excel(和其他电子表格程序)通常也可以将电子表格转换为 CSV。

我们将使用`pandas`库加载文件，这是一个非常有用的数据处理库。Python 还包含一个名为`csv`的内置库，支持读写 CSV 文件。然而，我们将使用熊猫，它提供了更强大的功能，我们将在本章后面使用它来创建新的功能。

For this chapter, you will need to install pandas. The easiest way to install it is to use Anaconda's `conda` installer, as you did in [Chapter 1](02.html), *Getting Started with data mining to install scikit-learn*:
`$ conda install pandas` If you have difficulty in installing pandas, head to the project's website at [http://pandas.pydata.org/getpandas.html](http://pandas.pydata.org/getpandas.html) and read the installation instructions for your system.

# 使用熊猫加载数据集

`pandas`库是用于加载、管理和操作数据的库。它在幕后处理数据结构，并支持数据分析功能，如计算平均值和按值分组数据。

在做多个数据挖掘实验的时候，你会发现你一遍又一遍的写很多相同的函数，比如读文件，提取特征。每次这种重新实现发生时，您都有引入 bug 的风险。使用像`pandas`这样的高质量库可以显著减少完成这些功能所需的工作量，也让你更有信心使用经过良好测试的代码来构建自己的程序。

在这本书里，我们将会大量使用熊猫，介绍我们正在使用的用例和需要的新功能。

我们可以使用`read_csv`函数加载数据集:

```
import pandas as pd
data_filename = "basketball.csv"
dataset = pd.read_csv(data_filename)

```

这样做的结果是一个熊猫**数据框**，它有一些有用的功能，我们以后会用到。查看结果数据集，我们可以看到一些问题。键入以下内容并运行代码以查看数据集的前五行:

```
dataset.head(5)

```

输出如下:

![](images/B06162OS_03_01.png)

仅仅读取没有参数的数据就产生了一个相当有用的数据集，但是它有一些问题，我们将在下一节中讨论。

# 清理数据集

查看输出后，我们可以看到许多问题:

*   日期只是一个字符串，而不是日期对象
*   从目测结果来看，标题不完整或不正确

这些问题来自数据，我们可以通过改变数据本身来解决这个问题。然而，在这样做的时候，我们可能会忘记我们采取的步骤，或者误用它们；也就是说，我们不能复制我们的结果。就像前面的部分一样，我们使用管道来跟踪我们对数据集进行的转换，我们将使用 pandas 来对原始数据本身应用转换。

`pandas.read_csv`函数有参数来修复这些问题，我们可以在加载文件时指定这些参数。我们还可以在加载文件后更改标题，如以下代码所示:

```
dataset = pd.read_csv(data_filename, parse_dates=["Date"]) dataset.columns
        = ["Date", "Start (ET)", "Visitor Team", "VisitorPts", 
           "Home Team", "HomePts", "OT?", "Score Type", "Notes"]

```

结果有了显著改善，我们可以看到，如果我们打印出结果数据帧:

```
dataset.head()

```

输出如下:

![](images/B06162OS_03_02.png)

即使在像这样编译良好的数据源中，您也需要进行一些调整。不同的系统有不同的细微差别，导致数据文件彼此不太兼容。第一次加载数据集时，一定要检查加载的数据(即使是已知格式)，还要检查数据的数据类型。在熊猫中，这可以通过以下代码来完成:

```
print(dataset.dtypes)

```

现在我们有了一致格式的数据集，我们可以计算一个**基线**，这是一个在给定问题上获得良好精度的简单方法。任何像样的数据挖掘解决方案都应该超过这个基线数字。

For a product recommendation system, a good baseline is to simply *recommend the most popular product*.
For a classification task, it can be to *always predict the most frequent task*, or alternatively applying a very simple classification algorithm like **OneR**.

对于我们的数据集，每场比赛有两个队:主队和客队。这项任务的一个明显的基线是 50%，如果我们只是随机猜测一个获胜者，这是我们预期的准确性。换句话说，随机选择预测的获胜团队将(随着时间的推移)导致大约 50%的准确率。但是，只要掌握一点领域知识，我们就可以为这项任务使用更好的基线，我们将在下一节中看到。

# 提取新特征

我们现在将通过组合和比较现有数据，从该数据集中提取一些特征。首先，我们需要指定我们的类值，这将给我们的分类算法一些东西来比较，看看它的预测是否正确。这可以通过多种方式进行编码；但是，对于这个应用程序，如果主队赢了，我们将把我们的类指定为 1，如果客队赢了，我们将指定为 0。在篮球比赛中，得分最多的队获胜。因此，虽然数据集没有指定谁直接获胜，但我们可以轻松计算。

我们可以通过以下方式指定数据集:

```
dataset["HomeWin"] = dataset["VisitorPts"] < dataset["HomePts"]

```

然后，我们将这些值复制到一个 NumPy 数组中，以便以后用于我们的 scikit-learn 分类器。熊猫和 scikit-learn 之间目前还没有一个干净的集成，但是通过使用 NumPy 阵列，它们可以很好地协同工作。虽然我们将使用熊猫提取特征，但我们需要提取值，以便与 scikit-learn 一起使用:

```
y_true = dataset["HomeWin"].values

```

前面的数组现在以 scikit-learn 可以读取的格式保存我们的类值。

对了，体育预测比较好的基线图是预测每场比赛的主队。主队在世界上几乎所有的运动中都有优势。这个优势有多大？我们来看看:

```
dataset["HomeWin"].mean()

```

结果值约为 0.59，表明主队平均赢得 59%的比赛。这高于随机概率的 50%，是一个适用于大多数运动的简单规则。

我们也可以开始为输入值创建一些用于数据挖掘的特征(T0 数组)。虽然有时我们可以将原始数据放入我们的分类器，但我们经常需要从数据中导出连续的数字或分类特征。

对于我们当前的数据集，我们不能真正使用已经存在的特征(以它们当前的形式)来做预测。在我们需要预测游戏结果之前，我们不会知道游戏的分数，所以我们不能将它们用作特征。虽然这听起来很明显，但很容易被忽略。

我们想要创建的帮助我们预测哪支球队将获胜的前两个特性是这两支球队中的任何一支是否赢得了他们之前的比赛。这将大致估计哪支球队目前表现良好。

我们将通过按顺序遍历行并记录哪个队赢来计算这个特征。当我们到达新的一排时，我们会查看上次看到他们时，球队是否赢了。

我们首先创建一个(默认的)字典来存储团队的最后结果:

```
from collections import defaultdict 
won_last = defaultdict(int)

```

然后，我们在数据集上创建一个新要素来存储新要素的结果:

```
dataset["HomeLastWin"] = 0
dataset["VisitorLastWin"] = 0

```

这本字典的关键将是球队，价值将是他们是否赢得了上一场比赛。然后，我们可以遍历所有行，并用团队的最后结果更新当前行:

```
for index, row in dataset.iterrows():
    home_team = row["Home Team"]
    visitor_team = row["Visitor Team"]
    row["HomeLastWin"] = won_last[home_team]
    dataset.set_value(index, "HomeLastWin", won_last[home_team])
    dataset.set_value(index, "VisitorLastWin", won_last[visitor_team])
    won_last[home_team] = int(row["HomeWin"])
    won_last[visitor_team] = 1 - int(row["HomeWin"])

```

请注意，前面的代码依赖于我们的数据集按时间顺序排列。我们的数据集是有序的；但是，如果使用的数据集不符合顺序，则需要将`dataset.iterrows()`替换为`dataset.sort("Date").iterrows()`。

循环中的最后两行用 1 或 0 更新我们的字典，这取决于哪一队赢得了当前的*游戏。这些信息将用于每支球队的下一场比赛。*

在前面的代码运行之后，我们将有两个新特性:`HomeLastWin`和`VisitorLastWin`。使用`dataset.head(6)`查看数据集，查看赢得最近比赛的主队和客队的示例。使用 panda 的索引器查看数据集的其他部分:

```
dataset.ix[1000:1005]

```

目前，这给所有队伍(包括前一年的冠军！)当他们第一次被看见的时候。我们可以使用前一年的数据来改进这个特性，但是在本章中我们不会这样做。

# 决策树

Decision trees are a class of supervised learning algorithms like a flow chart that consists of a sequence of nodes, where the values for a sample are used to make a decision on the next node to go to.  

下面的例子很好地说明了决策树是一类有监督的学习算法:

![](images/B06162OS_03_03.jpg)

与大多数分类算法一样，使用它们有两个阶段:

*   第一个阶段是**训练**阶段，使用训练数据构建一棵树。虽然上一章中的最近邻算法没有训练阶段，但决策树需要它。这样，最近邻算法就是一个懒惰的学习者，只在需要做预测的时候做任何工作。相比之下，决策树像大多数分类方法一样，是热切的学习者，在训练阶段承担工作，因此在预测阶段需要做的较少。
*   第二阶段是**预测**阶段，使用训练好的树来预测新样本的分类。使用前面的示例树，数据点`["is raining", "very windy"]`将被归类为*恶劣天气*。

There are many algorithms for creating decision trees. Many of these algorithms are iterative. They start at the base node and decide the best feature to use for the first decision, then go to each node and choose the next best feature, and so on. This process is stopped at a certain point when it is decided that nothing more can be gained from extending the tree further.

`scikit-learn`包实现了**分类和回归树** ( **CART** )算法作为其默认的决策树类，它可以使用分类和连续特征。

# 决策树中的参数

决策树最重要的参数之一是**停止标准**。当树的构建接近完成时，最后的几个决定通常会有些武断，并且只依赖少量样本来做出决定。使用这种特定的节点会导致树明显过度填充训练数据。相反，可以使用停止标准来确保决策树没有达到这种准确性。

可以完全创建树，然后修剪，而不是使用停止标准。这个修整过程移除了没有为整个过程提供太多信息的节点。这被称为**修剪**，并导致模型在新数据集上通常表现更好，因为它没有过度拟合训练数据。

scikit-learn 中的决策树实现提供了一种使用以下选项停止构建树的方法:

*   `**min_samples_split**`:指定在决策树中创建一个新节点需要多少个样本
*   `**min_samples_leaf**`:指定一个节点必须产生多少样本才能保持

第一个决定是否创建决策节点，而第二个决定是否保留决策节点。

决策树的另一个参数是创建决策的标准。**基尼杂质**和**信息增益**是该参数的两个常用选项:

*   **基尼不纯**:这是一个衡量决策节点错误预测样本类别的频率
*   **信息增益**:这使用基于信息论的熵来指示决策节点获得了多少额外信息

这些参数值做了大致相同的事情-决定使用哪个规则和值来将节点拆分为子节点。值本身就是用来确定分割的度量，但是这会对最终模型产生重大影响。

# 使用决策树

我们可以导入`DecisionTreeClassifier`类，并使用 scikit-learn 创建决策树:

```
from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(random_state=14)

```

We used 14 for our `random_state` again and will do so for most of the book. Using the same random seed allows for replication of experiments. However, with your experiments, you should mix up the random state to ensure that the algorithm's performance is not tied to the specific value.

我们现在需要从熊猫数据帧中提取数据集，以便与我们的`scikit-learn`分类器一起使用。我们通过指定我们希望使用的列并使用数据框视图的 values 参数来实现这一点。下面的代码为主队和客队使用我们的上次获胜值创建了一个数据集:

```
X_previouswins = dataset[["HomeLastWin", "VisitorLastWin"]].values

```

决策树是估计器，如[第 2 章](02.html)、*中介绍的使用* *scikit 分类-学习* *估计器*，因此有`fit`和`predict`方法。我们也可以使用`cross_val_score`方法获得平均分数(如我们之前所做的那样):

```
from sklearn.cross_validation import cross_val_score
import numpy as np
scores = cross_val_score(clf, X_previouswins, y_true,
scoring='accuracy')
print("Accuracy: {0:.1f}%".format(np.mean(scores) * 100))

```

这个得分 59.4%:我们比随机选择好！然而，我们并没有超越我们选择主队的另一条底线。事实上，我们几乎完全一样。我们应该能做得更好。**特征工程**是数据挖掘中最难的任务之一，选择*好的* **特征**是获得好结果的关键——比选择正确的算法更重要！

# 运动结果预测

我们也许可以通过尝试其他功能做得更好。我们有一种方法来测试我们的模型有多精确。`cross_val_score`方法允许我们尝试新功能。

我们可以使用许多可能的功能，但是我们将尝试以下问题:

*   一般认为哪个队更好？
*   哪支球队赢得了最后一场比赛？

我们还将尝试将原始团队放入算法中，以检查算法是否可以学习一个检查不同团队如何相互对抗的模型。

# 把它们放在一起

对于第一个特性，我们将创建一个特性，告诉我们主队是否普遍比客队好。为此，我们将加载上赛季 NBA 的积分榜(在某些运动中也称为阶梯)。如果一个团队在 2015 年的排名高于另一个团队，那么这个团队将被认为更好。

要获取排名数据，请执行以下步骤:

1.  在你的网页浏览器中导航到[http://www . basketball-reference . com/league/NBA _ 2015 _ standing . html](http://www.basketball-reference.com/leagues/NBA_2015_standings.html)。
2.  选择扩大排名以获得整个联盟的单一名单。
3.  单击导出链接。
4.  复制文本并将其保存在数据文件夹中名为`standings.csv`的文本/CSV 文件中。

回到你的笔记本中，在一个新的单元格中输入下面的行。您需要确保文件保存在 data_folder 变量所指向的位置。代码如下:

```
import os
standings_filename = os.path.join(data_folder, "standings.csv")
standings = pd.read_csv(standings_filename, skiprows=1)

```

您可以通过在新单元格中键入排名并运行
代码来查看阶梯:

```
standings.head()

```

输出如下:

![](images/B06162OS_03_04.png)

接下来，我们使用与前一个特征相似的模式创建一个新特征。我们遍历行，查找主队和客队的排名。代码如下:

```
dataset["HomeTeamRanksHigher"] = 0
for index, row in dataset.iterrows():
    home_team = row["Home Team"]
    visitor_team = row["Visitor Team"]
    home_rank = standings[standings["Team"] == home_team]["Rk"].values[0]
    visitor_rank = standings[standings["Team"] == visitor_team]["Rk"].values[0]
    row["HomeTeamRanksHigher"] = int(home_rank > visitor_rank)
    dataset.set_value(index, "HomeTeamRanksHigher", int(home_rank < visitor_rank))

```

接下来，我们使用`cross_val_score`函数来测试结果。首先，我们提取数据集:

```
X_homehigher = dataset[["HomeLastWin", "VisitorLastWin", "HomeTeamRanksHigher"]].values

```

然后，我们创建一个新的`DecisionTreeClassifier`并运行评估:

```
clf = DecisionTreeClassifier(random_state=14)
scores = cross_val_score(clf, X_homehigher, y_true, scoring='accuracy')
print("Accuracy: {0:.1f}%".format(np.mean(scores) * 100))

```

现在这个分数比我们之前的成绩还要高 60.9%，现在比每次只选择主队还要好。我们能做得更好吗？

接下来，让我们测试一下这两个队中哪一个赢了最后一场比赛。虽然排名可以给出一些谁赢了的提示(排名较高的球队更有可能赢)，但有时球队在与其他球队的比赛中表现得更好。这有很多原因——例如，一些球队可能有很好地对抗特定球队的策略或球员。按照我们之前的模式，我们创建了一个字典来存储过去游戏的获胜者，并在我们的数据框中创建了一个新功能。代码如下:

```
last_match_winner = defaultdict(int)
dataset["HomeTeamWonLast"] = 0

for index, row in dataset.iterrows():
    home_team = row["Home Team"]
    visitor_team = row["Visitor Team"]
    teams = tuple(sorted([home_team, visitor_team])) # Sort for a consistent ordering
    # Set in the row, who won the last encounter
    home_team_won_last = 1 if last_match_winner[teams] == row["Home Team"] else 0
    dataset.set_value(index, "HomeTeamWonLast", home_team_won_last)
    # Who won this one?
    winner = row["Home Team"] if row["HomeWin"] else row["Visitor Team"]
    last_match_winner[teams] = winner

```

这个特性的工作原理与我们之前的基于等级的特性非常相似。然而，这个特性不是查找等级，而是创建一个名为`teams`的元组，然后将先前的结果存储在字典中。当这两个队接下来互相比赛时，它重新创建这个元组，并查找之前的结果。我们的代码没有区分家庭游戏和访客游戏，这对于实现来说可能是一个有用的改进。

接下来，我们需要评估。该过程与之前非常相似，只是我们将新特征添加到提取的值中:

```
X_lastwinner = dataset[[ "HomeTeamWonLast", "HomeTeamRanksHigher", "HomeLastWin", "VisitorLastWin",]].values
clf = DecisionTreeClassifier(random_state=14, criterion="entropy")

scores = cross_val_score(clf, X_lastwinner, y_true, scoring='accuracy')

print("Accuracy: {0:.1f}%".format(np.mean(scores) * 100))

```

这个分数是 62.2%。我们的成绩越来越好。

最后，我们将检查如果我们向决策树抛出大量数据会发生什么，并看看它是否能学习一个有效的模型。我们将把团队输入到树中，并检查决策树是否可以学习合并这些信息。

虽然决策树能够从分类特征中学习，但是`scikit-learn`中的实现要求将这些特征编码为数字和特征，而不是字符串值。我们可以使用`LabelEncoder` **转换器**将基于字符串的团队名称转换为指定的整数值。代码如下:

```
from sklearn.preprocessing import LabelEncoder
encoding = LabelEncoder()
encoding.fit(dataset["Home Team"].values)
home_teams = encoding.transform(dataset["Home Team"].values)
visitor_teams = encoding.transform(dataset["Visitor Team"].values)
X_teams = np.vstack([home_teams, visitor_teams]).T

```

我们应该使用相同的转换器来编码主队和客队。这是为了让同一个团队获得与主队和客队相同的整数值。虽然这对该应用程序的性能并不重要，但它很重要，否则可能会降低未来模型的性能。

这些整数可以输入到决策树中，但它们仍然会被`DecisionTreeClassifier`解释为连续特征。例如，可以为团队分配从 0 到 16 的整数。算法将看到团队 1 和团队 2 是相似的，而团队 4 和团队 10 将是非常不同的——但这完全没有意义。所有的队伍都不一样——两个队伍要么一样，要么不一样！

为了解决这种不一致，我们使用`OneHotEncoder` **转换器**将这些整数编码成许多二进制特征。每个二进制特征将是该特征的单个值。例如，如果 NBA 球队芝加哥公牛队被`LabelEncoder`分配为整数 7，那么`OneHotEncoder`返回的第七个特征将是 1(如果球队是芝加哥公牛队)，而所有其他特征/球队为 0。对每个可能的值都这样做，从而产生一个更大的数据集。代码如下:

```
from sklearn.preprocessing import OneHotEncoder
onehot = OneHotEncoder()
X_teams = onehot.fit_transform(X_teams).todense()

```

接下来，我们像以前一样在新数据集上运行决策树:

```
clf = DecisionTreeClassifier(random_state=14)
scores = cross_val_score(clf, X_teams, y_true, scoring='accuracy')
print("Accuracy: {0:.1f}%".format(np.mean(scores) * 100))

```

这个分数的准确率为 62.8%。比分更好，尽管给出的信息只是参赛的球队。决策树可能没有正确处理大量特征。出于这个原因，我们将尝试改变算法，看看这是否有所帮助。数据挖掘可以是一个尝试新算法和新特性的迭代过程。

# 随机森林

A single Decision Tree can learn quite complex functions. However, decision trees are prone to overfitting--learning rules that work only for the specific training set and don't generalize well to new data.

我们可以调整的方法之一是限制它学习的规则数量。例如，我们可以将树的深度限制在三层。这样的树将学习在全局级别拆分数据集的最佳规则，但不会学习将数据集分成高精度组的高度特定的规则。这种权衡导致树可能具有良好的泛化能力，但在训练数据集上的总体性能稍差。

为了弥补这一点，我们可以创建许多这样的*有限*决策树，然后要求每个决策树预测类的值。我们可以采取多数票，并使用这个答案作为我们的总体预测。随机森林就是从这一观点发展而来的算法。

上述程序有两个问题。第一个问题是，构建决策树在很大程度上是确定性的——每次使用相同的输入将导致相同的输出。我们只有一个训练数据集，这意味着如果我们尝试构建多个树，我们的输入(因此输出)将是相同的。我们可以通过选择数据集的随机子样本来解决这个问题，从而有效地创建新的训练集。这个过程叫做**装袋**，在数据挖掘的很多情况下都可以非常有效。

从相似的数据创建许多决策树时，我们可能遇到的第二个问题是，用于树中前几个决策节点的特征往往是相似的。即使我们选择训练数据的随机子样本，构建的决策树仍然很有可能基本相同。为了弥补这一点，我们还选择了随机的特征子集来执行数据分割。

然后，我们使用随机选择的样本，使用(几乎)随机选择的特征，随机构建了树。这是一个随机的森林，也许是非直觉的，这个算法对许多数据集非常有效，几乎不需要调整模型的许多参数。

# 系综是如何工作的？

随机森林中固有的随机性可能会让我们看起来像是让算法的结果听天由命。然而，我们将平均的好处应用于几乎随机构建的决策树，从而产生一种减少结果方差的算法。

**Variance** is the error introduced by variations in the training dataset on the algorithm. Algorithms with a high variance (such as decision trees) can be greatly affected by variations to the training dataset. This results in models that have the problem of overfitting. In contrast, **bias** is the error introduced by assumptions in the algorithm rather than anything to do with the dataset, that is, if we had an algorithm that presumed that all features would be normally distributed, then our algorithm may have a high error if the features were not.

通过分析数据，查看分类器的数据模型是否与实际数据相匹配，可以减少偏差带来的负面影响。

举一个极端的例子，不管输入是什么，一个总是预测真的分类器有很高的偏差。一个总是随机预测的分类器会有很高的方差。每个分类器都有很高的误差，但性质不同。

通过对大量决策树求平均，这种方差被大大降低。这至少通常会导致模型具有更高的总体精度和更好的预测能力。代价是时间的增加和算法偏差的增加。

总的来说，集成基于这样的假设，即预测中的误差实际上是随机的，并且这些误差在不同的分类器之间有很大的不同。通过对许多模型的结果进行平均，这些随机误差被抵消了——留下了真正的预测。在本书的其余部分，我们将看到更多的合奏在起作用。

# 在随机森林中设置参数

scikit-learn 中的 Random Forest 实现称为`RandomForestClassifier`，它有多个参数。由于随机森林使用许多`DecisionTreeClassifier`实例，它们共享许多相同的参数，如`criterion`(基尼不纯或熵/信息增益)`max_features`和`min_samples_split`。

集成过程中使用了一些新参数:

*   `n_estimators`:这决定了应该构建多少决策树。值越高，运行时间越长，但(可能)精度越高。
*   `oob_score`:如果为真，则使用不在为训练决策树而选择的随机子样本中的样本来测试该方法。
*   `n_jobs`:指定并行训练决策树时使用的核心数。

`scikit-learn`包使用名为 **Joblib** 的库进行内置并行化。此参数规定了要使用的内核数量。默认情况下，只使用一个内核-如果您有更多的内核，您可以增加它，或者将其设置为-1 以使用所有内核。

# 应用随机森林

scikit-learn 中的随机森林使用**估计器**界面，允许我们使用与之前几乎完全相同的代码进行交叉验证:

```
from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(random_state=14)
scores = cross_val_score(clf, X_teams, y_true, scoring='accuracy')
print("Accuracy: {0:.1f}%".format(np.mean(scores) * 100))

```

这带来了 65.3%的直接收益，仅通过交换分类器就提高了 2.5 个百分点。

使用特征子集的随机森林应该能够比普通决策树更有效地学习更多的特征。我们可以通过在算法中加入更多特性来测试这一点，并看看它是如何进行的:

```
X_all = np.hstack([X_lastwinner, X_teams])
clf = RandomForestClassifier(random_state=14)
scores = cross_val_score(clf, X_all, y_true, scoring='accuracy')
print("Accuracy: {0:.1f}%".format(np.mean(scores) * 100))

```

这导致 63.3%的性能下降！一个原因是随机森林固有的随机性只选择了一些特征来使用，而没有选择其他特征。此外，`X_teams`中的特征比`X_lastwinner`中的特征多得多，拥有额外的特征会导致使用的相关信息更少。也就是说，不要对百分比的微小变化过于兴奋，无论是上升还是下降。与我们刚刚观察到的这些特征集之间的细微差异相比，更改随机状态值对准确性的影响更大。相反，您应该用不同的随机状态运行许多测试，以很好地了解准确性值的平均值和分布。

我们也可以使用`GridSearchCV`类尝试一些其他参数，就像我们在[第 2 章](01.html)、*中使用**scikit-learn estimates*介绍的那样:

```
from sklearn.grid_search import GridSearchCV

parameter_space = {
 "max_features": [2, 10, 'auto'],
 "n_estimators": [100, 200],
 "criterion": ["gini", "entropy"],
 "min_samples_leaf": [2, 4, 6],
}

clf = RandomForestClassifier(random_state=14)
grid = GridSearchCV(clf, parameter_space)
grid.fit(X_all, y_true)
print("Accuracy: {0:.1f}%".format(grid.best_score_ * 100))

```

这有一个更好的准确率 67.4%！

如果我们想看到使用的参数，我们可以打印出在网格搜索中找到的最佳模型。代码如下:

```
print(grid.best_estimator_)

```

结果显示了最佳评分模型中使用的参数:

```
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',
            max_depth=None, max_features=2, max_leaf_nodes=None,
            min_samples_leaf=2, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
            oob_score=False, random_state=14, verbose=0, warm_start=False)

```

# 设计新功能

在前面的几个例子中，我们看到改变特征会对算法的性能产生相当大的影响。通过我们少量的测试，我们仅仅从特征上就有超过 10%的差异。

您可以通过执行以下操作来创建熊猫的简单功能:

```
dataset["New Feature"] = feature_creator()

```

feature_creator 函数必须返回数据集中每个样本的要素值列表。常见的模式是将数据集用作参数:

```
dataset["New Feature"] = feature_creator(dataset)

```

通过将所有值设置为一个默认值，可以更直接地创建这些要素，如下一行中的 0:

```
dataset["My New Feature"] = 0

```

然后，您可以迭代数据集，边走边计算要素。我们在本章中使用了
这种格式来创建我们的许多功能:

```
for index, row in dataset.iterrows():
    home_team = row["Home Team"]
    visitor_team = row["Visitor Team"]
    # Some calculation here to alter row
    dataset.set_value(index, "FeatureName", feature_value)

```

请记住，这种模式效率不高。如果你要这样做，立刻尝试你所有的功能。

A common *best practice* is to touch every sample as little as possible, preferably only once.

您可以尝试和实现的一些示例功能如下:

*   每队的前一场比赛已经过去多少天了？如果球队在短时间内打太多比赛，他们可能会很累。
*   最近五场比赛，每队赢了多少场？这将给出我们之前提取的`HomeLastWin`和`VisitorLastWin`特征的更稳定的形式(并且可以以非常相似的方式提取)。
*   球队在拜访某些其他球队时有好的战绩吗？例如，一个球队可能在一个特定的球场打得很好，即使他们是客队。

如果您在提取这些类型的特征时遇到问题，请查看位于[http://pandas.pydata.org/pandas-docs/stable/](http://pandas.pydata.org/pandas-docs/stable/)的 pandasdocumentation 以获取帮助。或者，您可以尝试在线论坛，如堆栈溢出来寻求帮助。

更极端的例子可以使用球员数据来估计每支球队的实力，以预测谁赢了。赌徒和体育博彩机构每天都在使用这些类型的复杂功能，试图通过预测体育比赛的结果来获利。

# 摘要

在本章中，我们扩展了 scikit-learn 的分类器来执行分类，并引入了`pandas`库来管理我们的数据。我们分析了 NBA 篮球比赛结果的真实数据，发现了一些即使是精心策划的数据也会带来的问题，并为我们的分析创造了新的特征。

我们看到了好的特征对性能的影响，并使用了一种集成算法，即随机森林，来进一步提高准确性。为了进一步理解这些概念，尝试创建自己的特性并测试它们。哪些功能表现更好？如果您在获取要素方面有困难，请考虑可以包含哪些其他数据集。例如，如果关键球员受伤，这可能会影响特定比赛的结果，并导致更好的球队输球。

在下一章中，我们将扩展我们在第一章中执行的相似性分析，以创建一个程序来查找类似的书籍。我们将看到如何使用算法进行排名，以及如何使用近似值来提高数据挖掘的可扩展性。
# 用真实例子分类

本章的题目是**分类**。在机器学习的这种设置中，您向系统提供您感兴趣的不同对象类的示例，然后要求它推广到该类未知的新示例。这看似抽象，但你可能已经将这种形式的机器学习作为一种消费，即使你没有意识到这一点:你的电子邮件系统很可能有自动检测垃圾邮件的能力。也就是说，系统将分析所有收到的电子邮件，并将它们标记为垃圾邮件或非垃圾邮件。通常，您(最终用户)能够手动标记电子邮件是否为垃圾邮件，以提高其垃圾邮件检测能力。这正是我们所说的分类:您提供垃圾邮件和非垃圾邮件的示例，然后使用自动系统对收到的电子邮件进行分类。这是最重要的机器学习模式之一，也是本章的主题。

处理电子邮件等文本需要一套特定的技术和技能，我们将在本书后面讨论这些。目前，我们将使用更小、更容易处理的数据集。本章的示例问题是:机器能根据图像区分花卉种类吗？我们将使用两个数据集，其中记录了花卉形态的测量结果以及几个标本的物种。

我们将探索这些小数据集，以便专注于高级概念。本章的重要内容如下:

*   什么是分类
*   scikit-learn 如何用于分类，哪个分类器是大多数问题的好解决方案
*   如何严格评价一个分类器，避免自欺欺人

# 虹膜数据集

Iris 数据集是 20 世纪 30 年代的经典数据集；这是统计分类的第一个现代例子。

该数据集是几种鸢尾花形态测量的集合。这些测量将使我们能够区分多种花卉。如今，物种是通过它们的 DNA 指纹来识别的，但是在 20 世纪 30 年代，DNA 在遗传学中的作用还没有被发现。

测量了每种植物的以下四个属性:

*   萼片长度
*   萼片宽度
*   花瓣长度
*   花瓣宽度

一般来说，我们称我们用来描述数据的单个数值测量为**特征**。这些特征可以从中间数据直接测量或计算。

该数据集有四个特征。此外，对于每种植物，物种都被记录下来。我们想要解决的问题是:“给定这些例子，如果我们在田野里看到一朵新的花，我们能从它的测量中很好地预测它的物种吗？

这就是**分类**的问题:给定标注的例子，我们能不能设计一个规则，以后应用到其他例子？

在这本书的后面，我们将研究处理文本的问题。目前，Iris 数据集很好地服务于我们的目的。它很小(150 个例子，每个例子有四个特征)，可以很容易地可视化和操作。

# 可视化是很好的第一步

本书后面的数据集将增长到数千个特征。在我们的起始示例中只有四个要素，我们可以轻松地在单个页面上绘制所有二维投影并构建预测，然后可以将其扩展到具有更多要素的大型数据集。正如我们在[第 3 章](03.html)、*回归*中所看到的，可视化在分析的初始探索阶段非常出色，因为它们允许您了解问题的一般特征，以及捕捉数据收集早期出现的问题。

下图中的每个子图显示了投射到两个维度中的所有点。外围组(三角形)为濑户鸢尾属植物，中心组(圆形)为杂色鸢尾属植物，以 *x* 标记绘制处女座鸢尾。我们可以看到有两大集团。一种是濑户鸢尾，另一种是杂色鸢尾和弗吉尼亚鸢尾的混合物:

![](assets/f2ee2004-8b88-45e2-95f3-4c7343355f50.png)

以下是加载数据集的代码(您可以在在线存储库中找到绘图代码):

```
from sklearn.datasets import load_iris 
data = load_iris() 
features = data.data 
feature_names = data.feature_names 
target = data.target 
target_names = data.target_names 
labels = target_names[target] 
```

# 使用 scikit-learn 进行分类

Python 是一种优秀的机器学习语言，因为它有优秀的库。特别是 scikit-learn 已经成为包括分类在内的许多机器学习任务的标准库。我们将在本节和其他分类器中使用它的决策树实现。幸运的是，scikit-learn 中的分类器遵循相同的 API，因此很容易从一个转换到另一个。这些对象有以下两种基本方法:

*   `fit(features, labels)`:这是学习步骤，拟合模型的参数。它以一个类似列表的带有特征的对象和另一个带有标签的对象作为参数。
*   `predict(features)`:该方法只能在拟合后调用，并返回一个或多个输入的预测。

# 建立我们的第一个分类模型

如果目标是将三种类型的花分开，我们可以通过查看数据立即提出一些建议。例如，花瓣长度似乎能够独立地将濑户鸢尾与其他两个花卉物种分开。

直观来说，我们可以在脑海中建立一个简单的模型:如果花瓣宽度小于约`1`，那么这就是一朵鸢尾花；否则要么是弗吉尼亚鸢尾，要么是杂色鸢尾。机器学习是当我们编写代码时自动寻找这种类型的分离。

将濑户鸢尾与其他两个物种区分开来的问题很容易解决。然而，我们不能立即确定区分弗吉尼亚鸢尾和杂色鸢尾的最佳切口。我们甚至可以看到，我们永远不会用一个简单的规则来实现完美的分离，比如，如果特征 X 高于某个值，那么 A，否则 b。

我们可以尝试在**决策树**中组合多个规则。这是最简单的分类模型之一，也是最早为机器学习提出的模型之一。它的另一个优点是模型可以简单地解释。

使用 scikit-learn，很容易学习决策树:

```
from sklearn import tree 
tr = tree.DecisionTreeClassifier(min_samples_leaf=10)
tr.fit(features, labels) 
```

就这样。可视化树需要我们首先以点格式将其写入文件，然后显示它:

```
import graphviz
tree.export_graphviz(tr, feature_names=feature_names, round-ed=True, out_file='decision.dot')

graphviz.Source(open('decision.dot').read()) 
```

我们可以看到，第一次拆分是花瓣宽度，结果是两个节点，一个节点是所有样本都是第一类的(用`[50,0,0]`表示)，其余的是数据(`[0,50,50]`)。

这个模型有多好？我们可以通过将它应用于数据(使用`predict`方法)并查看它与输入的匹配程度来尝试它:

```
prediction = tr.predict(features) 
print("Accuracy: {:.1%}".format(np.mean(prediction == labels))) 
```

这会打印出精度:`96.0`百分比。

# 评估-提供数据和交叉验证

上一节讨论的模型是一个简单的模型；它实现了整个数据的百分之`96.0`精度。然而，这一评价几乎肯定过于乐观。我们使用数据来定义树的外观，然后使用相同的数据来评估模型。当然，该模型在这个数据集上会表现很好，因为它已经过优化，在这个数据集上表现很好。推理是循环的。

我们真正想做的是评估模型推广到新实例的能力。我们应该在算法在训练中没有看到的情况下测量它的性能。因此，我们将进行更严格的评估，并使用保留的数据。为此，我们将数据分成两组:在一组中，我们将训练模型，在另一组中，我们将测试我们在训练中保留的模型。完整的代码是对前面介绍的代码的改编，可在在线支持存储库中找到。其输出如下:

```
Training accuracy was 96.0%.
Testing accuracy was 94.7%.  
```

训练数据(整个数据的子集)的结果与之前相同。然而，需要注意的是，测试数据的结果低于训练误差的结果。在这种情况下，差异很小，但可以大得多。当使用复杂模型时，在训练中有可能获得 100%的准确性，并且在测试中做得不比随机猜测好！虽然这可能会让没有经验的机器学习者感到惊讶，但预计测试精度将低于训练精度。

要理解为什么，考虑一下决策树是如何工作的:它定义了不同特征的一系列阈值。有时可能非常清楚阈值应该在哪里，但在某些区域，即使是一个数据点也可以改变阈值并上下移动。

The accuracy on the training data, the **training accuracy**, is almost always an overly optimistic estimate of how well your algorithm is doing. We should always measure and report the **testing accuracy**, which is the accuracy on a collection of examples that were not used for training.

我们刚才所做的一个可能的问题是，我们只使用了一半的数据进行训练。也许使用更多的训练数据会更好。另一方面，如果我们留给测试的数据太少，误差估计将在很少的例子上进行。理想情况下，我们希望将所有数据用于培训，也将所有数据用于测试，这是不可能的。

我们可以通过一种叫做**交叉验证**的方法来很好地近似这个不可能的理想。交叉验证的一种简单形式是**省去一个交叉验证**。我们将从训练数据中拿出一个例子，学习一个没有这个例子的模型，然后测试这个模型对这个例子的分类是否正确。

然后对数据集中的所有元素重复该过程:

```
predictions = [] 
for i in range(len(features)): 
    train_features = np.delete(features, i, axis=0) 
    train_labels = np.delete(labels, i, axis=0) 
    tr.fit(train_features, train_labels) 
    predictions.append(tr.predict([features[i]])) 
predictions = np.array(predictions) 
```

在这个循环结束时，我们将对所有示例测试一系列模型，并将获得最终的平均结果。当使用交叉验证时，不存在循环性问题，因为每个例子都是在没有考虑数据点的模型上测试的。因此，交叉验证的估计是对模型推广到新数据的可靠估计。

省略交叉验证的主要问题是，我们现在被迫多次执行更多的工作。事实上，您必须为每一个示例学习一个全新的模型，并且这个成本会随着数据集的增长而增加。

通过使用 k 倍交叉验证，我们可以以很小的成本获得省略的大部分好处，其中 *k* 代表一个小数字。例如，为了执行五重交叉验证，我们将数据分成五组，即所谓的五重。

然后你学习五种模式。每次，你都会在训练数据中留下一个折叠。生成的代码将类似于本节前面给出的代码，但是我们保留了 20%的数据，而不是只有一个元素。我们在左侧折叠上测试每个模型，并对结果进行平均:

![](assets/969a97f8-3d13-44d1-ae06-b6d696b06038.png)

上图说明了五个块的这个过程:数据集被分成五部分。对于每一个折叠，你拿出其中一个积木进行测试，并在另外四个积木上进行训练。你可以使用任意数量的折叠。计算效率(折叠越多，需要的计算就越多)和精确结果(折叠越多，就越接近使用整个数据进行训练)之间存在权衡。五倍往往是一个很好的妥协。这相当于用 80%的数据进行训练，应该已经接近使用所有数据得到的结果。如果你的数据很少，你甚至可以考虑使用 10 或 20 倍。在一个极端的情况下，如果你有和数据点一样多的折叠，你只是简单地执行了省略交叉验证。另一方面，如果计算时间是一个问题，并且你有更多的数据，两三倍可能是更合适的选择。

生成折叠时，您需要小心保持它们的平衡。例如，如果一个文件夹中的所有示例都来自同一个类，则结果将不具有代表性。我们将不详细讨论如何做到这一点，因为 scikit-learn 机器学习包将为您处理它们。以下是如何使用 scikit-learn 执行五重交叉验证:

```
from sklearn import model_selection 
predictions = model_selection.cross_val_predict( 
    tr, 
    features, 
    labels, 
    cv=model_selection.LeaveOneOut()) 
print(np.mean(predictions == labels)) 
```

我们现在已经生成了几个模型，而不是一个。那么，我们为新数据返回和使用什么最终模型呢？最简单的解决方案是现在在所有的训练数据上训练一个单一的整体模型。交叉验证循环为您提供了该模型推广程度的估计。

A cross-validation schedule allows you to use all your data to estimate whether your methods are doing well. At the end of the cross-validation loop, you can then use all your data to train a final model.

尽管在机器学习作为一个领域起步时，它没有得到正确的认识，但如今，甚至讨论分类系统的训练精度都被视为一个非常糟糕的迹象。这是因为结果可能会非常误导人，甚至仅仅呈现它们就标志着你是机器学习的新手。我们总是希望测量和比较保留数据集的误差或使用交叉验证方案估计的误差。

# 如何衡量和比较分类器

我们如何决定哪个分类器是最好的？我们很少找到完美的解决方案，永远不会出错的模型，所以我们需要决定使用哪一个。我们以前使用过精度，但有时优化会更好，这样模型会产生更少的特定类型的错误。例如，在垃圾邮件过滤中，删除一封好邮件可能比错误地让一封坏邮件通过更糟糕。在这种情况下，我们可能希望选择一个在扔掉电子邮件方面保守的模式，而不是一个总体上犯错最少的模式。我们可以从收益(我们希望最大化)或损失(我们希望最小化)的角度来讨论这些问题。它们是等价的，但有时一个比另一个更方便，你会读到讨论最小化损失或最大化收益的文章。

在医学环境中，假阴性和假阳性并不等同。一个**假阴性**(当一个测试的结果返回阴性，但那是假的)可能会导致病人没有接受严重疾病的治疗。一个**假阳性**(当检测结果呈阳性时，即使患者实际上并没有那种疾病)可能会导致额外的检测来确认这种或不必要的治疗(这仍然会有成本，包括治疗的副作用，但通常没有错过诊断那么严重)。因此，根据具体的设置，不同的权衡是有意义的。在一个极端的情况下，如果疾病是致命的，并且治疗费用低廉，副作用很小，那么你就要尽可能减少假阴性。

What the gain/cost function should be is always dependent on the exact problem you are working on. When we present a general-purpose algorithm, we often focus on minimizing the number of mistakes, achieving the highest accuracy. However, if some mistakes are costlier than others, it might be better to accept a lower overall accuracy to minimize the overall costs.

# 更复杂的数据集和最近邻分类器

我们现在来看一个稍微复杂一点的数据集。这将包括引入新的分类算法和一些其他想法。

# 了解种子数据集

我们现在看另一个农业数据集，它仍然很小，但是已经太大了，不能像我们使用 Iris 数据集那样在一个页面上详尽地绘制出来。这个数据集由小麦种子的测量值组成。存在以下七个特征:

*   A 区
*   周长 P
*   紧密度 *C = 4πA/P*
*   内核长度
*   内核宽度
*   偏度系数
*   仁沟长度

与三个小麦品种相对应的有三类:加拿大小麦、科马小麦和罗莎小麦。如前所述，目标是能够根据这些形态学测量对物种进行分类。与 20 世纪 30 年代收集的 Iris 数据集不同，这是一个非常新的数据集，其特征是根据数字图像自动计算的。

这就是图像模式识别的实现方式:你可以拍摄数字形式的图像，从中计算出一些相关的特征，并使用一个通用的分类系统。在[第 12 章](12.html)*计算机视觉*中，我们将通过这个问题的计算机视觉方面进行工作，并计算图像中的特征。目前，我们将使用赋予我们的特性。

UCI Machine Learning Dataset Repository:
The **University of California at Irvine** (**UCI**) maintains an online repository of machine learning datasets (at the time of writing, they list 233 datasets). Both the Iris and the seeds datasets used in this chapter were taken from there. The repository is available online at [http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/).

# 特征和特征工程

这些特征的一个有趣的方面是紧凑性特征实际上不是一个新的度量，而是前面两个特征的函数:面积和周长。导出新的组合特征通常非常有用。尝试创建新特征一般称为**特征工程**。它有时被认为不如算法迷人，但它通常对性能更重要(在精选特征上的简单算法比在不太好的特征上的花哨算法性能更好)。

在这种情况下，最初的研究人员计算了**紧密度**，这是形状的典型特征。它有时也被称为**圆形**。该特性对于两个内核具有相同的值，其中一个内核是另一个内核的两倍大，但是具有相同的形状。但是，与拉长的内核(当特征接近于零时)相比，非常圆的内核(当特征接近于 1 时)将具有不同的值。

一个好的特性的目标是同时随重要的东西(期望的输出)而变化，而不随不重要的东西而变化。例如，紧凑性不是在大小上变化，而是在形状上变化。在实践中，可能很难完美地实现这两个目标，但我们希望接近这个理想。

你将需要使用背景知识来设计好的功能。幸运的是，对于许多问题领域来说，已经有大量可能的特性和特性类型可以构建。就图像而言，前面提到的所有特征都是典型的，计算机视觉库将为您计算它们。在基于文本的问题中，也有可以混合搭配的标准解决方案(我们也会在[第 4 章](04.html)、*分类 I -检测不良答案*中看到这一点)。在可能的情况下，你应该利用你对问题的了解来设计一个特定的特性，或者从文献中选择更适用于手头数据的特性。

甚至在你有数据之前，你必须决定哪些数据值得收集。然后，你把你所有的特征交给机器来评估和计算最好的分类器。

一个自然的问题是，我们能否自动选择好的特征。这个问题被称为**特征选择**。针对这个问题已经提出了许多方法，但在实践中，非常简单的想法效果最好。对于我们目前正在探索的小问题，使用特征选择是没有意义的，但是如果你有成千上万个特征，那么扔掉其中的大部分可能会使剩下的过程更快。

# 最近邻分类

为了使用这个数据集，我们将引入一个新的分类器:最近邻分类器。最近邻分类器非常简单。对新元素进行分类时，会查看训练数据。对于离它最近的物体，它最近的邻居。然后，它返回其标签作为答案。请注意，该模型在其训练数据上表现完美！对于每个点，它最近的邻居就是它自己，因此它的标签完全匹配(除非两个具有不同标签的示例具有完全相同的特征值，这将表明您正在使用的特征描述性不强)。因此，使用交叉验证协议来测试分类是至关重要的。

最近邻法可以概括为不看单个邻居，而是看多个邻居，并且可以在邻居中进行投票。这使得该方法比异常值或错误标记的数据更稳健。

为了使用 scikit-learn 的最近邻分类实现，我们首先从`sklearn.neighbors`子模块导入`KneighborsClassifier`对象:

```
from sklearn.neighbors import KNeighborsClassifier  
```

我们现在可以实例化一个`classifier`对象。在构造器中，我们指定要考虑的`neighbors`的数量，如下所示:

```
knn = KNeighborsClassifier(n_neighbors=1)  
```

如果我们不指定邻居的数量，它默认为`5`，这通常是一个很好的分类选择，但是我们坚持使用`1`，因为它非常容易思考(在在线存储库中，您可以使用这些参数来玩)。

我们将使用交叉验证(当然)来查看我们的数据。scikit-learn 模块也使这变得简单:

```
kf = model_selection.KFold(n_splits=5, shuffle=False) 
means = [] 
for training,testing in kf.split(features): 
    # We learn a model for this fold with `fit` and then apply it to the 
    # testing data with `predict`: 
    knn.fit(features[training], target[training]) 
    prediction = knn.predict(features[testing]) 

    # np.mean on an array of booleans returns fraction 
    # of correct decisions for this fold: 
    curmean = np.mean(prediction == target[testing]) 
    means.append(curmean) 
print('Mean accuracy: {:.1%}'.format(np.mean(means))) 
```

使用五倍交叉验证，对于这个数据集，使用这个算法，我们获得了 83.8%的准确率。正如我们在前面部分中讨论的，交叉验证精度低于训练精度，但这是对模型性能更可信的估计
。

# 查看决策边界

我们现在将检查决策边界。为了在纸上画出这些，我们将简化并只看两个维度:

```
knn.fit(features[:, [0,2]], target)  
```

我们将通过`1000`点调用特征值网格上的预测(T0):

```
y0, y1 = features[:, 2].min() * .9, features[:, 2].max() * 1.1 
x0, x1 = features[:, 0].min() * .9, features[:, 0].max() * 1.1 
X = np.linspace(x0, x1, 1000) 
Y = np.linspace(y0, y1, 1000) 
X, Y = np.meshgrid(X, Y) 
C = knn.predict(np.vstack([X.ravel(), Y.ravel()]).T).reshape(X.shape)  
```

现在，我们绘制决策边界:

```
cmap = ListedColormap([(1., 1., 1.), (.2, .2, .2), (.6, .6, .6)]) 

fig,ax = plt.subplots() 
ax.scatter(features[:, 0], features[:, 2], c=target, cmap=cmap) 
for lab, ma in zip(range(3), "Do^"): 
    ax.plot(features[target == lab, 0], features[ 
             target == lab, 2], ma, c=(1., 1., 1.), ms=6) 

ax.set_xlim(x0, x1) 
ax.set_ylim(y0, y1) 
ax.set_xlabel(feature_names[0]) 
ax.set_ylabel(feature_names[2]) 
ax.pcolormesh(X, Y, C, cmap=cmap) 
```

结果是这样的:

![](assets/5dd0547f-e204-4e64-b3b3-08bcf815302b.png)

加拿大的例子显示为钻石，科马种子为圆形，罗莎种子为三角形。它们各自的区域显示为白色、黑色和灰色。你可能想知道为什么这些区域如此水平，几乎奇怪的是。问题是 *x* 轴(面积)范围从 **10** 到 **22** ，而 *y* 轴(密实度)范围从 **0.75** 到 1.0。这意味着 *x* 的微小变化实际上比 *y* 的微小变化要大得多。所以，当我们计算点与点之间的距离时，我们在很大程度上只考虑了 *x* 轴。这也是一个很好的例子，说明为什么可视化我们的数据并寻找危险信号或惊喜是一个好主意。

如果你学过物理(还记得你的课)，你可能已经注意到我们一直在总结长度、面积和无量纲量，混合我们的单位(这是你永远不想在物理系统中做的事情)。我们需要将所有特征标准化到一个共同的尺度。这个问题有很多解决办法；一个简单的方法是标准化为 z 分数。一个值的 z 分数是它离平均值有多远，以标准差为单位。归结起来就是这个操作:

*f ' = ( f - µ)/σ*

该公式中， *f* 为旧特征值， *f'* 为归一化特征值，*T5】为特征均值， *σ* 为标准差。和 *σ* 都是从训练数据中估计出来的。与原始值无关，在 z 评分后，零值对应于训练平均值，正值高于平均值，负值低于平均值。*

scikit-learn 模块使得将这种规范化作为预处理步骤非常容易。我们将使用一个转换管道:第一个元素进行转换，第二个元素进行分类。我们首先导入管道和要素缩放类，如下所示:

```
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler  
```

现在，我们可以将它们结合起来:

```
clf = KNeighborsClassifier(n_neighbors=1)
clf = Pipeline([('norm', StandardScaler()), ('knn', classifier)])  
```

管道构造器获取一个对列表`(str,clf)`。每对对应于管道中的一个步骤:第一个元素是命名该步骤的字符串，而第二个元素是执行转换的对象。对象的高级用法使用这些名称来指代不同的步骤。

归一化后，每个特征都以相同的单位表示(技术上，每个特征现在都是无量纲的；它没有单位)，我们可以更自信地混合维度。事实上，如果我们现在运行最近邻分类器，我们将获得 86%的准确率，使用前面显示的相同的五倍交叉验证代码进行估计！

再从两个维度来看决策空间:

![](assets/976b5ceb-6f18-45c7-9cf7-0b725788d70c.png)

界限现在不同了，你可以看到两个维度对结果都有影响。在完整的数据集中，一切都发生在一个七维空间，这很难想象，但同样的原理适用；虽然一些维度在原始数据中占主导地位，但在标准化之后，它们都被赋予了相同的重要性。

# 使用哪个分类器

到目前为止，我们已经研究了两个经典的分类器，即决策树和最近邻分类器。Scikit-learn 支持更多，但它不支持学术文献中提出的所有内容。因此，人们可能会想:我应该用哪一个？了解所有这些有什么重要的吗？

在许多情况下，数据集的知识可以帮助您决定哪个分类器的结构最符合您的问题。然而，曼努埃尔·费尔南德斯-德尔加多和他的同事们有一项非常好的研究，题为*我们需要数百个分类器来解决现实世界的分类问题吗？*这是一项可读性很强、非常注重实际的研究，作者得出结论，实际上有一个分类器很可能是大多数问题的最佳(或接近最佳)分类器，即**随机森林**。

什么是随机森林？顾名思义，森林是树木的集合。在这种情况下，决策树的集合。我们如何从单个数据集中获得许多树？如果你试着多次调用我们之前用过的方法，你会发现你每次都会得到完全一样的树。诀窍是用数据集的不同随机变量多次调用该方法。特别是，每次，我们都会获取数据集的一部分和要素的一部分。因此，每次都有不同的树。在分类的时候，所有的树投票，最终决定达成。有许多不同的参数决定所有次要的细节，但只有一个是相关的，即您使用的树的数量。一般来说，构建的树越多，需要的内存就越多，但是分类的准确性也会提高(达到最佳性能的平稳状态)。scikit-learn 中的默认值是 10 棵树。除非数据集非常大，以致内存使用成为问题，否则增加该值通常是有利的:

```
from sklearn import ensemble 
rf = ensemble.RandomForestClassifier(n_estimators=100) 
predict = model_selection.cross_val_predict(rf, features, target) 
print("RF accuracy: {:.1%}".format(np.mean(predict == target)))  
```

在这个数据集上，结果约为 86%(运行时可能略有不同，因为它们是**随机**森林)。

随机森林的另一大优势是，由于它们基于决策树，最终它们只基于特征阈值执行二元决策。因此，当特征被放大或缩小时，它们是不变的。

# 摘要

分类意味着从示例中进行归纳，以构建一个将对象分配给预定义类的模型(即，一个可以自动应用于新的未分类对象的规则)。它是机器学习的基本工具之一，我们将在接下来的章节中看到更多这样的例子。

在某种程度上，这是一个非常抽象和理论化的章节，因为我们用简单的例子介绍了一般的概念。我们对 Iris 数据集进行了一些操作。这是一个小数据集。然而，它有一个优势，那就是我们能够绘制所有的数据，并详细了解我们在做什么。当我们继续研究具有许多维度和成千上万个例子的问题时，这种东西将会丢失。我们在这里获得的见解仍然有效。

您还了解到，训练误差是对模型性能的误导性、过于乐观的估计。相反，我们必须根据未用于培训的测试数据对其进行评估。为了不在测试中浪费太多的例子，交叉验证计划可以让我们两全其美(以更多的计算为代价)。

最后，我们讨论了通常最好的现成分类器，随机森林。使用非常灵活的分类系统很简单(几乎不需要对数据进行预处理)，并且在各种各样的问题中获得非常高的性能。

[第三章](03.html)、*回归*，我们将深入 sci kit-learn——神奇的机器学习工具包——概述不同类型的学习，向您展示特征工程之美。
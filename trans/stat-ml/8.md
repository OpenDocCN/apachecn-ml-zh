# 无监督学习

无监督学习的目标是发现数据中不存在目标变量的隐藏模式或结构，以执行分类或回归方法。无监督学习方法通常更具挑战性，因为结果是主观的，并且没有简单的分析目标，例如预测类别或连续变量。这些方法是探索性数据分析的一部分。除此之外，很难评估从无监督学习方法中获得的结果，因为没有普遍接受的机制来验证结果。

尽管如此，无监督学习方法作为当今的一个热门话题，在各个领域都变得越来越重要，许多研究人员目前正在积极研究它们，以探索这一新的领域。一些好的应用是:

*   **基因组学**:无监督学习应用于理解来自 DNA 的基因组范围的生物学见解，以更好地理解疾病和人类。这些类型的任务本质上更具探索性。
*   **搜索引擎**:搜索引擎可能会根据其他相似用户的点击历史来选择向特定个人显示哪些搜索结果。
*   **知识提取**:从原始文本中提取概念的分类，生成知识图，创建自然语言处理领域的语义结构。
*   **客户细分**:在银行业中，像聚类这样的无监督学习被应用于对相似客户进行分组，营销部门基于这些细分设计他们的联系策略。比如，年龄较大的低风险客户会以定期存款产品为目标，风险较高的年轻客户会以信用卡或共同基金为目标，等等。
*   **社交网络分析**:识别社交网络中联系更紧密、共同特征相似的人群的内聚群体。

在本章中，我们将介绍使用公开可用的数据执行无监督学习的以下技术:

*   k-均值聚类
*   主成分分析
*   奇异值分解
*   深度自动编码器

# k-均值聚类

聚类是对观测值进行分组的任务，其方式是同一聚类的成员彼此更相似，而不同聚类的成员彼此差异很大。

聚类通常用于探索数据集，以识别其中的底层模式或创建一组特征。在社交网络的情况下，它们可以聚集在一起，以识别社区并暗示人与人之间缺失的联系。这里有几个例子:

*   在反洗钱措施中，可以使用异常检测来识别可疑活动和个人
*   在生物学中，聚类被用来寻找具有相似表达模式的基因组
*   在营销分析中，聚类被用来寻找相似客户的细分，以便不同的营销策略可以相应地应用于不同的客户细分

k-means 聚类算法是一个迭代过程，将聚类或质心的中心移动到其组成点的平均位置，并迭代地将实例重新分配到它们最接近的聚类，直到可能的聚类中心数量或达到的迭代数量没有显著变化。

k 均值的成本函数由属于该聚类的观测值与其各自质心值之间的欧几里德距离(平方范数)决定。理解这个方程的一个直观方法是，如果只有一个聚类( *k=1* ，那么所有观测值之间的距离与其单个平均值进行比较。然而，如果集群的数量增加到 *2* ( *k= 2* )，则计算两个平均值，并将一些观测值分配给集群 *1* ，并且基于接近度将其他观测值分配给集群二 *-* 。随后，在成本函数中通过应用相同的距离度量来计算距离，但是对它们的聚类中心分别进行计算:

![](assets/5c1bfaf2-5198-41be-aa86-a272f5147e6e.jpg)

# k-表示来自第一性原理的工作方法

k-means 工作方法在以下示例中进行了说明，其中考虑了 12 个实例的 *X* 和 *Y* 值。任务是从数据中确定最佳聚类。

| **实例** | **X** | **Y** |
| one | seven | eight |
| Two | Two | four |
| three | six | four |
| four | three | Two |
| five | six | five |
| six | five | seven |
| seven | three | three |
| eight | one | four |
| nine | five | four |
| Ten | seven | seven |
| Eleven | seven | six |
| Twelve | Two | one |

在 2D 图上绘制数据点后，我们可以看到大致有两个聚类是可能的，其中左下是第一个聚类，右上是另一个聚类，但是在许多实际情况下，变量(或维度)太多，我们无法简单地将它们可视化。因此，我们需要一种数学和算法的方法来解决这些类型的问题。

![](assets/3de01976-ec15-4652-b619-3112b2d1bda0.png)

迭代 1:让我们假设所有 *12* 实例中的两个实例有两个中心。在这里，我们选择了实例 *1* ( *X = 7，Y = 8* )和实例 *8* ( *X = 1，Y = 4* )，因为它们似乎处于两个极端。对于每个实例，我们将计算它相对于两个质心的欧几里德距离，并将其分配给最近的聚类中心。

| **实例** | **X** | **Y** | **质心 1 距离** | **质心 2 距离** | **分配的集群** |
| one | seven | eight | Seven point two one | Zero | C2 |
| Two | Two | four | One | Six point four | C1 |
| three | six | four | Five | Four point one two | C2 |
| four | three | Two | Two point eight three | Seven point two one | C1 |
| five | six | five | Five point one | Three point one six | C2 |
| six | five | seven | Five | Two point two four | C2 |
| seven | three | three | Two point two four | Six point four | C1 |
| eight | one | four | Zero | Seven point two one | C1 |
| nine | five | four | Four | Four point four seven | C1 |
| Ten | seven | seven | Six point seven one | One | C2 |
| Eleven | seven | six | Six point three two | Two | C2 |
| Twelve | Two | one | Three point one six | Eight point six | C1 |
| 质心 1 | one | four | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) |
| 质心 2 | seven | eight | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) |

两点 *A (X1，Y1)* 和 *B (X2，Y2)* 之间的欧氏距离如下所示:

![](assets/00fd6445-82f0-46d0-86b0-6d108b03a793.jpg)

质心距离计算通过采用欧几里德距离来执行。示例计算如下所示。例如，六个相对于两个质心(质心 1 和质心 2)。

![](assets/b96fb27f-f3cc-41fd-b741-38406ae88555.jpg)

![](assets/a131b704-1f1a-40c7-bb1e-24fa508933db.jpg)

下表描述了实例到两个质心的分配，如前表格式所示:

![](assets/3d4f8521-1c83-4b5f-b0ea-b5289f28abb9.png)

如果我们仔细观察前面的图表，我们会发现除了实例 *9 (X =5，Y = 4)* 之外，所有的实例似乎都被适当地分配了。但是，在后期，应该适当分配。让我们在下面的步骤中看看作业是如何发展的。

迭代 2:在这个迭代中，新的质心是从该簇或质心的指定实例中计算出来的。基于指定点的简单平均值计算新质心。

| **实例** | **X** | **Y** | **分配的集群** |
| one | seven | eight | C2 |
| Two | Two | four | C1 |
| three | six | four | C2 |
| four | three | Two | C1 |
| five | six | five | C2 |
| six | five | seven | C2 |
| seven | three | three | C1 |
| eight | one | four | C1 |
| nine | five | four | C1 |
| Ten | seven | seven | C2 |
| Eleven | seven | six | C2 |
| Twelve | Two | one | C1 |
| 质心 1 | Two point six seven | three | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) |
| 质心 2 | Six point three three | Six point one seven | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) |

质心 1 和 2 的示例计算如下所示。类似的方法也将应用于所有后续迭代:

![](assets/a56f9b50-d54c-422d-9f77-9894bbb9952a.jpg)

![](assets/cea7454f-9e72-4c85-9314-8307ddd6b5e8.jpg)

![](assets/1084b726-e2c1-4f35-820e-b19d88324d25.jpg)

![](assets/0eef2d66-2577-4143-91ec-6741139f47e3.jpg)

![](assets/7be8ce21-634c-4949-8b1c-2d3a1269c702.jpg)

![](assets/5ed26073-a96e-4200-adf4-694243ef6bbd.jpg)

![](assets/5e49d00a-c375-4513-b8de-ce686938e8cc.png)

更新质心后，我们需要将实例重新分配到最近的质心，这将在迭代 3 中执行。

迭代 3:在此迭代中，基于实例和新质心之间的欧氏距离计算新的赋值。在任何变化的情况下，新的质心将被迭代计算，直到分配中没有变化是可能的或者达到迭代次数。下表描述了新质心和所有实例之间的距离度量:

| **实例** | **X** | **Y** | **质心 1 距离** | **质心 2 距离** | **之前分配的集群** | **新分配的集群** | **变了？** |
| one | seven | eight | Six point six one | One point nine five | C2 | C2 | 不 |
| Two | Two | four | One point two | Four point eight four | C1 | C1 | 不 |
| three | six | four | Three point four eight | Two point one nine | C2 | C2 | 不 |
| four | three | Two | One point zero five | Five point three four | C1 | C1 | 不 |
| five | six | five | Three point eight eight | One point two two | C2 | C2 | 不 |
| six | five | seven | Four point six three | One point five seven | C2 | C2 | 不 |
| seven | three | three | Zero point three three | Four point six | C1 | C1 | 不 |
| eight | one | four | One point nine five | Five point seven five | C1 | C1 | 不 |
| nine | five | four | Two point five four | Two point five five | C1 | C1 | 不 |
| Ten | seven | seven | Five point eight nine | One point zero seven | C2 | C2 | 不 |
| Eleven | seven | six | Five point two seven | Zero point six nine | C2 | C2 | 不 |
| Twelve | Two | one | Two point one one | Six point seven four | C1 | C1 | 不 |
| 质心 1 | Two point six seven | three | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) |
| 质心 2 | Six point three three | Six point one seven | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) | ![](assets/8fae4175-3d43-42a4-978d-82b925b8d631.png) |

似乎没有登记变更。因此，我们可以说解是收敛的。这里需要注意的一点是，除了实例 *9 (X = 5，Y = 4)之外，所有的实例都分类得非常清楚。*基于本能，似乎应该将其分配给质心 2，但经过仔细计算，该实例更接近聚类 1，而不是聚类 2。然而，距离的差异很小(质心为 1 时为 2.54，质心为 2 时为 2.55)。

# 最佳聚类数和聚类评价

虽然选择簇的数量更多的是一门艺术，而不是科学，但是选择最优的簇的数量是可能的，通过增加簇的数量，解释能力不会有太多的边际增加。在实际应用中，企业通常应该能够提供他们正在寻找的大约数量的集群。

# 肘形法

在 k-均值聚类中，使用肘形方法来确定最佳聚类数。肘形法绘制由不同的 *k* 值产生的成本函数值。如你所知，如果 *k* 增加，平均畸变将减少，每个簇将有更少的组成实例，并且实例将更接近它们各自的质心。然而，平均失真的改善将随着 *k* 的增加而下降。失真改善下降最多的 *k* 的值被称为肘，在该值下，我们应该停止将数据分成更多的簇。

![](assets/65542780-9461-4170-bf0b-95a1c8af0270.png)

用轮廓系数评价聚类:轮廓系数是对聚类紧密度和分离度的度量。更高的值代表更好的聚类质量。轮廓系数对于分离良好的紧凑簇较高，对于重叠簇较低。轮廓系数值确实从-1 变化到+1，数值越高越好。

轮廓系数是按实例计算的。对于一组实例，它被计算为单个样本得分的平均值。

![](assets/14c1e206-79ae-4b96-9716-5b02779bfbe6.jpg)

*a* 是集群中实例之间的平均距离， *b* 是实例和下一个最近集群中实例之间的平均距离。

# 虹膜数据实例的 k 均值聚类

著名的 iris 数据已经从 UCI 机器学习存储库中使用 k-means 聚类进行说明。下载数据的链接在这里:[http://archive.ics.uci.edu/ml/datasets/Iris](http://archive.ics.uci.edu/ml/datasets/Iris)。鸢尾的数据有三种类型的花:濑户花、云芝花和弗吉尼亚花，以及它们各自的萼片长度、萼片宽度、花瓣长度和花瓣宽度的测量值。我们的任务是根据花朵的尺寸对它们进行分组。代码如下:

```py
>>> import os 
""" First change the following directory link to where all input files do exist """ 
>>> os.chdir("D:\\Book writing\\Codes\\Chapter 8") 

K-means algorithm from scikit-learn has been utilized in the following example 

# K-means clustering 
>>> import numpy as np 
>>> import pandas as pd 
>>> import matplotlib.pyplot as plt 
>>> from scipy.spatial.distance import cdist, pdist 

>>> from sklearn.cluster import KMeans 
>>> from sklearn.metrics import silhouette_score 

>>> iris = pd.read_csv("iris.csv") 
>>> print (iris.head()) 

```

![](assets/723e8958-74e7-425b-88b0-238fdd0f640f.png)

以下代码用于将`class`变量分离为因变量，以便在绘图中创建颜色，并且应用于给定`x`变量的无监督学习算法不存在任何目标变量:

```py
>>> x_iris = iris.drop(['class'],axis=1) 
>>> y_iris = iris["class"] 

```

作为样本度量，已经使用了三个聚类，但是在现实生活中，我们不知道有多少聚类的数据会被提前使用，因此我们需要通过反复试验来测试结果。下面选择的最大迭代次数是 300，但是，也可以更改该值，并相应地检查结果:

```py
>>> k_means_fit = KMeans(n_clusters=3,max_iter=300) 
>>> k_means_fit.fit(x_iris) 

>>> print ("\nK-Means Clustering - Confusion Matrix\n\n",pd.crosstab(y_iris, k_means_fit.labels_,rownames = ["Actuall"],colnames = ["Predicted"]) )      
>>> print ("\nSilhouette-score: %0.3f" % silhouette_score(x_iris, k_means_fit.labels_, metric='euclidean')) 

```

![](assets/5efc2ce4-8e01-472d-8ec3-1f07ab2b400b.png)

从前面的混淆矩阵中，我们可以看到所有的刚毛花都被正确地聚类，而 50 朵云芝花中有 2 朵，50 朵海滨花中有 14 朵被错误地分类。

Again, to reiterate, in real-life examples we do not have the category names in advance, so we cannot measure accuracy, and so on.

以下代码用于执行敏感度分析，以检查实际上有多少个群集可以更好地解释数据段:

```py
>>> for k in range(2,10): 
...     k_means_fitk = KMeans(n_clusters=k,max_iter=300) 
...     k_means_fitk.fit(x_iris) 
...     print ("For K value",k,",Silhouette-score: %0.3f" % silhouette_score(x_iris, k_means_fitk.labels_, metric='euclidean')) 

```

![](assets/388059e8-0b9a-4f7a-bd4e-6d94109af6b4.png)

前面结果中的侧影系数值显示`K value 2`和`K value 3`比其他所有数值得分都高。作为一个经验法则，我们需要取下一个轮廓系数最高的`K value`。在这里，我们可以说`K value 3`更好。此外，在得出最优`K value`之前，我们还需要查看聚类内的平均值变化值和肘形图。

```py
# Avg. within-cluster sum of squares 
>>> K = range(1,10) 

>>> KM = [KMeans(n_clusters=k).fit(x_iris) for k in K] 
>>> centroids = [k.cluster_centers_ for k in KM] 

>>> D_k = [cdist(x_iris, centrds, 'euclidean') for centrds in centroids] 

>>> cIdx = [np.argmin(D,axis=1) for D in D_k] 
>>> dist = [np.min(D,axis=1) for D in D_k] 
>>> avgWithinSS = [sum(d)/x_iris.shape[0] for d in dist] 

# Total with-in sum of square 
>>> wcss = [sum(d**2) for d in dist] 
>>> tss = sum(pdist(x_iris)**2)/x_iris.shape[0] 
>>> bss = tss-wcss 

# elbow curve - Avg. within-cluster sum of squares 
>>> fig = plt.figure() 
>>> ax = fig.add_subplot(111) 
>>> ax.plot(K, avgWithinSS, 'b*-') 
>>> plt.grid(True) 
>>> plt.xlabel('Number of clusters') 
>>> plt.ylabel('Average within-cluster sum of squares') 

```

![](assets/2a80eb91-9f41-47ba-8e2a-f252831a347e.png)

从肘部图来看，似乎在值为 3 时，斜率发生了剧烈变化。在这里，我们可以选择最佳 k 值为三。

```py
# elbow curve - percentage of variance explained 
>>> fig = plt.figure() 
>>> ax = fig.add_subplot(111) 
>>> ax.plot(K, bss/tss*100, 'b*-') 
>>> plt.grid(True) 
>>> plt.xlabel('Number of clusters') 
>>> plt.ylabel('Percentage of variance explained')
>>> plt.show()

```

![](assets/8cef63f9-2354-4dc6-b2df-4db7b707b348.png)

最后但同样重要的是，方差解释值的总百分比应该大于 80%，以决定最佳的聚类数。即使在这里，k 值为 3 似乎给出了总方差的合理值。因此，我们可以从前面的所有指标(轮廓、聚类内平均方差和解释的总方差)中得出结论，三个聚类是理想的。

使用虹膜数据进行 k 均值聚类的 R 码如下:

```py
setwd("D:\\Book   writing\\Codes\\Chapter 8")   

iris_data = read.csv("iris.csv")   
x_iris =   iris_data[,!names(iris_data) %in% c("class")]   
y_iris = iris_data$class   

km_fit = kmeans(x_iris,centers   = 3,iter.max = 300 )   

print(paste("K-Means   Clustering- Confusion matrix"))   
table(y_iris,km_fit$cluster)   

mat_avgss = matrix(nrow = 10,   ncol = 2)   

# Average within the cluster   sum of square   
print(paste("Avg. Within   sum of squares"))   
for (i in (1:10)){   
  km_fit =   kmeans(x_iris,centers = i,iter.max = 300 )   
  mean_km =   mean(km_fit$withinss)   
  print(paste("K-Value",i,",Avg.within   sum of squares",round(mean_km, 2)))   
  mat_avgss[i,1] = i   
  mat_avgss[i,2] = mean_km   
}   
 plot(mat_avgss[,1],mat_avgss[,2],type   = 'o',xlab = "K_Value",ylab = "Avg. within sum of square")   
title("Avg. within sum of   squares vs. K-value")   

mat_varexp = matrix(nrow = 10,   ncol = 2)   
# Percentage of Variance   explained   
print(paste("Percent.   variance explained"))   
for (i in (1:10)){   
  km_fit =   kmeans(x_iris,centers = i,iter.max = 300 )   
  var_exp =   km_fit$betweenss/km_fit$totss   
  print(paste("K-Value",i,",Percent   var explained",round(var_exp,4)))   
  mat_varexp[i,1]=i   
  mat_varexp[i,2]=var_exp   
}   

plot(mat_varexp[,1],mat_varexp[,2],type   = 'o',xlab = "K_Value",ylab = "Percent Var explained")   
title("Avg. within sum of   squares vs. K-value") 

```

# 主成分分析

**主成分分析** ( **主成分分析**)是一种非常有用的降维技术。主成分分析通过将数据投影到低维子空间来降低数据集的维数。例如，可以通过将点投影到一条线上来减少 2D 数据集。然后，数据集中的每个实例将由单个值表示，而不是一对值。类似地，通过将变量投影到一个平面上，可以将三维数据集简化为二维。主成分分析有以下实用程序:

*   减轻维度的进程
*   压缩数据，同时最大限度地减少信息丢失
*   在监督学习的下一阶段，主成分将被进一步用于随机森林、boosting 等等
*   理解具有数百个维度的数据结构可能是困难的，因此，通过将维度减少到 2D 或三维，观察可以很容易地可视化

主成分分析可以很容易地用机械工程课程的机器绘图模块中绘制的机械支架的下图来解释。图的左侧描绘了组件的俯视图、正视图和侧视图。但是，在右侧，绘制了一个等轴测视图，其中使用了一个图像来可视化组件的外观。因此，可以想象左边的图像是实际变量，右边的图像是第一主成分，其中大部分方差已经被捕获。

最后，通过旋转方向轴，三幅图像被一幅图像所取代。事实上，我们在主成分分析中复制了相同的技术。

![](assets/44c2fe98-047e-4f32-988d-9b26d7332b0a.png)

在以下示例中解释了主成分工作方法，其中实际数据显示在 2D 空间中，其中 *X* 和 *Y* 轴用于绘制数据。主成分是获取数据最大变化的成分。

![](assets/56ebc4ac-0892-4643-80e6-e49f81003084.png)

下图说明了拟合主成分后的外观。第一个主成分覆盖数据中的最大方差，第二个主成分与第一个主成分正交，因为我们知道所有的主成分都是相互正交的。我们可以用第一主成分本身来表示整个数据。事实上，这就是用更少的维度来表示数据、节省空间以及获取数据中的最大方差是多么有利，这可以用于下一阶段的监督学习。这是计算主成分的核心优势。

![](assets/4576e902-2eda-443a-9d9e-7fcf3e2ae146.png)

特征向量和特征值在线性代数、物理、力学等领域具有重要意义。刷新，特征向量和特征值的基础知识是必要的，当研究主成分分析。特征向量是线性变换简单地通过*拉伸/压缩*和/或*翻转*作用的轴(方向)；而特征值给出了压缩发生的因素。换句话说，线性变换的特征向量是非零向量，当对其应用线性变换时，其方向不变。

更正式地说， *A* 是向量空间的线性变换，![](assets/ef838231-6196-41bf-83d4-793a6f88f1a2.jpg)是非零向量，那么 *A* 的本征向量如果![](assets/baf092b4-61cd-409e-bb3e-45a76dd9c6e0.jpg)是![](assets/ef838231-6196-41bf-83d4-793a6f88f1a2.jpg)的标量倍数。该条件可以写成下面的等式:

![](assets/8d929a4f-dc8c-4105-8432-29bc22965ae4.jpg)

在上式中，![](assets/ef838231-6196-41bf-83d4-793a6f88f1a2.jpg)为特征向量， *A* 为方阵，λ为标量，称为特征值。特征向量经过 *A* 变换后，方向保持不变；只有它的大小发生了变化，如特征值所示，也就是说，将一个矩阵乘以它的一个特征向量等于缩放特征向量，这是原始矩阵的紧凑表示。下图描述了 2D 空间中图形表示的特征向量和特征值:

![](assets/ff1b6495-8bd1-4fce-9d7e-c75e6665c6e5.png)

下面的例子描述了如何从方阵计算特征向量和特征值及其理解。请注意，特征向量和特征值只能针对方阵(行和列维度相同的方阵)进行计算。

![](assets/18b17587-2d59-4ba6-994e-bc5cc02c8241.jpg)

回想一下 *A* 和 *A* 的任意特征向量的乘积必须等于特征向量乘以特征值的大小的等式:

![](assets/df61736c-b624-48d2-9dd0-393613987a4c.jpg)

![](assets/aaf8dad2-c8f9-4ac7-9933-17d0fb9e6578.jpg)

一个特征方程表示矩阵的行列式，即数据矩阵和单位矩阵的乘积与一个特征值之差为 *0* 。

![](assets/74f63d11-8978-44e7-8b21-93bbea325847.jpg)

前面矩阵的两个特征值都等于 *-2* 。我们可以用特征值来代替方程中的特征向量:

![](assets/8d929a4f-dc8c-4105-8432-29bc22965ae4.jpg)

![](assets/ce12ab62-29f9-4c68-a1bb-4daf84c1cad3.jpg)

![](assets/114b99bf-f66b-4b5e-a91e-e7bc54f6a2cb.jpg)

将上式中的特征值代入，我们将得到以下公式:

![](assets/53837472-b710-4e3e-aa2b-19f42a2ddb94.jpg)

前面的方程可以改写为方程组，如下所示:

![](assets/0220d547-c525-48e3-98ad-961d74634e32.jpg)

这个方程表明它可以有多个特征向量的解，我们可以用任何保持前面方程的值来代替它来验证这个方程。在这里，我们用了向量*【1 1】*进行验证，似乎得到了证明。

![](assets/86bd7cbc-f296-4ff3-9a23-f286361b4a00.jpg)

主成分分析需要在计算中使用单位特征向量，因此我们需要用范数来划分单位特征向量，或者我们需要归一化特征向量。2 范数方程如下所示:

![](assets/55bc8685-5547-4a5d-9991-3edc37916e83.jpg)

输出向量的范数计算如下:

![](assets/5f90e2cf-a138-400e-8728-34f631ed9663.jpg)

单位特征向量如下所示:

![](assets/e0b85031-8144-4b18-80f7-fa427374a007.jpg)

# 来自基本原则的常设仲裁院工作方法

主成分分析工作方法在以下示例数据中进行了描述，每个实例或数据点都有两个维度。这里的目标是将 2D 数据简化为一维(也称为**主成分**):

| **实例** | **X** | **Y** |
| one | Zero point seven two | Zero point one three |
| Two | Zero point one eight | Zero point two three |
| three | Two point five | Two point three |
| four | Zero point four five | Zero point one six |
| five | Zero point zero four | Zero point four four |
| six | Zero point one three | Zero point two four |
| seven | Zero point three | Zero point zero three |
| eight | Two point six five | Two point one |
| nine | Zero point nine one | Zero point nine one |
| Ten | Zero point four six | Zero point three two |
| 列中值 | Zero point eight three | Zero point six nine |

在进行任何分析之前，第一步是从所有观察值中减去平均值，这将去除变量的比例因子，并使它们在各个维度上更加一致。

| **X** | **Y** |
| *0.72 - 0.83 = -0.12* | *0.13 - 0.69 = - 0.55* |
| *0.18 - 0.83 = -0.65* | *0.23 - 0.69 = - 0.46* |
| *2.50 - 0.83 = 1.67* | *2.30 - 0.69 = 1.61* |
| *0.45 - 0.83 = -0.38* | *0.16 - 0.69 = - 0.52* |
| *0.04 - 0.83 = -0.80* | *0.44 - 0.69 = - 0.25* |
| *0.13 - 0.83 = -0.71* | *0.24 - 0.69 = - 0.45* |
| *0.30 - 0.83 = -0.53* | *0.03 - 0.69 = - 0.66* |
| *2.65 - 0.83 = 1.82* | *2.10 - 0.69 = 1.41* |
| *0.91 - 0.83 = 0.07* | *0.91 - 0.69 = 0.23* |
| *0.46 - 0.83 = -0.37* | *0.32 - 0.69 = -0.36* |

使用两种不同的技术计算主成分:

*   数据的协方差矩阵
*   奇异值分解

我们将在下一节讨论奇异值分解技术。在本节中，我们将使用协方差矩阵方法来求解特征向量和特征值。

协方差是对两个变量一起变化的程度的度量，也是对两组变量之间相关性强度的度量。如果两个变量的协方差为零，我们可以断定两组变量之间不会有任何相关性。协方差公式如下:

![](assets/5552179c-6413-430f-90f8-7b55293be52c.jpg)

以下公式中显示了 *X* 和 *Y* 变量的样本协方差计算。然而，它是整个协方差矩阵的 2×2 矩阵(也是一个方阵)。

![](assets/6acde477-a6f2-4055-a22e-bf49db13fb9e.jpg)

![](assets/95c78c03-a188-4a77-b0d6-ccc909fb2199.jpg)

![](assets/e9a09e9b-4d58-4798-9b45-f621f9788db3.jpg)

由于协方差矩阵是平方的，我们可以从中计算特征向量和特征值。您可以参考前面章节中解释的方法。

![](assets/3303754e-fb61-4316-a955-fb82db11e2e7.jpg)

通过求解前面的方程，我们可以得到特征向量和特征值，如下所示:

![](assets/ae52ab1a-fcbe-4f68-b91f-f5098f050de6.jpg)

![](assets/1518968c-610a-4086-aff9-188569ac9070.jpg)

使用以下 Python 语法可以获得前面提到的结果:

```py
>>> import numpy as np
>>> w, v = np.linalg.eig(np.array([[ 0.91335 ,0.75969 ],[ 0.75969,0.69702]]))
\>>> print ("\nEigen Values\n", w)
>>> print ("\nEigen Vectors\n", v)

```

![](assets/b635818b-d388-4c62-9f55-026e355cb7a8.png)

一旦我们获得特征向量和特征值，我们就可以将数据投影到主成分中。第一特征向量具有最大特征值，并且是第一主成分，因为我们希望将原始 2D 数据简化为 1D 数据。

![](assets/89c4273f-827b-4870-86ed-d86e83e3100a.jpg)

从前面的结果中，我们可以看到来自原始 2D 数据的第一主成分的 1D 投影。此外，1.5725 的特征值解释了这样一个事实，即主成分解释的方差比原始变量多 57%。在多维数据的情况下，经验法则是选择特征值或主成分的值大于投影应该考虑的值。

# 基于 scikit-learn 的主成分分析在手写数字中的应用

以 scikit-learn 数据集的手写数字为例说明了主成分分析的例子，其中手写数字是从 0-9 及其相应的 64 个像素强度特征(8×8 矩阵)创建的。这里的想法是将 64 维的原始特征表示成尽可能少的:

```py
# PCA - Principal Component Analysis 
>>> import matplotlib.pyplot as plt 
>>> from sklearn.decomposition import PCA 
>>> from sklearn.datasets import load_digits 

>>> digits = load_digits() 
>>> X = digits.data 
>>> y = digits.target 

>>> print (digits.data[0].reshape(8,8)) 

```

![](assets/8487d51f-7631-4f41-9b1a-587e76e3f246.png)

使用`plt.show`功能绘制图表:

```py
>>> plt.matshow(digits.images[0])  
>>> plt.show()  

```

![](assets/915d1d2e-953b-4357-8c70-ab661fb05b36.png)

在执行主成分分析之前，建议对输入数据进行缩放，以消除由于数据维度不同而导致的任何问题。例如，在对客户数据应用主成分分析时，他们的工资比客户的年龄具有更大的维度。因此，如果我们不把所有的变量放在一个相似的维度，一个变量将解释整个变化，而不是它的实际影响。在下面的代码中，我们对所有列分别应用了缩放:

```py
>>> from sklearn.preprocessing import scale 
>>> X_scale = scale(X,axis=0)

```

在下文中，我们使用了两个主成分，因此我们可以在 2D 图上表示性能。在后面的部分中，我们也应用了 3D。

```py
>>> pca = PCA(n_components=2) 
>>> reduced_X = pca.fit_transform(X_scale) 

>>> zero_x, zero_y = [],[] ; one_x, one_y = [],[] 
>>> two_x,two_y = [],[]; three_x, three_y = [],[] 
>>> four_x,four_y = [],[]; five_x,five_y = [],[] 
>>> six_x,six_y = [],[]; seven_x,seven_y = [],[] 
>>> eight_x,eight_y = [],[]; nine_x,nine_y = [],[] 

```

在下面的代码部分，我们将相关的主成分分别附加到每个数字上，这样我们就可以创建所有 10 个数字的散点图:

```py
>>> for i in range(len(reduced_X)): 
...     if y[i] == 0: 
...         zero_x.append(reduced_X[i][0]) 
...         zero_y.append(reduced_X[i][1]) 

...     elif y[i] == 1: 
...         one_x.append(reduced_X[i][0]) 
...         one_y.append(reduced_X[i][1]) 

...     elif y[i] == 2: 
...         two_x.append(reduced_X[i][0]) 
...         two_y.append(reduced_X[i][1]) 

...     elif y[i] == 3: 
...         three_x.append(reduced_X[i][0]) 
...         three_y.append(reduced_X[i][1]) 

...     elif y[i] == 4: 
...         four_x.append(reduced_X[i][0]) 
...         four_y.append(reduced_X[i][1]) 

...     elif y[i] == 5: 
...         five_x.append(reduced_X[i][0]) 
...         five_y.append(reduced_X[i][1]) 

...     elif y[i] == 6: 
...         six_x.append(reduced_X[i][0]) 
...         six_y.append(reduced_X[i][1]) 

...     elif y[i] == 7: 
...         seven_x.append(reduced_X[i][0]) 
...         seven_y.append(reduced_X[i][1]) 

...     elif y[i] == 8: 
...         eight_x.append(reduced_X[i][0]) 
...         eight_y.append(reduced_X[i][1]) 

...     elif y[i] == 9: 
...         nine_x.append(reduced_X[i][0]) 
...         nine_y.append(reduced_X[i][1]) 
>>> zero = plt.scatter(zero_x, zero_y, c='r', marker='x',label='zero') 
>>> one = plt.scatter(one_x, one_y, c='g', marker='+') 
>>> two = plt.scatter(two_x, two_y, c='b', marker='s') 

>>> three = plt.scatter(three_x, three_y, c='m', marker='*') 
>>> four = plt.scatter(four_x, four_y, c='c', marker='h') 
>>> five = plt.scatter(five_x, five_y, c='r', marker='D') 

>>> six = plt.scatter(six_x, six_y, c='y', marker='8') 
>>> seven = plt.scatter(seven_x, seven_y, c='k', marker='*') 
>>> eight = plt.scatter(eight_x, eight_y, c='r', marker='x') 

>>> nine = plt.scatter(nine_x, nine_y, c='b', marker='D') 

>>> plt.legend((zero,one,two,three,four,five,six,seven,eight,nine), 
...            ('zero','one','two','three','four','five','six', 'seven','eight','nine'), 
...            scatterpoints=1, 
...            loc='lower left', 
...            ncol=3, 
...            fontsize=10) 

>>> plt.xlabel('PC 1') 
>>> plt.ylabel('PC 2') 

>>> plt.show() 

```

![](assets/60edae9b-b0d9-4b7d-8a4d-caf149c518b1.png)

虽然前面的情节看起来有点混乱，但它确实提供了一些关于数字之间远近的概念。我们得到的想法是数字 *6* 和 *8* 非常相似，数字 *4* 和 *7* 离中心组非常远，以此类推。然而，我们也应该尝试使用更多数量的主成分分析，因为有时，我们可能无法代表两个维度本身的每个变化。

在下面的代码中，我们应用了三个主成分分析，这样我们就可以在三维空间中更好地查看数据。除了为每个数字创建一个额外维度( *X* 、 *Y* 和 *Z* )之外，该过程与两个主成分分析非常相似。

```py
# 3-Dimensional data 
>>> pca_3d = PCA(n_components=3) 
>>> reduced_X3D = pca_3d.fit_transform(X_scale) 

>>> zero_x, zero_y,zero_z = [],[],[] ; one_x, one_y,one_z = [],[],[] 
>>> two_x,two_y,two_z = [],[],[]; three_x, three_y,three_z = [],[],[] 
>>> four_x,four_y,four_z = [],[],[]; five_x,five_y,five_z = [],[],[] 
>>> six_x,six_y,six_z = [],[],[]; seven_x,seven_y,seven_z = [],[],[] 
>>> eight_x,eight_y,eight_z = [],[],[]; nine_x,nine_y,nine_z = [],[],[] 

>>> for i in range(len(reduced_X3D)): 

...     if y[i]==10: 
...         continue  

...     elif y[i] == 0: 
...         zero_x.append(reduced_X3D[i][0]) 
...         zero_y.append(reduced_X3D[i][1]) 
...         zero_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 1: 
...         one_x.append(reduced_X3D[i][0]) 
...         one_y.append(reduced_X3D[i][1]) 
...         one_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 2: 
...         two_x.append(reduced_X3D[i][0]) 
...         two_y.append(reduced_X3D[i][1]) 
...         two_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 3: 
...         three_x.append(reduced_X3D[i][0]) 
...         three_y.append(reduced_X3D[i][1]) 
...         three_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 4: 
...         four_x.append(reduced_X3D[i][0]) 
...         four_y.append(reduced_X3D[i][1]) 
...         four_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 5: 
...         five_x.append(reduced_X3D[i][0]) 
...         five_y.append(reduced_X3D[i][1]) 
...         five_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 6: 
...         six_x.append(reduced_X3D[i][0]) 
...         six_y.append(reduced_X3D[i][1]) 
...         six_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 7: 
...         seven_x.append(reduced_X3D[i][0]) 
...         seven_y.append(reduced_X3D[i][1]) 
...         seven_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 8: 
...         eight_x.append(reduced_X3D[i][0]) 
...         eight_y.append(reduced_X3D[i][1]) 
...         eight_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 9: 
...         nine_x.append(reduced_X3D[i][0]) 
...         nine_y.append(reduced_X3D[i][1]) 
...         nine_z.append(reduced_X3D[i][2]) 

 # 3- Dimensional plot 
>>> from mpl_toolkits.mplot3d import Axes3D 
>>> fig = plt.figure() 
>>> ax = fig.add_subplot(111, projection='3d') 

>>> ax.scatter(zero_x, zero_y,zero_z, c='r', marker='x',label='zero') 
>>> ax.scatter(one_x, one_y,one_z, c='g', marker='+',label='one') 
>>> ax.scatter(two_x, two_y,two_z, c='b', marker='s',label='two') 

>>> ax.scatter(three_x, three_y,three_z, c='m', marker='*',label='three') 
>>> ax.scatter(four_x, four_y,four_z, c='c', marker='h',label='four') 
>>> ax.scatter(five_x, five_y,five_z, c='r', marker='D',label='five') 

>>> ax.scatter(six_x, six_y,six_z, c='y', marker='8',label='six') 
>>> ax.scatter(seven_x, seven_y,seven_z, c='k', marker='*',label='seven') 
>>> ax.scatter(eight_x, eight_y,eight_z, c='r', marker='x',label='eight') 

>>> ax.scatter(nine_x, nine_y,nine_z, c='b', marker='D',label='nine') 
>>> ax.set_xlabel('PC 1') 
>>> ax.set_ylabel('PC 2') 
>>> ax.set_zlabel('PC 3') 

>>> plt.legend(loc='upper left', numpoints=1, ncol=3, fontsize=10, bbox_to_anchor=(0, 0)) 

>>> plt.show()

```

![](assets/2227f691-ca4a-4b82-ade0-6d07b3f39c41.png)

matplotlib 图与其他软件图如 R 图等相比有一个很大的优势。它们是交互式的，这意味着我们可以旋转它们，并从各个方向看到它们的外观。我们鼓励读者通过旋转和探索来观察情节。在一个 3D 剧情中，我们可以看到一个类似的故事，有更多的解释。数字 *2* 在图的最左边，数字 *0* 在图的下部。而数字 *4* 在右上角，数字 *6* 似乎更偏向 *PC 1* 轴。这样，我们就可以形象地看到数字是如何分布的。在 4 个 PCA 的情况下，我们需要去寻找支线剧情并分别可视化它们。

在无监督学习中，选择要提取的主成分分析的数量是一个开放式的问题，但是为了获得近似的视图，有一些转折。有两种方法可以确定集群的数量:

*   检查解释的总方差在哪里略微减少
*   解释的总差异超过 80%

下面的代码确实提供了用主成分数量的变化解释的总方差。随着电脑数量的增加，将会解释更多的差异。但是，挑战是限制尽可能少的个人电脑，这将通过限制解释开始的边际方差增加减少的地方来实现。

```py
# Choosing number of Principal Components 
>>> max_pc = 30 

>>> pcs = [] 
>>> totexp_var = [] 

>>> for i in range(max_pc): 
...     pca = PCA(n_components=i+1) 
...     reduced_X = pca.fit_transform(X_scale) 
...     tot_var = pca.explained_variance_ratio_.sum() 
...     pcs.append(i+1) 
...     totexp_var.append(tot_var) 

>>> plt.plot(pcs,totexp_var,'r') 
>>> plt.plot(pcs,totexp_var,'bs') 
>>> plt.xlabel('No. of PCs',fontsize = 13) 
>>> plt.ylabel('Total variance explained',fontsize = 13) 
 >>> plt.xticks(pcs,fontsize=13) 
>>> plt.yticks(fontsize=13) 
>>> plt.show() 

```

![](assets/d4e6b576-9041-4362-8fc5-4376d9b63946.png)

从前面的图中，我们可以看到解释的总方差在 10 个主成分分析时略微减小；而在 21 个主成分分析中，解释的总方差大于 80%。选择哪种价值取决于企业和用户。

应用于手写数字数据的主成分分析的 R 代码如下:

```py
# PCA   
digits_data = read.csv("digitsdata.csv")   

remove_cols = c("target")   
x_data =   digits_data[,!(names(digits_data) %in% remove_cols)]   
y_data = digits_data[,c("target")]   

# Normalizing the data   
normalize <- function(x)   {return((x - min(x)) / (max(x) - min(x)))}   
data_norm <-   as.data.frame(lapply(x_data, normalize))   
data_norm <-   replace(data_norm, is.na(data_norm), 0.0)   

# Extracting Principal   Components   
pr_out =prcomp(data_norm)   
pr_components_all = pr_out$x   

# 2- Dimensional PCA   
K_prcomps = 2   
pr_components =   pr_components_all[,1:K_prcomps]   

pr_components_df =   data.frame(pr_components)   
pr_components_df =   cbind(pr_components_df,digits_data$target)   
names(pr_components_df)[K_prcomps+1]   = "target"   

out <- split(   pr_components_df , f = pr_components_df$target )   
zero_df = out$`0`;one_df =   out$`1`;two_df = out$`2`; three_df = out$`3`; four_df = out$`4`   
five_df = out$`5`;six_df =   out$`6`;seven_df = out$`7`;eight_df = out$`8`;nine_df = out$`9`   

library(ggplot2)   
# Plotting 2-dimensional PCA   
ggplot(pr_components_df, aes(x   = PC1, y = PC2, color = factor(target,labels = c("zero","one","two",   "three","four", "five","six","seven","eight","nine"))))   +    
geom_point()+ggtitle("2-D   PCA on Digits Data") +   
labs(color = "Digtis")   

# 3- Dimensional PCA   
# Plotting 3-dimensional PCA   
K_prcomps = 3   

pr_components =   pr_components_all[,1:K_prcomps]   
pr_components_df =   data.frame(pr_components)   
pr_components_df =   cbind(pr_components_df,digits_data$target)   
names(pr_components_df)[K_prcomps+1]   = "target"   

pr_components_df$target =   as.factor(pr_components_df$target)   

out <- split(   pr_components_df , f = pr_components_df$target )   
zero_df = out$`0`;one_df =   out$`1`;two_df = out$`2`; three_df = out$`3`; four_df = out$`4`   
five_df = out$`5`;six_df =   out$`6`;seven_df = out$`7`;eight_df = out$`8`;nine_df = out$`9`   

library(scatterplot3d)   
colors <- c("darkred",   "darkseagreen4", "deeppink4", "greenyellow", "orange",   "navyblue", "red", "tan3", "steelblue1",   "slateblue")   
colors <- colors[as.numeric(pr_components_df$target)]   
s3d =   scatterplot3d(pr_components_df[,1:3], pch = 16, color=colors,   
xlab = "PC1",ylab = "PC2",zlab   = "PC3",col.grid="lightblue",main = "3-D PCA on   Digits Data")   
legend(s3d$xyz.convert(3.1,   0.1, -3.5), pch = 16, yjust=0,   
       legend =   levels(pr_components_df$target),col =colors,cex = 1.1,xjust = 0)   

# Choosing number of Principal   Components   
pr_var =pr_out$sdev ^2   
pr_totvar = pr_var/sum(pr_var)   
plot(cumsum(pr_totvar), xlab="Principal   Component", ylab ="Cumilative Prop. of Var.",   ylim=c(0,1),type="b",main = "PCAs vs. Cum prop of Var   Explained") 

```

# 奇异值分解

主成分分析的许多实现使用奇异值分解来计算特征向量和特征值。奇异值分解由下式给出:

![](assets/2d894c0a-db0c-4d73-91fb-3e6a89b9bcbf.jpg)

![](assets/6a714b8d-26f9-4eb1-84af-ba2d98c602ad.jpg)

*U* 的列称为数据矩阵的左奇异向量， *V* 的列为其右奇异向量，![](assets/7a1f26f9-511f-4c94-b02e-cb718d431278.png)的对角条目为其奇异值。左奇异向量是协方差矩阵的特征向量，![](assets/f43934e4-9070-4ba9-a788-debc35d9908c.png)的对角元素是协方差矩阵特征值的平方根。

在继续使用支持向量机之前，最好了解支持向量机的一些优点和要点:

*   奇异值分解甚至可以应用于矩形矩阵；而特征值只为方阵定义。通过奇异值分解方法获得的特征值的等价物被称为奇异值，获得的与特征向量等价的向量被称为奇异向量。然而，因为它们本质上是矩形的，所以我们需要为它们的维度分别有左奇异向量和右奇异向量。
*   如果一个矩阵 *A* 有一个不可逆的特征向量矩阵 *P* ，那么 *A* 就没有特征分解。但是如果 *A* 是 *m* x *n* 实矩阵与*m*T16*n*的话，那么 A 可以用奇异值分解来写。
*   *U* 和 *V* 都是正交矩阵，表示 *U <sup>T</sup> U = I* ( *I* 带 *m* x *m* 维)或 *V <sup>T</sup> V = I* (此处 *I* 带 *n* x *n* 维)，其中
*   ![](assets/e79937b4-fd80-4b10-a7c6-b044abf9bc95.png)为非负对角矩阵，尺寸为 *m* x *n* 。

然后，奇异值和奇异向量的计算通过以下方程组完成:

![](assets/f464c276-87c1-407a-b3e8-63590166f805.jpg)

在第一阶段，奇异值/特征值用以下方程计算。一旦我们得到奇异/特征值，我们将代入确定 *V* 或右奇异/特征向量:

![](assets/3fb866a6-ff8b-4316-a859-bf62ddf32090.jpg)

一旦我们获得了右奇异向量和对角值，我们将使用下面提到的等式代入以获得左奇异向量 *U* :

![](assets/adf07d6c-e447-48ba-a7c7-f9b028c47a7e.jpg)

这样，我们将计算原始方程组矩阵的奇异值分解。

# 基于 scikit-learn 的支持向量机在手写数字中的应用

奇异值分解可以应用于相同的手写数字数据，进行苹果对苹果的技术比较。

```py
# SVD 
>>> import matplotlib.pyplot as plt 
>>> from sklearn.datasets import load_digits 

>>> digits = load_digits() 
>>> X = digits.data 
>>> y = digits.target 

```

在下面的代码中，使用了 15 个 300 次迭代的奇异向量，但是我们鼓励读者更改值并检查 SVD 的性能。我们使用了两种类型的奇异值分解函数，一种函数`randomized_svd`提供原始矩阵的分解，一种函数`TruncatedSVD`提供总方差解释比。实际上，用户可能不需要查看所有的分解，他们可以使用`TruncatedSVD`函数来实现他们的实际目的。

```py
>>> from sklearn.utils.extmath import randomized_svd 
>>> U,Sigma,VT = randomized_svd(X,n_components=15,n_iter=300,random_state=42) 

>>> import pandas as pd 
>>> VT_df = pd.DataFrame(VT) 

>>> print ("\nShape of Original Matrix:",X.shape) 
>>> print ("\nShape of Left Singular vector:",U.shape) 
>>> print ("Shape of Singular value:",Sigma.shape) 
>>> print ("Shape of Right Singular vector",VT.shape) 

```

![](assets/46089f98-05f1-4bb7-a436-0dc908b03536.png)

通过看前面的截图，我们可以看到维(1797 x 64)的原始矩阵已经分解为左奇异向量(1797 x 15)、奇异值(15 的对角矩阵)和右奇异向量(15 x 64)。我们可以通过将所有三个矩阵按顺序相乘来获得原始矩阵。

```py
>>> n_comps = 15 
>>> from sklearn.decomposition import TruncatedSVD 
>>> svd = TruncatedSVD(n_components=n_comps, n_iter=300, random_state=42) 
>>> reduced_X = svd.fit_transform(X) 

>>> print("\nTotal Variance explained for %d singular features are %0.3f"%(n_comps, svd.explained_variance_ratio_.sum())) 

```

![](assets/4e1cbdcc-079c-4490-8d98-3f5be1986af5.png)

15 个奇异值特征的总方差解释为 83.4%。但是读者需要改变不同的值来决定最佳值。

以下代码说明了总方差的变化，并分别解释了奇异值数量的变化:

```py
# Choosing number of Singular Values 
>>> max_singfeat = 30 
>>> singfeats = [] 
>>> totexp_var = [] 

>>> for i in range(max_singfeat): 
...     svd = TruncatedSVD(n_components=i+1, n_iter=300, random_state=42) 
...     reduced_X = svd.fit_transform(X) 
...     tot_var = svd.explained_variance_ratio_.sum() 
...     singfeats.append(i+1) 
...     totexp_var.append(tot_var) 

>>> plt.plot(singfeats,totexp_var,'r') 
>>> plt.plot(singfeats,totexp_var,'bs') 
>>> plt.xlabel('No. of Features',fontsize = 13) 
>>> plt.ylabel('Total variance explained',fontsize = 13) 

>>> plt.xticks(pcs,fontsize=13) 
>>> plt.yticks(fontsize=13) 
>>> plt.show()

```

![](assets/d45f0140-e7f1-4f8e-b73a-db9be0f0d7bf.png)

从前面的图中，我们可以根据需要选择 8 个或 15 个奇异向量。

应用于手写数字数据的奇异值分解的 R 码如下:

```py
#SVD    
library(svd)   

digits_data = read.csv("digitsdata.csv")   

remove_cols = c("target")   
x_data =   digits_data[,!(names(digits_data) %in% remove_cols)]   
y_data = digits_data[,c("target")]   

sv2 <- svd(x_data,nu=15)   

# Computing the square of the   singular values, which can be thought of as the vector of matrix energy   
# in order to pick top singular   values which preserve at least 80% of variance explained   
energy <- sv2$d ^ 2   
tot_varexp = data.frame(cumsum(energy)   / sum(energy))   

names(tot_varexp) = "cum_var_explained"   
tot_varexp$K_value =   1:nrow(tot_varexp)   

plot(tot_varexp[,2],tot_varexp[,1],type   = 'o',xlab = "K_Value",ylab = "Prop. of Var Explained")   
title("SVD - Prop. of Var   explained with K-value")    

```

# 深度自动编码器

自动编码器神经网络是一种无监督学习算法，它应用反向传播将目标值设置为等于输入*y<sup>(I)</sup>= x<sup>(I)</sup>*。自动编码器试图学习一个函数 *h <sub>w，b</sub> (x) ≈ x* ，意味着它试图学习一个恒等式函数的近似值，从而输出类似于 *x* 的![](assets/0897fb34-0878-4361-a91a-b555ca3a383a.jpg)。

![](assets/1d500bee-7192-4b86-a942-1723cf366898.png)

虽然试图复制身份函数看起来是微不足道的学习功能，但通过对网络设置约束，例如限制隐藏单元的数量，我们可以发现关于数据的有趣结构。假设大小为 10 x 10 像素的输入图片具有总共 100 个输入值的强度值，第二层(隐藏层)中的神经元数量为 50 个单位，最后输出层具有 100 个单位的神经元，因为我们需要传递图像以将其映射到自身，并且当在该过程中实现该表示时，我们将强制网络学习输入的压缩表示， 也就是隐藏单元激活*a<sup>(2)</sup>εR<sup>100</sup>T5】，用它我们必须尝试重建 100 像素输入 *x* 。 如果输入数据是完全随机的，没有任何相关性，等等。压缩将非常困难，而如果底层数据具有一些相关性或可检测的结构，则该算法将能够发现相关性并紧凑地表示它们。事实上，自动编码器最终往往会学习到与主成分分析非常相似的低维表示。*

# 使用编码器-解码器结构的建模技术

训练自动编码器模型有点棘手，因此提供了详细的说明，以便读者更好地理解。在训练阶段，整个编码器-解码器部分针对与解码器输出相同的输入进行训练。为了获得期望的输出，当我们通过会聚层和发散层时，特征将在中间层被压缩。一旦通过减少迭代次数的误差值进行了足够的训练，我们将使用训练好的编码器部分来为下一阶段的建模或可视化等创建潜在特征。

下图显示了一个示例。输入和输出层有五个神经元，而中间部分的神经元数量逐渐减少。压缩层只有两个神经元，这是我们希望从数据中提取的潜在维数。

![](assets/6fd22554-ac9d-404d-894d-f097011aba48.png)

下图描述了使用训练好的编码器部分从新的输入数据创建潜在特征，这些特征将用于可视化或模型的下一阶段:

![](assets/f3988071-81fe-41e6-ac89-81b39659e665.png)

# 深度自动编码器应用于手写数字使用 Keras

用相同的手写数字数据解释深度自动编码器，以显示这种非线性方法与线性方法(如主成分分析和奇异值分解)的区别。非线性方法通常表现得更好，但这些方法是一种黑箱模型，我们无法确定背后的解释。Keras 软件已被用于构建此处的深度自动编码器，因为它们像乐高积木一样工作，这使得用户可以轻松地玩模型的不同架构和参数，以便更好地理解:

```py
# Deep Auto Encoders 
>>> import matplotlib.pyplot as plt 
>>> from sklearn.preprocessing import StandardScaler 
>>> from sklearn.datasets import load_digits 

>>> digits = load_digits() 
>>> X = digits.data 
>>> y = digits.target 

>>> print (X.shape) 
>>> print (y.shape) 
>>> x_vars_stdscle = StandardScaler().fit_transform(X) 
>>> print (x_vars_stdscle.shape) 

```

![](assets/8cf8ac0b-b153-408a-b147-9eac9423f68a.png)

用于构建编码器-解码器架构的 Keras 密集神经元模块:

```py
>>> from keras.layers import Input,Dense 
>>> from keras.models import Model

```

![](assets/a242cd0c-e889-4c71-a128-c8d40d546334.png)

这里使用了 NVIDIA GTX 1060 的 GPU，还安装了`cuDNN`和`CNMeM`库，在常规 GPU 性能的基础上，速度进一步提升 4-5 倍。这些库利用了 20%的图形处理器内存，剩下 80%的内存用于处理数据。用户需要小心，如果他们有像 3 GB 到 4 GB 这样的低内存 GPU，他们可能无法利用这些库。

The reader needs to consider one important point that, syntax of Keras code, will remain same in both CPU and GPU mode.

以下几行代码是模型的核心。输入数据有 64 列。我们需要将这些列作为层的输入，因此我们给出了 64 的形状。此外，神经网络的每一层都有名称，我们将在接下来的代码部分解释原因。在第一隐藏层中，使用了 32 个密集神经元，这意味着来自输入层的所有 64 个输入都连接到第一隐藏层中的 32 个神经元。整个维度流就像 *64，32，16，2，16，32，64* 。我们已经将输入压缩到两个神经元，以便在 2D 图上绘制组件，然而，如果我们需要绘制 3D 数据(我们将在下一节中讨论)，我们需要将隐藏的三层编号更改为三，而不是二。训练完成后，我们需要使用编码器部分并预测输出。

```py
# 2-Dimensional Architecture 

>>> input_layer = Input(shape=(64,),name="input") 

>>> encoded = Dense(32, activation='relu',name="h1encode")(input_layer) 
>>> encoded = Dense(16, activation='relu',name="h2encode")(encoded) 
>>> encoded = Dense(2, activation='relu',name="h3latent_layer")(encoded) 

>>> decoded = Dense(16, activation='relu',name="h4decode")(encoded) 
>>> decoded = Dense(32, activation='relu',name="h5decode")(decoded) 
>>> decoded = Dense(64, activation='sigmoid',name="h6decode")(decoded) 

```

为了训练模型，我们需要通过架构的起点和终点。在下面的代码中，我们提供的输入为`input_layer`，输出为`decoded`，这是最后一层(名称为`h6decode`):

```py
>>> autoencoder = Model(input_layer, decoded) 

```

Adam 优化已用于优化均方误差，因为我们希望在网络输出层的末端再现原始输入:

```py
>>> autoencoder.compile(optimizer="adam", loss="mse") 

```

该网络用 100 个时期和每批 256 个观测值的批量来训练。20%的验证分割用于检查随机选择的验证数据的准确性，以确保稳健性，就好像我们只对训练数据进行训练可能会产生过拟合问题，这在高度非线性的模型中非常常见:

```py
# Fitting Encoder-Decoder model 
>>> autoencoder.fit(x_vars_stdscle, x_vars_stdscle, epochs=100,batch_size=256, shuffle=True,validation_split= 0.2 ) 

```

![](assets/9acedd8c-bf8b-4eb4-b576-515355c5923c.png)

从前面的结果可以看出，该模型已经在 1437 个训练样本上进行了训练，并在 360 个样本上进行了验证。通过查看损失值，训练和验证损失分别从 1.2314 降至 0.9361 和 1.0451 降至 0.7326。因此，我们正朝着正确的方向前进。然而，我们鼓励读者尝试各种体系结构和迭代次数、批次大小等，看看精度可以进一步提高多少。

一旦编码器-解码器部分已经被训练，我们只需要采取编码器部分来压缩输入特征，以获得压缩的潜在特征，这是降维的核心思想！在下面的代码中，我们构建了另一个模型，它有一个训练好的输入层和一个中间隐藏层(`h3latent_layer`)。这就是为网络的每一层分配名称的原因。

```py
# Extracting Encoder section of the Model for prediction of latent variables 
>>> encoder = Model(autoencoder.input,autoencoder.get_layer("h3latent_layer").output) 

Extracted encoder section of the whole model used for prediction of input variables to generate sparse 2-dimensional representation, which is being performed with the following code 

# Predicting latent variables with extracted Encoder model 
>>> reduced_X = encoder.predict(x_vars_stdscle)  

```

只是为了检查减少的输入变量的维度，我们可以看到，对于所有观察，我们可以看到两个维度或两个列向量:

```py
 >>> print (reduced_X.shape) 

```

![](assets/3a56d32d-ce79-4713-b395-6911702320f9.png)

守则的以下部分与 2D 常设仲裁院非常相似:

```py
>>> zero_x, zero_y = [],[] ; one_x, one_y = [],[] 
>>> two_x,two_y = [],[]; three_x, three_y = [],[] 
>>> four_x,four_y = [],[]; five_x,five_y = [],[] 
>>> six_x,six_y = [],[]; seven_x,seven_y = [],[] 
>>> eight_x,eight_y = [],[]; nine_x,nine_y = [],[] 

# For 2-Dimensional data 
>>> for i in range(len(reduced_X)): 
...     if y[i] == 0: 
...         zero_x.append(reduced_X[i][0]) 
...         zero_y.append(reduced_X[i][1]) 

...     elif y[i] == 1: 
...         one_x.append(reduced_X[i][0]) 
...         one_y.append(reduced_X[i][1]) 

...     elif y[i] == 2: 
...         two_x.append(reduced_X[i][0]) 
...         two_y.append(reduced_X[i][1]) 
 ...     elif y[i] == 3: 
...         three_x.append(reduced_X[i][0]) 
...         three_y.append(reduced_X[i][1]) 

...     elif y[i] == 4: 
...         four_x.append(reduced_X[i][0]) 
...         four_y.append(reduced_X[i][1]) 

...     elif y[i] == 5: 
...         five_x.append(reduced_X[i][0]) 
...         five_y.append(reduced_X[i][1]) 

...     elif y[i] == 6: 
...         six_x.append(reduced_X[i][0]) 
...         six_y.append(reduced_X[i][1]) 

...     elif y[i] == 7: 
...         seven_x.append(reduced_X[i][0]) 
...         seven_y.append(reduced_X[i][1]) 

...     elif y[i] == 8: 
...         eight_x.append(reduced_X[i][0]) 
 ...        eight_y.append(reduced_X[i][1]) 

 ...    elif y[i] == 9: 
 ...        nine_x.append(reduced_X[i][0]) 
 ...        nine_y.append(reduced_X[i][1]) 

>>> zero = plt.scatter(zero_x, zero_y, c='r', marker='x',label='zero') 
>>> one = plt.scatter(one_x, one_y, c='g', marker='+') 
>>> two = plt.scatter(two_x, two_y, c='b', marker='s') 

>>> three = plt.scatter(three_x, three_y, c='m', marker='*') 
>>> four = plt.scatter(four_x, four_y, c='c', marker='h') 
>>> five = plt.scatter(five_x, five_y, c='r', marker='D') 

>>> six = plt.scatter(six_x, six_y, c='y', marker='8') 
>>> seven = plt.scatter(seven_x, seven_y, c='k', marker='*') 
>>> eight = plt.scatter(eight_x, eight_y, c='r', marker='x') 

>>> nine = plt.scatter(nine_x, nine_y, c='b', marker='D') 

>>> plt.legend((zero,one,two,three,four,five,six,seven,eight,nine), 
...  ('zero','one','two','three','four','five','six','seven','eight','nine'), 
...            scatterpoints=1,loc='lower right',ncol=3,fontsize=10) 

>>> plt.xlabel('Latent Feature 1',fontsize = 13) 
>>> plt.ylabel('Latent Feature 2',fontsize = 13) 

>>> plt.show() 

```

![](assets/f852498c-015f-4e1a-961c-10fbfe237e73.png)

从前面的图中，我们可以看到数据点被很好地分开，但问题是观察的方向，因为这些特征不会像相互正交的主成分那样，按照相互垂直的维度变化。在深度自动编码器的情况下，我们需要从 *(0，0)* 改变方向的视图来可视化这种非线性分类，我们将在下面的 3D 情况中详细看到。

以下是 3D 潜在特征的代码。除了`h3latent_layer`之外，所有代码保持不变，其中我们必须将值从`2`替换为`3`，因为这是编码器部分的结尾，我们将利用它创建潜在特征，最终，它将用于绘图目的。

```py
# 3-Dimensional architecture 
>>> input_layer = Input(shape=(64,),name="input") 

>>> encoded = Dense(32, activation='relu',name="h1encode")(input_layer) 
>>> encoded = Dense(16, activation='relu',name="h2encode")(encoded) 
>>> encoded = Dense(3, activation='relu',name="h3latent_layer")(encoded) 

>>> decoded = Dense(16, activation='relu',name="h4decode")(encoded) 
>>> decoded = Dense(32, activation='relu',name="h5decode")(decoded) 
>>> decoded = Dense(64, activation='sigmoid',name="h6decode")(decoded) 

>>> autoencoder = Model(input_layer, decoded) 
autoencoder.compile(optimizer="adam", loss="mse") 

# Fitting Encoder-Decoder model 
>>> autoencoder.fit(x_vars_stdscle, x_vars_stdscle, epochs=100,batch_size=256, shuffle=True,validation_split= 0.2) 

```

![](assets/982aebec-3b37-47d1-8cef-92445efdc4e9.png)

从前面的结果中，我们可以看到，在包含三维而不是二维的情况下，获得的损失值小于 2D 用例中的损失值。100 个时期后两个潜在因素的训练和验证损失为 0.9061 和 0.7326，100 个时期后三个潜在因素的训练和验证损失为 0.8032 和 0.6464。这意味着，通过多包含一个维度，我们可以显著减少误差。这样，读者可以更改各种参数来确定降维的理想架构:

```py
# Extracting Encoder section of the Model for prediction of latent variables 
>>> encoder = Model(autoencoder.input,autoencoder.get_layer("h3latent_layer").output) 

# Predicting latent variables with extracted Encoder model 
>>> reduced_X3D = encoder.predict(x_vars_stdscle) 

>>> zero_x, zero_y,zero_z = [],[],[] ; one_x, one_y,one_z = [],[],[] 
>>> two_x,two_y,two_z = [],[],[]; three_x, three_y,three_z = [],[],[] 
>>> four_x,four_y,four_z = [],[],[]; five_x,five_y,five_z = [],[],[] 
>>> six_x,six_y,six_z = [],[],[]; seven_x,seven_y,seven_z = [],[],[] 
>>> eight_x,eight_y,eight_z = [],[],[]; nine_x,nine_y,nine_z = [],[],[] 

>>> for i in range(len(reduced_X3D)): 

...     if y[i]==10: 
...         continue 

...     elif y[i] == 0: 
...         zero_x.append(reduced_X3D[i][0]) 
...         zero_y.append(reduced_X3D[i][1]) 
...         zero_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 1: 
...         one_x.append(reduced_X3D[i][0]) 
...         one_y.append(reduced_X3D[i][1]) 
...         one_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 2: 
...         two_x.append(reduced_X3D[i][0]) 
...         two_y.append(reduced_X3D[i][1]) 
...         two_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 3: 
...         three_x.append(reduced_X3D[i][0]) 
...         three_y.append(reduced_X3D[i][1]) 
...         three_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 4: 
...         four_x.append(reduced_X3D[i][0]) 
...         four_y.append(reduced_X3D[i][1]) 
...         four_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 5: 
...         five_x.append(reduced_X3D[i][0]) 
...         five_y.append(reduced_X3D[i][1]) 
...         five_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 6: 
...         six_x.append(reduced_X3D[i][0]) 
...         six_y.append(reduced_X3D[i][1]) 
...         six_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 7: 
...         seven_x.append(reduced_X3D[i][0]) 
...         seven_y.append(reduced_X3D[i][1]) 
...         seven_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 8: 
...         eight_x.append(reduced_X3D[i][0]) 
...         eight_y.append(reduced_X3D[i][1]) 
...         eight_z.append(reduced_X3D[i][2]) 

...     elif y[i] == 9: 
...         nine_x.append(reduced_X3D[i][0]) 
...         nine_y.append(reduced_X3D[i][1]) 
...         nine_z.append(reduced_X3D[i][2]) 

 # 3- Dimensional plot 
>>> from mpl_toolkits.mplot3d import Axes3D 
>>> fig = plt.figure() 
>>> ax = fig.add_subplot(111, projection='3d') 

>>> ax.scatter(zero_x, zero_y,zero_z, c='r', marker='x',label='zero') 
>>> ax.scatter(one_x, one_y,one_z, c='g', marker='+',label='one') 
>>> ax.scatter(two_x, two_y,two_z, c='b', marker='s',label='two') 

>>> ax.scatter(three_x, three_y,three_z, c='m', marker='*',label='three') 
>>> ax.scatter(four_x, four_y,four_z, c='c', marker='h',label='four') 
>>> ax.scatter(five_x, five_y,five_z, c='r', marker='D',label='five') 

>>> ax.scatter(six_x, six_y,six_z, c='y', marker='8',label='six') 
>>> ax.scatter(seven_x, seven_y,seven_z, c='k', marker='*',label='seven') 
>>> ax.scatter(eight_x, eight_y,eight_z, c='r', marker='x',label='eight') 
 >>> ax.scatter(nine_x, nine_y,nine_z, c='b', marker='D',label='nine') 

>>> ax.set_xlabel('Latent Feature 1',fontsize = 13) 
>>> ax.set_ylabel('Latent Feature 2',fontsize = 13) 
>>> ax.set_zlabel('Latent Feature 3',fontsize = 13) 

>>> ax.set_xlim3d(0,60) 

>>> plt.legend(loc='upper left', numpoints=1, ncol=3, fontsize=10, bbox_to_anchor=(0, 0)) 

>>> plt.show() 

```

![](assets/a659b9a7-188a-48cb-97fe-35bcb0f270ef.png)

与三个主成分分析相比，深度自动编码器的三维图确实提供了很好的分离分类。这里我们得到了更好的数字分离。这里读者应该考虑的一个重要点是，上面的图是从 *(0，0，0)* 旋转的视图，因为数据分离不会发生在正交平面上(像 PCAs)，因此我们需要从原点看到视图，以便看到这种非线性分类。

# 摘要

在本章中，您已经学习了各种无监督学习方法，使用 k 均值聚类、PCA、SVD 和深度自动编码器来识别数据中的结构和模式。此外，用虹膜数据解释了 k-均值聚类算法。给出了基于各种性能指标选择最佳 k 值的方法。scikit-learn 的手写数据被用来比较线性方法(如 PCA 和 SVD)与非线性技术和深度自动编码器之间的差异。详细给出了主成分分析和奇异值分解的区别，以便读者理解奇异值分解，它甚至可以应用于用户数和产品数不一定相等的矩形矩阵。最后，通过可视化，证明深度自动编码器比主成分分析和奇异值分解等线性无监督学习方法更擅长数字分离。

在下一章中，我们将讨论各种强化学习方法及其在人工智能等领域的应用。
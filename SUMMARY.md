+   [台湾大学林轩田机器学习笔记](docs/ntu-hsuantienlin-ml/README.md)
    +   [机器学习基石](docs/ntu-hsuantienlin-ml/1.md)
        +   [1 -- The Learning Problem](docs/ntu-hsuantienlin-ml/2.md)
        +   [2 -- Learning to Answer Yes/No](docs/ntu-hsuantienlin-ml/3.md)
        +   [3 -- Types of Learning](docs/ntu-hsuantienlin-ml/4.md)
        +   [4 -- Feasibility of Learning](docs/ntu-hsuantienlin-ml/5.md)
        +   [5 -- Training versus Testing](docs/ntu-hsuantienlin-ml/6.md)
        +   [6 -- Theory of Generalization](docs/ntu-hsuantienlin-ml/7.md)
        +   [7 -- The VC Dimension](docs/ntu-hsuantienlin-ml/8.md)
        +   [8 -- Noise and Error](docs/ntu-hsuantienlin-ml/9.md)
        +   [9 -- Linear Regression](docs/ntu-hsuantienlin-ml/10.md)
        +   [10 -- Logistic Regression](docs/ntu-hsuantienlin-ml/11.md)
        +   [11 -- Linear Models for Classification](docs/ntu-hsuantienlin-ml/12.md)
        +   [12 -- Nonlinear Transformation](docs/ntu-hsuantienlin-ml/13.md)
        +   [13 -- Hazard of Overfitting](docs/ntu-hsuantienlin-ml/14.md)
        +   [14 -- Regularization](docs/ntu-hsuantienlin-ml/15.md)
        +   [15 -- Validation](docs/ntu-hsuantienlin-ml/16.md)
        +   [16 -- Three Learning Principles](docs/ntu-hsuantienlin-ml/17.md)
    +   [机器学习技法](docs/ntu-hsuantienlin-ml/18.md)
        +   [1 -- Linear Support Vector Machine](docs/ntu-hsuantienlin-ml/19.md)
        +   [2 -- Dual Support Vector Machine](docs/ntu-hsuantienlin-ml/20.md)
        +   [3 -- Kernel Support Vector Machine](docs/ntu-hsuantienlin-ml/21.md)
        +   [4 -- Soft-Margin Support Vector Machine](docs/ntu-hsuantienlin-ml/22.md)
        +   [5 -- Kernel Logistic Regression](docs/ntu-hsuantienlin-ml/23.md)
        +   [6 -- Support Vector Regression](docs/ntu-hsuantienlin-ml/24.md)
        +   [7 -- Blending and Bagging](docs/ntu-hsuantienlin-ml/25.md)
        +   [8 -- Adaptive Boosting](docs/ntu-hsuantienlin-ml/26.md)
        +   [9 -- Decision Tree](docs/ntu-hsuantienlin-ml/27.md)
        +   [10 -- Random Forest](docs/ntu-hsuantienlin-ml/28.md)
        +   [11 -- Gradient Boosted Decision Tree](docs/ntu-hsuantienlin-ml/29.md)
        +   [12 -- Neural Network](docs/ntu-hsuantienlin-ml/30.md)
        +   [13 -- Deep Learning](docs/ntu-hsuantienlin-ml/31.md)
        +   [14 -- Radial Basis Function Network](docs/ntu-hsuantienlin-ml/32.md)
        +   [15 -- Matrix Factorization](docs/ntu-hsuantienlin-ml/33.md)
        +   [16（完结） -- Finale](docs/ntu-hsuantienlin-ml/34.md)
+   [Sklearn 秘籍](docs/sklearn-cookbook/README.md)
    +   [第一章 模型预处理](docs/sklearn-cookbook/1.md)
    +   [第二章 处理线性模型](docs/sklearn-cookbook/2.md)
    +   [第三章 使用距离向量构建模型](docs/sklearn-cookbook/3.md)
    +   [第四章 使用 scikit-learn 对数据分类](docs/sklearn-cookbook/4.md)
    +   [第五章 模型后处理](docs/sklearn-cookbook/5.md)
+   [Sklearn 学习手册](docs/learning-sklearn/README.md)
    +   [一、机器学习 - 温和的介绍](docs/learning-sklearn/ch01.md)
    +   [二、监督学习](docs/learning-sklearn/ch02.md)
    +   [三、无监督学习](docs/learning-sklearn/ch03.md)
    +   [四、高级功能](docs/learning-sklearn/ch04.md)
+   [SciPyCon 2018 sklearn 教程](docs/scipycon-2018-sklearn-tut/README.md)
    +   [一、Python 机器学习简介](docs/scipycon-2018-sklearn-tut/1.md)
    +   [二、Python 中的科学计算工具](docs/scipycon-2018-sklearn-tut/2.md)
    +   [三、数据表示和可视化](docs/scipycon-2018-sklearn-tut/3.md)
    +   [四、训练和测试数据](docs/scipycon-2018-sklearn-tut/4.md)
    +   [五、监督学习第一部分：分类](docs/scipycon-2018-sklearn-tut/5.md)
    +   [六、监督学习第二部分：回归分析](docs/scipycon-2018-sklearn-tut/6.md)
    +   [七、无监督学习第一部分：变换](docs/scipycon-2018-sklearn-tut/7.md)
    +   [八、无监督学习第二部分：聚类](docs/scipycon-2018-sklearn-tut/8.md)
    +   [九、sklearn 估计器接口回顾](docs/scipycon-2018-sklearn-tut/9.md)
    +   [十、案例学习：泰坦尼克幸存者](docs/scipycon-2018-sklearn-tut/10.md)
    +   [十一、文本特征提取](docs/scipycon-2018-sklearn-tut/11.md)
    +   [十二、案例学习：用于 SMS 垃圾检测的文本分类](docs/scipycon-2018-sklearn-tut/12.md)
    +   [十三、交叉验证和得分方法](docs/scipycon-2018-sklearn-tut/13.md)
    +   [十四、参数选择、验证和测试](docs/scipycon-2018-sklearn-tut/14.md)
    +   [十五、估计器流水线](docs/scipycon-2018-sklearn-tut/15.md)
    +   [十六、模型评估、得分指标和处理不平衡类别](docs/scipycon-2018-sklearn-tut/16.md)
    +   [十七、深入：线性模型](docs/scipycon-2018-sklearn-tut/17.md)
    +   [十八、深入：决策树与森林](docs/scipycon-2018-sklearn-tut/18.md)
    +   [十九、自动特征选择](docs/scipycon-2018-sklearn-tut/19.md)
    +   [二十、无监督学习：层次和基于密度的聚类算法](docs/scipycon-2018-sklearn-tut/20.md)
    +   [二十一、无监督学习：非线性降维](docs/scipycon-2018-sklearn-tut/21.md)
    +   [二十二、无监督学习：异常检测](docs/scipycon-2018-sklearn-tut/22.md)
    +   [二十三、核外学习 - 用于语义分析的大规模文本分类](docs/scipycon-2018-sklearn-tut/23.md)
+   [Python 机器学习在线指南](docs/vt-cs4624-pyml/README.md)
    +   [作者](docs/vt-cs4624-pyml/3.md)
    +   [引言](docs/vt-cs4624-pyml/5.md)
    +   [核心概念](docs/vt-cs4624-pyml/6.md)
        +   [交叉验证](docs/vt-cs4624-pyml/7.md)
        +   [线性回归](docs/vt-cs4624-pyml/8.md)
        +   [过拟合和欠拟合](docs/vt-cs4624-pyml/9.md)
        +   [正则化](docs/vt-cs4624-pyml/10.md)
    +   [监督学习](docs/vt-cs4624-pyml/11.md)
        +   [逻辑回归](docs/vt-cs4624-pyml/12.md)
        +   [朴素贝叶斯分类](docs/vt-cs4624-pyml/13.md)
        +   [决策树](docs/vt-cs4624-pyml/14.md)
        +   [k 最近邻](docs/vt-cs4624-pyml/15.md)
        +   [线性支持向量机](docs/vt-cs4624-pyml/16.md)
    +   [无监督学习](docs/vt-cs4624-pyml/17.md)
        +   [聚类](docs/vt-cs4624-pyml/18.md)
        +   [主成分分析](docs/vt-cs4624-pyml/19.md)
    +   [深度学习](docs/vt-cs4624-pyml/20.md)
        +   [多层感知机](docs/vt-cs4624-pyml/21.md)
        +   [卷积神经网络](docs/vt-cs4624-pyml/22.md)
        +   [自编码器](docs/vt-cs4624-pyml/23.md)
    +   [原文的协议](docs/vt-cs4624-pyml/25.md)
+   [写给人类的机器学习](docs/ml-for-humans/README.md)
    +   [一、为什么机器学习重要](docs/ml-for-humans/1.md)
    +   [2.1 监督学习](docs/ml-for-humans/2.1.md)
    +   [2.2 监督学习 II](docs/ml-for-humans/2.2.md)
    +   [2.3 监督学习 III](docs/ml-for-humans/2.3.md)
    +   [三、无监督学习](docs/ml-for-humans/3.md)
    +   [四、神经网络和深度学习](docs/ml-for-humans/4.md)
    +   [五、强化学习](docs/ml-for-humans/5.md)
    +   [六、最好的机器学习资源](docs/ml-for-humans/6.md)
+   [机器学习超级复习笔记](docs/super-machine-learning-revision-notes/README.md)
